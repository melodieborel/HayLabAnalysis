{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotCaCorr_BlackLinesOK.pkl\n",
      "TotCaCorr_BlueLinesOK.pkl\n",
      "TotCaCorr_GreenDotsOK.pkl\n",
      "TotCaCorr_GreenLinesOK.pkl\n",
      "TotCaCorr_RedLinesOK.pkl\n",
      "TotSpCorr_BlackLinesOK.pkl\n",
      "TotSpCorr_BlueLinesOK.pkl\n",
      "TotSpCorr_GreenDotsOK.pkl\n",
      "TotSpCorr_GreenLinesOK.pkl\n",
      "TotSpCorr_RedLinesOK.pkl\n",
      "VigSt_CaCorr_BlackLinesOK.pkl\n",
      "VigSt_CaCorr_BlueLinesOK.pkl\n",
      "VigSt_CaCorr_GreenDotsOK.pkl\n",
      "VigSt_CaCorr_GreenLinesOK.pkl\n",
      "VigSt_CaCorr_RedLinesOK.pkl\n",
      "VigSt_Global_BlackLinesOK.pkl\n",
      "VigSt_Global_BlueLinesOK.pkl\n",
      "VigSt_Global_GreenDotsOK.pkl\n",
      "VigSt_Global_GreenLinesOK.pkl\n",
      "VigSt_Global_RedLinesOK.pkl\n",
      "VigSt_SpCorr_BlackLinesOK.pkl\n",
      "VigSt_SpCorr_BlueLinesOK.pkl\n",
      "VigSt_SpCorr_GreenDotsOK.pkl\n",
      "VigSt_SpCorr_GreenLinesOK.pkl\n",
      "VigSt_SpCorr_RedLinesOK.pkl\n",
      "TotCaCorr_BlackLinesOK.pkl\n",
      "TotCaCorr_BlueLinesOK.pkl\n",
      "TotCaCorr_GreenDotsOK.pkl\n",
      "TotSpCorr_BlackLinesOK.pkl\n",
      "TotSpCorr_BlueLinesOK.pkl\n",
      "TotSpCorr_GreenDotsOK.pkl\n",
      "VigSt_CaCorr_BlackLinesOK.pkl\n",
      "VigSt_CaCorr_BlueLinesOK.pkl\n",
      "VigSt_CaCorr_GreenDotsOK.pkl\n",
      "VigSt_Global_BlackLinesOK.pkl\n",
      "VigSt_Global_BlueLinesOK.pkl\n",
      "VigSt_Global_GreenDotsOK.pkl\n",
      "VigSt_SpCorr_BlackLinesOK.pkl\n",
      "VigSt_SpCorr_BlueLinesOK.pkl\n",
      "VigSt_SpCorr_GreenDotsOK.pkl\n",
      "TotCaCorr_Purple.pkl\n",
      "TotCaCorr_ThreeBlueCrossesOK.pkl\n",
      "TotCaCorr_ThreeColDotsOK.pkl\n",
      "TotSpCorr_Purple.pkl\n",
      "TotSpCorr_ThreeBlueCrossesOK.pkl\n",
      "TotSpCorr_ThreeColDotsOK.pkl\n",
      "VigSt_CaCorr_Purple.pkl\n",
      "VigSt_CaCorr_ThreeBlueCrossesOK.pkl\n",
      "VigSt_CaCorr_ThreeColDotsOK.pkl\n",
      "VigSt_Global_Purple.pkl\n",
      "VigSt_Global_ThreeBlueCrossesOK.pkl\n",
      "VigSt_Global_ThreeColDotsOK.pkl\n",
      "VigSt_SpCorr_Purple.pkl\n",
      "VigSt_SpCorr_ThreeBlueCrossesOK.pkl\n",
      "VigSt_SpCorr_ThreeColDotsOK.pkl\n",
      "TotCaCorr_Purple.pkl\n",
      "TotCaCorr_ThreeColDotsOK.pkl\n",
      "TotSpCorr_Purple.pkl\n",
      "TotSpCorr_ThreeColDotsOK.pkl\n",
      "VigSt_CaCorr_Purple.pkl\n",
      "VigSt_CaCorr_ThreeColDotsOK.pkl\n",
      "VigSt_Global_Purple.pkl\n",
      "VigSt_Global_ThreeColDotsOK.pkl\n",
      "VigSt_SpCorr_Purple.pkl\n",
      "VigSt_SpCorr_ThreeColDotsOK.pkl\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column RatioNREM_REM",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28740\\574986794.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    512\u001b[0m                 \u001b[0mresultNormalizedAUC_calcium_perUnit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Unit_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Substate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Session'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NormalizedAUC_calcium'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m                 \u001b[1;32mtry\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mresultNormalizedAUC_calcium_perUnit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresultNormalizedAUC_calcium_perUnit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdesired_order\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m                 \u001b[0mresultNormalizedAUC_calcium_perUnit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Activated_by'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresultNormalizedAUC_calcium_perUnit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_column_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                 \u001b[0mresultNormalizedAUC_calcium_perUnit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RatioNREM_REM'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mdiscrimination_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultNormalizedAUC_calcium_perUnit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[0mfilenameOutAUC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_nAUC.xlsx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m                 \u001b[0mresultNormalizedAUC_calcium_perUnit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenameOutAUC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4077\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4078\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4079\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4080\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4081\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4082\u001b[0m         elif (\n\u001b[0;32m   4083\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4084\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4236\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4239\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   4240\u001b[0m                 \u001b[1;34m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4241\u001b[0m                 \u001b[1;34mf\"column {key}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4242\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column RatioNREM_REM"
     ]
    }
   ],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Vigilance States\n",
    "\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "AnalysisID='_AB_wRealTStest' #to identify this analysis from another\n",
    "DrugExperiment=0 # 0 if Baseline, 1 if CGP, 2 if Baseline & CGP\n",
    "\n",
    "saveexcel=0\n",
    "Local=1\n",
    "\n",
    "#choosed_folder='VigSt_2024-07-22_18_21_32_AB_FINAL' if DrugExperiment else 'VigSt_2024-07-22_17_16_28_AB_FINAL'\n",
    "choosed_folder1='VigSt_2024-09-03_02_33_22_AB_wRealTS' # for Baseline Expe\n",
    "choosed_folder2='VigSt_2024-09-03_03_16_31_AB_wRealTS' # for CGP Expe\n",
    "\n",
    "desired_order = ['Wake','NREM', 'REM']   \n",
    "#desired_order = ['Wake', 'N2', 'NREM', 'REM'] \n",
    "\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def extract_micename(index_value):\n",
    "    match = re.match(r\"([a-zA-Z]+)\", index_value)\n",
    "    return match.group(1) if match else index_value\n",
    "\n",
    "def max_column_name(row):\n",
    "    return row.idxmax()\n",
    "    \n",
    "def discrimination_index(df):\n",
    "    #Index = (AUCa-AUCb)/(AUCa+AUCb)\n",
    "    if 'REM' in df.columns and 'NREM' in df.columns :\n",
    "        disc_index =(df['NREM']-df['REM'])/(df['NREM']+df['REM'])\n",
    "        nan_rows = df['NREM'].isna() | df['REM'].isna()\n",
    "        disc_index[nan_rows] = np.nan\n",
    "    else:\n",
    "        disc_index=np.full(len(df), np.nan)\n",
    "    #min=df[['NREM', 'REM']].min(axis=1).abs()+1\n",
    "    #NREMadj=df['NREM']#+min\n",
    "    #REMadj=df['REM']#+min\n",
    "    #disc_index=NREMadj/REMadj\n",
    "    return disc_index\n",
    "\n",
    "def normalize_row(row):\n",
    "    max_col = row.idxmax()  # Find the column with the maximum value\n",
    "    max_val = row[max_col]  # Get the maximum value\n",
    "    return row / max_val   # Normalize the row by dividing by the maximum value\n",
    "\n",
    "def divide_keys(data, startkey, everykey):\n",
    "    for it in range(startkey, len(data), everykey):        \n",
    "        key2 = list(data.keys())[it-1]\n",
    "        key3 = list(data.keys())[it]\n",
    "        d=data[key3]\n",
    "        data[key3]=d.replace(0, np.nan)\n",
    "        if startkey>1:\n",
    "            key1 = list(data.keys())[it-2]\n",
    "            data[key1] = data[key1] / data[key3]\n",
    "        data[key2] = data[key2] / data[key3]\n",
    "    keys_to_delete = list(data.keys())[startkey::everykey]\n",
    "    for key in keys_to_delete:\n",
    "        del data[key]\n",
    "    return data   \n",
    "\n",
    "########################################################################\n",
    "        # SCRIPT 23AB_GrandAverages&Stats_for_VigilanceStates\n",
    "########################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory1 = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\" \n",
    "directory1= f'{InitialDirectory1}/{choosed_folder1}'\n",
    "InitialDirectory2 =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\" if Local else \"/crnldata/waking///L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\"\n",
    "directory2= f'{InitialDirectory2}/{choosed_folder2}'\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/AVG_VigSt_{FolderNameSave}{AnalysisID}\" if Local else f\"/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/AVG_VigSt_{FolderNameSave}{AnalysisID}\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/23_24_GrandAverage&Stats_for_VigilanceStates_FullAuto.py\" if Local else \"/HayLabAnalysis/python/23_24.py\" \n",
    "destination_file_path = f\"{destination_folder}/23_24_GrandAverage&Stats_for_VigilanceStates_FullAuto.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "NrSubtypeList=['L1','L2&3']\n",
    "\n",
    "for NrSubtype in NrSubtypeList:  \n",
    "\n",
    "    # Initialize an empty df/dict to store the dataframes\n",
    "    dfs = []\n",
    "    dfs2_per_sheet = {}\n",
    "    dfs3_per_sheet = {}\n",
    "    dfs4_per_sheet = {}\n",
    "    dfs5_per_sheet = {}\n",
    "    dfs6_per_sheet = {}\n",
    "\n",
    "    if NrSubtype=='L1':\n",
    "        MiceList=['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK', 'GreenLinesOK', 'RedLinesOK']\n",
    "    else:\n",
    "        MiceList=['Purple', 'ThreeColDotsOK', 'ThreeBlueCrossesOK']\n",
    "    \n",
    "    nametofind='Global'\n",
    "    nametofind2='VigSt_CaCorr'\n",
    "    nametofind3='VigSt_SpCorr'      \n",
    "    nametofind4='TotCaCorr'\n",
    "    nametofind5='TotSpCorr'\n",
    "    nametofind6='SatesCaCorr'\n",
    "\n",
    "    # Recursively traverse the directory structure\n",
    "    for directory in [directory1, directory2]:\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for filename in files:\n",
    "                # Check if the file is an Excel file and contains the specified name\n",
    "                if filename.endswith('.pkl') and nametofind in filename : \n",
    "                    if any(name in filename for name in MiceList): \n",
    "                        # Construct the full path to the file\n",
    "                        filepath = os.path.join(root, filename)\n",
    "                        # Read the file and append it to the list\n",
    "                        with open(filepath, 'rb') as pickle_file:\n",
    "                            df = pickle.load(pickle_file)\n",
    "                        dfs.append(df)\n",
    "                        print(filename)\n",
    "                if filename.endswith('.pkl') and nametofind2 in filename: \n",
    "                    if any(name in filename for name in MiceList): \n",
    "                        # Construct the full path to the file\n",
    "                        filepath = os.path.join(root, filename)\n",
    "                        with open(filepath, 'rb') as pickle_file:\n",
    "                            df = pickle.load(pickle_file)\n",
    "                        for key, value in df.items():\n",
    "                            if key in dfs2_per_sheet:\n",
    "                                dfs2_per_sheet[key]=pd.concat([dfs2_per_sheet[key],value],axis=0)\n",
    "                            else:\n",
    "                                dfs2_per_sheet[key]=value\n",
    "                        print(filename)\n",
    "                if filename.endswith('.pkl') and nametofind3 in filename: \n",
    "                    if any(name in filename for name in MiceList): \n",
    "                        # Construct the full path to the file\n",
    "                        filepath = os.path.join(root, filename)\n",
    "                        with open(filepath, 'rb') as pickle_file:\n",
    "                            df = pickle.load(pickle_file)\n",
    "                        for key, value in df.items():\n",
    "                            if key in dfs3_per_sheet:\n",
    "                                dfs3_per_sheet[key]=pd.concat([dfs3_per_sheet[key],value],axis=0)\n",
    "                            else:\n",
    "                                dfs3_per_sheet[key]=value\n",
    "                        print(filename)\n",
    "                if filename.endswith('.pkl') and nametofind4 in filename: \n",
    "                    if any(name in filename for name in MiceList): \n",
    "                        # Construct the full path to the file\n",
    "                        filepath = os.path.join(root, filename)\n",
    "                        with open(filepath, 'rb') as pickle_file:\n",
    "                            df = pickle.load(pickle_file)\n",
    "                        for key, value in df.items():\n",
    "                            if key in dfs4_per_sheet:\n",
    "                                dfs4_per_sheet[key]=pd.concat([dfs4_per_sheet[key],value],axis=0)\n",
    "                            else:\n",
    "                                dfs4_per_sheet[key]=value\n",
    "                        print(filename)\n",
    "                if filename.endswith('.pkl') and nametofind5 in filename: \n",
    "                    if any(name in filename for name in MiceList): \n",
    "                        # Construct the full path to the file\n",
    "                        filepath = os.path.join(root, filename)\n",
    "                        with open(filepath, 'rb') as pickle_file:\n",
    "                            df = pickle.load(pickle_file)\n",
    "                        for key, value in df.items():\n",
    "                            if key in dfs5_per_sheet:\n",
    "                                dfs5_per_sheet[key]=pd.concat([dfs5_per_sheet[key],value],axis=0)\n",
    "                            else:\n",
    "                                dfs5_per_sheet[key]=value\n",
    "                        print(filename)\n",
    "                if filename.endswith('.pkl') and nametofind6 in filename: \n",
    "                    if any(name in filename for name in MiceList): \n",
    "                        # Construct the full path to the file\n",
    "                        filepath = os.path.join(root, filename)\n",
    "                        with open(filepath, 'rb') as pickle_file:\n",
    "                            try : df = pickle.load(pickle_file)\n",
    "                            except: pass\n",
    "                        for key, value in df.items():\n",
    "                            if key in dfs6_per_sheet:\n",
    "                                dfs6_per_sheet[key]=pd.concat([dfs6_per_sheet[key],value],axis=0)\n",
    "                            else:\n",
    "                                dfs6_per_sheet[key]=value\n",
    "                        print(filename)\n",
    "\n",
    "    # Concatenate all dataframes into a single dataframe\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Remove non defined Unique Units \n",
    "    combined_df = combined_df[combined_df['Unique_Unit'] != '[]']\n",
    "    combined_df = combined_df.dropna(subset=['Unique_Unit'])\n",
    "\n",
    "    combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(int).astype(str)\n",
    "    combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "    combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "\n",
    "    combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "    \n",
    "    combined_df['NormalizedAUC_calcium'] = combined_df['AUC_calcium'] / combined_df['DurationSubstate']\n",
    "\n",
    "    combined_df['Substate_ID'] = combined_df['Mice'] + combined_df['Session'] + combined_df['Substate'] + combined_df['SubstateNumber'].astype(str)\n",
    "    combined_df['Session_ID'] = combined_df['Mice'] + combined_df['Session'].astype(str)\n",
    "\n",
    "    ######### Save big dataset for stats ########\n",
    "\n",
    "    filenameOut = f'{folder_to_save}/{NrSubtype}_VigSt_Global.xlsx'\n",
    "    writer = pd.ExcelWriter(filenameOut)\n",
    "    combined_df.to_excel(writer)\n",
    "    writer.close()\n",
    "\n",
    "    ######### Save the SubStates Ca correlation matrix   ########\n",
    "\n",
    "    dfs6_per_sheet = {sheet_name: df.groupby(df.index).sum() for sheet_name, df in dfs6_per_sheet.items()} #cause was concatenated in the 0 axis\n",
    "    dfs6_per_sheet=divide_keys(dfs6_per_sheet, 1, 2)\n",
    "    for sheet_name, df in dfs6_per_sheet.items():\n",
    "        df = df.sort_index(axis=1)\n",
    "        df = df.sort_index(axis=0)\n",
    "        dfs6_per_sheet[sheet_name]=df\n",
    "\n",
    "    if saveexcel:\n",
    "        file_path = f'{folder_to_save}/{NrSubtype}_SubSt_CaCorr.xlsx'\n",
    "        with pd.ExcelWriter(file_path) as writer:        \n",
    "            for sheet_name, df in dfs6_per_sheet.items():\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "\n",
    "    filenameOut = f'{folder_to_save}/{NrSubtype}_SubSt_CaCorr.pkl'\n",
    "    with open(filenameOut, 'wb') as pickle_file:\n",
    "        pickle.dump(dfs6_per_sheet, pickle_file)\n",
    "\n",
    "    ######### Save the Ca correlation matrix   ########\n",
    "\n",
    "    dfs2_per_sheet = {sheet_name: df.groupby(df.index).sum() for sheet_name, df in dfs2_per_sheet.items()} #cause was concatenated in the 0 axis\n",
    "    dfs2_per_sheet=divide_keys(dfs2_per_sheet, 2, 3)\n",
    "    for sheet_name, df in dfs2_per_sheet.items():\n",
    "        df = df.sort_index(axis=1)\n",
    "        df = df.sort_index(axis=0)\n",
    "        dfs2_per_sheet[sheet_name]=df\n",
    "\n",
    "    if saveexcel:\n",
    "        file_path = f'{folder_to_save}/{NrSubtype}_VigSt_CaCorr.xlsx'\n",
    "        with pd.ExcelWriter(file_path) as writer:        \n",
    "            for sheet_name, df in dfs2_per_sheet.items():\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "\n",
    "    filenameOut = f'{folder_to_save}/{NrSubtype}_VigSt_CaCorr.pkl'\n",
    "    with open(filenameOut, 'wb') as pickle_file:\n",
    "        pickle.dump(dfs2_per_sheet, pickle_file)\n",
    "\n",
    "    ######### Save the Sp correlation matrix  ########\n",
    "\n",
    "    dfs3_per_sheet = {sheet_name: df.groupby(df.index).sum() for sheet_name, df in dfs3_per_sheet.items()}\n",
    "    dfs3_per_sheet=divide_keys(dfs3_per_sheet, 2, 3)\n",
    "    for sheet_name, df in dfs3_per_sheet.items():\n",
    "        df = df.sort_index(axis=1)\n",
    "        df = df.sort_index(axis=0)\n",
    "        dfs3_per_sheet[sheet_name]=df\n",
    "\n",
    "    if saveexcel:    \n",
    "        file_path = f'{folder_to_save}/{NrSubtype}_VigSt_SpCorr.xlsx'\n",
    "        with pd.ExcelWriter(file_path) as writer:        \n",
    "            for sheet_name, df in dfs3_per_sheet.items():\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "\n",
    "    filenameOut = f'{folder_to_save}/{NrSubtype}_VigSt_SpCorr.pkl'\n",
    "    with open(filenameOut, 'wb') as pickle_file:\n",
    "        pickle.dump(dfs3_per_sheet, pickle_file)\n",
    "\n",
    "    ####### Save the TOT Ca correlation matrix  ########\n",
    "\n",
    "    dfs4_per_sheet = {sheet_name: df.groupby(df.index).sum() for sheet_name, df in dfs4_per_sheet.items()} #cause was concatenated in the 0 axis\n",
    "    dfs4_per_sheet=divide_keys(dfs4_per_sheet, 2, 3)\n",
    "    for sheet_name, df in dfs4_per_sheet.items():\n",
    "        df = df.sort_index(axis=1)\n",
    "        df = df.sort_index(axis=0)\n",
    "        dfs4_per_sheet[sheet_name]=df\n",
    "\n",
    "    if saveexcel:\n",
    "        with pd.ExcelWriter(file_path) as writer:  \n",
    "            file_path = f'{folder_to_save}/{NrSubtype}_Tot_CaCorr.xlsx'      \n",
    "            for sheet_name, df in dfs4_per_sheet.items():\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "\n",
    "    filenameOut = f'{folder_to_save}/{NrSubtype}_Tot_CaCorr.pkl'\n",
    "    with open(filenameOut, 'wb') as pickle_file:\n",
    "        pickle.dump(dfs4_per_sheet, pickle_file)\n",
    "\n",
    "    ######### Save the TOT Sp correlation matrix   ########\n",
    "\n",
    "    dfs5_per_sheet = {sheet_name: df.groupby(df.index).sum() for sheet_name, df in dfs5_per_sheet.items()}\n",
    "    dfs5_per_sheet=divide_keys(dfs5_per_sheet, 2, 3)\n",
    "    for sheet_name, df in dfs5_per_sheet.items():\n",
    "        df = df.sort_index(axis=1)\n",
    "        df = df.sort_index(axis=0)\n",
    "        dfs5_per_sheet[sheet_name]=df\n",
    "\n",
    "    if saveexcel:   \n",
    "        file_path = f'{folder_to_save}/{NrSubtype}_Tot_SpCorr.xlsx' \n",
    "        with pd.ExcelWriter(file_path) as writer:        \n",
    "            for sheet_name, df in dfs5_per_sheet.items():\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "\n",
    "    filenameOut = f'{folder_to_save}/{NrSubtype}_Tot_SpCorr.pkl'\n",
    "    with open(filenameOut, 'wb') as pickle_file:\n",
    "        pickle.dump(dfs5_per_sheet, pickle_file)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "            # SCRIPT 24AB_Load&Stats_for_VigilanceStates\n",
    "########################################################################\n",
    "\n",
    "AllProportionVigStates=pd.DataFrame()\n",
    "AllDurationVigStates=pd.DataFrame()\n",
    "AllTotDurationVigStates=pd.DataFrame()\n",
    "\n",
    "for NrSubtype in NrSubtypeList:\n",
    "\n",
    "    analysisfile='VigSt_Global'\n",
    "    combined_dfO = pd.read_excel(f'{folder_to_save}/{NrSubtype}_{analysisfile}.xlsx', index_col=0)\n",
    "    \n",
    "    analysisfileCa='VigSt_CaCorr'\n",
    "    with open(f'{folder_to_save}/{NrSubtype}_{analysisfileCa}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfCa = pickle.load(pickle_file)\n",
    "\n",
    "    analysisfileSp='VigSt_SpCorr'\n",
    "    with open(f'{folder_to_save}/{NrSubtype}_{analysisfileSp}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfSp = pickle.load(pickle_file)   \n",
    "        \n",
    "    analysisfileCa='Tot_CaCorr'\n",
    "    with open(f'{folder_to_save}/{NrSubtype}_{analysisfileCa}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfCaTot = pickle.load(pickle_file)\n",
    "\n",
    "    analysisfileSp='Tot_SpCorr'\n",
    "    with open(f'{folder_to_save}/{NrSubtype}_{analysisfileSp}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfSpTot = pickle.load(pickle_file)\n",
    "    \n",
    "    analysisfileCa='SubSt_CaCorr'\n",
    "    with open(f'{folder_to_save}/{NrSubtype}_{analysisfileCa}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfCaSub = pickle.load(pickle_file)\n",
    "\n",
    "\n",
    "    ######################\n",
    "    # CHOOSE OPTIONS\n",
    "    ######################\n",
    "\n",
    "    # MINIMUM VIG STATES DURATION #\n",
    "    combined_df = combined_dfO[combined_dfO['DurationSubstate'] >= 20] \n",
    "    \n",
    "    Drugs= ['Baseline', 'CGP'] if DrugExperiment else ['Baseline']\n",
    "\n",
    "    # NO LOW FIRING RATE #\n",
    "    #combined_df = combined_df[combined_df['Avg_SpikeActivityHz'] >= 0.05] \n",
    "    \n",
    "    #####################\n",
    "    # SELECTIVITY INDEX #\n",
    "    #####################\n",
    "\n",
    "    # /!/ The ones from Baseline (not CGP)\n",
    "\n",
    "    combined_df_Drug=combined_df.copy()\n",
    "    combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == 'Baseline']\n",
    "    AllBaselineUnits = combined_df_Drug['Unit_ID'].unique()\n",
    "    \n",
    "    # Compute selectivity index \n",
    "    AresultActivity_perUnit = combined_df_Drug.pivot_table(index='Unit_ID', columns='Substate', values='NormalizedAUC_calcium', aggfunc='mean')   \n",
    "    try : AresultActivity_perUnit = AresultActivity_perUnit[desired_order]\n",
    "    except: pass\n",
    "    AresultActivity_perUnit['Activated_by'] = AresultActivity_perUnit.apply(max_column_name, axis=1)\n",
    "    AresultActivity_perUnit['RatioNREM_REM'] =discrimination_index(AresultActivity_perUnit)\n",
    "    lower_threshold = -0.5 \n",
    "    upper_threshold = .5 \n",
    "    REMspeunits = AresultActivity_perUnit[AresultActivity_perUnit['RatioNREM_REM'] <= lower_threshold].index\n",
    "    NREMspeunits = AresultActivity_perUnit[AresultActivity_perUnit['RatioNREM_REM'] >= upper_threshold].index\n",
    "    NotSpeunits = AresultActivity_perUnit[(AresultActivity_perUnit['RatioNREM_REM'] > lower_threshold) & (AresultActivity_perUnit['RatioNREM_REM'] < upper_threshold)].index\n",
    "    \"\"\"\n",
    "    dfclusterpath= \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/ClusterAnalysis_dfL1-2.csv\" if NrSubtype=='L1' else \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/ClusterAnalysis_dfL23-2.csv\"\n",
    "    dfcluster=pd.read_csv(dfclusterpath, index_col=0)\n",
    "    Cluster0untis = dfcluster[dfcluster['Cluster'] ==0].index\n",
    "    Cluster1untis = dfcluster[dfcluster['Cluster'] ==1].index\n",
    "    \"\"\"\n",
    "\n",
    "    # Only keep units that appears in CGP & Baseline\n",
    "    \n",
    "    if DrugExperiment>=1 :\n",
    "        combined_df_CGP=combined_df.copy()\n",
    "        combined_df_CGP = combined_df_CGP[combined_df_CGP['Drug'] == 'CGP'] \n",
    "        AllCGPUnits = combined_df_CGP['Unit_ID'].unique()\n",
    "        AllBaselineUnits= np.intersect1d(AllBaselineUnits,AllCGPUnits) # not equal to the sum of spe & non spe unit cause no need to have REM & NREM sleep recorded\n",
    "        REMspeunits=np.intersect1d(REMspeunits, AllBaselineUnits)\n",
    "        NREMspeunits=np.intersect1d(NREMspeunits, AllBaselineUnits)\n",
    "        NotSpeunits=np.intersect1d(NotSpeunits, AllBaselineUnits)\n",
    "        \"\"\"\n",
    "        AllBaselineUnits= np.intersect1d(AllBaselineUnits,AllCGPUnits)\n",
    "        Cluster0untis= np.intersect1d(Cluster0untis,AllBaselineUnits)\n",
    "        Cluster1untis= np.intersect1d(Cluster1untis,AllBaselineUnits)\n",
    "        \"\"\"\n",
    "\n",
    "    # Save the List of significant Unit more active in one vigilance state\n",
    "    if NrSubtype=='L1':\n",
    "        os.makedirs(f'{folder_to_save}/Baseline/')\n",
    "\n",
    "    filenameOut = f'{folder_to_save}/Baseline/{NrSubtype}_ActivityPreference.xlsx'\n",
    "    writer = pd.ExcelWriter(filenameOut)    \n",
    "    AllBaselineUnitsDF = pd.DataFrame(AllBaselineUnits)\n",
    "    REMspeunitsDF = pd.DataFrame(REMspeunits)\n",
    "    NREMspeunitsDF = pd.DataFrame(NREMspeunits)\n",
    "    NotSpeunitsDF = pd.DataFrame(NotSpeunits)\n",
    "    AllBaselineUnitsDF.to_excel(writer, sheet_name='AllBaselineUnits', index=True, header=False) \n",
    "    REMspeunitsDF.to_excel(writer, sheet_name='REMspe', index=True, header=False) \n",
    "    NREMspeunitsDF.to_excel(writer, sheet_name='NREMspe', index=True, header=False) \n",
    "    NotSpeunitsDF.to_excel(writer, sheet_name='NotSpe', index=True, header=False)\n",
    "    \"\"\" \n",
    "    AllBaselineUnitsDF = pd.DataFrame(AllBaselineUnits)\n",
    "    Cluster0untisDF= pd.DataFrame(Cluster0untis)\n",
    "    Cluster1untisDF= pd.DataFrame(Cluster1untis)\n",
    "    AllBaselineUnitsDF.to_excel(writer, sheet_name='AllBaselineUnits', index=True, header=False) \n",
    "    Cluster0untisDF.to_excel(writer, sheet_name='Cluster0untis', index=True, header=False) \n",
    "    Cluster1untisDF.to_excel(writer, sheet_name='Cluster1untis', index=True, header=False) \n",
    "    \"\"\"\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    for Drug in Drugs:\n",
    "        \"\"\"\n",
    "        # /!/ The ones from the drug!!!! \n",
    "        combined_df_Drug=combined_df.copy()\n",
    "        combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == Drug]\n",
    "        AllBaselineUnits = combined_df_Drug['Unit_ID'].unique()\n",
    "        \n",
    "        # Compute selectivity index \n",
    "        AresultActivity_perUnit = combined_df_Drug.pivot_table(index='Unit_ID', columns='Substate', values='NormalizedAUC_calcium', aggfunc='mean')   \n",
    "        try : AresultActivity_perUnit = AresultActivity_perUnit[desired_order]\n",
    "        except: pass\n",
    "        AresultActivity_perUnit['Activated_by'] = AresultActivity_perUnit.apply(max_column_name, axis=1)\n",
    "        AresultActivity_perUnit['RatioNREM_REM'] =discrimination_index(AresultActivity_perUnit)\n",
    "        lower_threshold = -0.5 \n",
    "        upper_threshold = .5 \n",
    "        REMspeunits = AresultActivity_perUnit[AresultActivity_perUnit['RatioNREM_REM'] <= lower_threshold].index\n",
    "        NREMspeunits = AresultActivity_perUnit[AresultActivity_perUnit['RatioNREM_REM'] >= upper_threshold].index\n",
    "        NotSpeunits = AresultActivity_perUnit[(AresultActivity_perUnit['RatioNREM_REM'] > lower_threshold) & (AresultActivity_perUnit['RatioNREM_REM'] < upper_threshold)].index\n",
    "\"\"\"\n",
    "        combined_df_DrugO=combined_dfO.copy() # no min vig states durations == for vig states stats\n",
    "        combined_df_DrugO = combined_df_DrugO[combined_df_DrugO['Drug'] == Drug] \n",
    "\n",
    "        combined_df_Drug=combined_df.copy()\n",
    "        combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == Drug] \n",
    "        AllUnits= combined_df_Drug['Unit_ID'].unique()\n",
    "\n",
    "        folder_to_save2= f'{folder_to_save}/{Drug}/'\n",
    "        if NrSubtype=='L1' and Drug=='CGP':\n",
    "            os.makedirs(folder_to_save2)\n",
    "        \n",
    "        List_SignFiringPreference=[NREMspeunits, REMspeunits, NotSpeunits, AllBaselineUnits, AllUnits] if DrugExperiment else [NREMspeunits, REMspeunits, NotSpeunits, AllUnits] #NREMprefUnits, REMprefUnits, WakeprefUnits] \n",
    "        SecondaryList=[REMspeunits, NotSpeunits, NREMspeunits, AllBaselineUnits, AllUnits] if DrugExperiment else [REMspeunits, NotSpeunits, NREMspeunits, AllUnits] #NREMprefUnits, REMprefUnits, WakeprefUnits] \n",
    "        List_Names=['NREMspe','REMspe','NotSpe', 'AllBaselineUnits', 'All'] if DrugExperiment else ['NREMspe','REMspe','NotSpe', 'All'] #'NREMpref', 'REMpref', 'Wakepref' ] \n",
    "        SecondaryList_Names=['REMspe','NotSpe','NREMspe', 'AllBaselineUnits', 'All'] if DrugExperiment else ['REMspe','NotSpe','NREMspe', 'All'] #'NREMpref', 'REMpref', 'Wakepref' ] \n",
    "        \"\"\"\n",
    "        List_SignFiringPreference=[Cluster0untis, Cluster1untis, AllBaselineUnits, AllUnits] if DrugExperiment else [Cluster0untis, Cluster1untis, AllUnits]\n",
    "        SecondaryList=[Cluster1untis, Cluster0untis, AllBaselineUnits, AllUnits] if DrugExperiment else [Cluster1untis, Cluster0untis, AllUnits]\n",
    "        List_Names=['Cluster0untis', 'Cluster1untis', 'AllBaselineUnits', 'All']if DrugExperiment else ['Cluster0untis', 'Cluster1untis', 'All']\n",
    "        SecondaryList_Names=['Cluster1untis', 'Cluster0untis', 'AllBaselineUnits', 'All' ] if DrugExperiment else ['Cluster1untis', 'Cluster0untis', 'All']\n",
    "        \"\"\"\n",
    "        for listnb, listI  in enumerate(List_SignFiringPreference):\n",
    "            \n",
    "            filtered_df = combined_df_Drug[combined_df_Drug['Unit_ID'].isin(listI)]\n",
    "            List_name=List_Names[listnb]\n",
    "            SecondaryList_name=SecondaryList_Names[listnb]\n",
    "            listII=SecondaryList[listnb]\n",
    "\n",
    "            filtered_df_AllDrug = combined_df[combined_df['Unit_ID'].isin(listI)]\n",
    "            filenameOut = f'{folder_to_save}/GLM_{NrSubtype}_{List_name}_VigSt_Global.xlsx'\n",
    "            writer = pd.ExcelWriter(filenameOut)\n",
    "            filtered_df_AllDrug.to_excel(writer)\n",
    "            writer.close()\n",
    "\n",
    "            if NrSubtype=='L1':\n",
    "                new_folder= f\"{folder_to_save2}/{List_name}/\"\n",
    "                os.makedirs(new_folder)\n",
    "\n",
    "            if Drug==Drug: #'Baseline':\n",
    "                \n",
    "                #####################\n",
    "                # AUC CALCIUM #\n",
    "                #####################\n",
    "\n",
    "                resultNormalizedAUC_calcium_perUnit = filtered_df.pivot_table(index='Unit_ID', columns=[filtered_df['Substate'],filtered_df['Session']], values='NormalizedAUC_calcium', aggfunc='mean')   \n",
    "                try : resultNormalizedAUC_calcium_perUnit = resultNormalizedAUC_calcium_perUnit[desired_order]\n",
    "                except: pass\n",
    "                resultNormalizedAUC_calcium_perUnit['Activated_by'] = resultNormalizedAUC_calcium_perUnit.apply(max_column_name, axis=1)\n",
    "                resultNormalizedAUC_calcium_perUnit['RatioNREM_REM'] =discrimination_index(resultNormalizedAUC_calcium_perUnit)\n",
    "\n",
    "                filenameOutAUC = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_nAUC.xlsx'\n",
    "                resultNormalizedAUC_calcium_perUnit.to_excel(filenameOutAUC)\n",
    "\n",
    "                if Drug == 'Baseline':\n",
    "                    BaselineResultNormalizedAUC=resultNormalizedAUC_calcium_perUnit\n",
    "\n",
    "                proportions = resultNormalizedAUC_calcium_perUnit['Activated_by'].value_counts(normalize=True)*100\n",
    "\n",
    "                resultNormalizedAUC_calcium_perMouse = filtered_df.pivot_table(index='Mice', columns='Substate', values='NormalizedAUC_calcium', aggfunc='mean')\n",
    "                try: resultNormalizedAUC_calcium_perMouse = resultNormalizedAUC_calcium_perMouse[desired_order]\n",
    "                except: pass\n",
    "                filenameOutAUCM = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_AUC_perMouse.xlsx'\n",
    "                resultNormalizedAUC_calcium_perMouse.to_excel(filenameOutAUCM)\n",
    "\n",
    "                #####################\n",
    "                # DECONV ACTIVITY #\n",
    "                #####################\n",
    "                \"\"\"\n",
    "                resultSpikeActivity_perUnit = filtered_df.pivot_table(index='Unit_ID', columns='Substate', values='DeconvSpikeMeanActivity', aggfunc='mean')    \n",
    "                try: resultSpikeActivity_perUnit = resultSpikeActivity_perUnit[desired_order]\n",
    "                except: pass\n",
    "                resultSpikeActivity_perUnit['Activated_by'] = resultSpikeActivity_perUnit.apply(max_column_name, axis=1)\n",
    "\n",
    "                # Save  df\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_DeconvSpike.xlsx'\n",
    "                writer = pd.ExcelWriter(filenameOut)\n",
    "                resultSpikeActivity_perUnit.to_excel(writer)\n",
    "                writer.close()\n",
    "\n",
    "                resultSpikeActivity_perMouse = filtered_df.pivot_table(index='Mice', columns='Substate', values='DeconvSpikeMeanActivity', aggfunc='mean')\n",
    "                try: resultSpikeActivity_perMouse = resultSpikeActivity_perMouse[desired_order]\n",
    "                except: pass\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_DeconvSpike_perMouse.xlsx'\n",
    "                writer = pd.ExcelWriter(filenameOut)\n",
    "                resultSpikeActivity_perMouse.to_excel(writer)\n",
    "                writer.close()\n",
    "\n",
    "                \n",
    "                proportions = resultSpikeActivity_perUnit['Activated_by'].value_counts(normalize=True)*100\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_ActivityVigSt_DeconvSpike_proportions.xlsx'\n",
    "                writer = pd.ExcelWriter(filenameOut)\n",
    "                proportions.to_excel(writer)\n",
    "                writer.close()\n",
    "                \"\"\"\n",
    "\n",
    "                #####################    \n",
    "                # POPULATION COUPLING #\n",
    "                #####################\n",
    "\n",
    "                CaPopCoupling_perUnit = filtered_df.pivot_table(index='Unit_ID', columns='Substate', values='Z_CaPopCoupling', aggfunc='mean')\n",
    "                try: CaPopCoupling_perUnit = CaPopCoupling_perUnit[desired_order]\n",
    "                except: pass\n",
    "                # Save CaPopCoupling_perUnit\n",
    "                filenameOutCaPopCoupling = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_Z_CaPopCoupling.xlsx'\n",
    "                writerCaPopCoupling = pd.ExcelWriter(filenameOutCaPopCoupling)\n",
    "                CaPopCoupling_perUnit.to_excel(writerCaPopCoupling)\n",
    "                writerCaPopCoupling.close()\n",
    "                \n",
    "                \n",
    "                CaPopCoupling_perUnit = filtered_df.pivot_table(index='Unit_ID', columns=[filtered_df['Substate'], filtered_df['Session']], values='Z_CaPopCoupling', aggfunc='mean')   \n",
    "                try : CaPopCoupling_perUnit = CaPopCoupling_perUnit[desired_order]\n",
    "                except: pass\n",
    "\n",
    "                filenameOutAUC = f'{folder_to_save2}/{List_name}/{NrSubtype}_VarAcrossVigSt_CaPopCoup.xlsx'\n",
    "                CaPopCoupling_perUnit.to_excel(filenameOutAUC)\n",
    "\n",
    "        if DrugExperiment:\n",
    "            resultNormalizedAUC_calcium_perUnit = resultNormalizedAUC_calcium_perUnit.rename(columns={'Wake': 'CGP Wake', 'NREM': 'CGP NREM', 'REM': 'CGP REM', 'Activated_by':'CGP Activated_by', 'RatioNREM_REM':'CGP RatioNREM_REM'})\n",
    "            mergeRes=pd.concat([BaselineResultNormalizedAUC,resultNormalizedAUC_calcium_perUnit], axis=1)\n",
    "            filenameOut = f'{folder_to_save}/{NrSubtype}_SelectivityIndex.xlsx'\n",
    "            mergeRes.to_excel(filenameOut)\n",
    "\n",
    "    #######################\n",
    "    # Propreties VigStates\n",
    "    #######################\n",
    "\n",
    "    filenameOut = f'{folder_to_save}/VigStPropreties.xlsx'\n",
    "    writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "    combined_df2 = combined_dfO.drop_duplicates(subset='Substate_ID', keep='first')\n",
    "\n",
    "    DurationVigStates = combined_df2.pivot_table(index='Session_ID', columns=[combined_df2['Drug'], combined_df2['Substate']], values='DurationSubstate', aggfunc='mean', fill_value=None)\n",
    "    try: DurationVigStates = DurationVigStates[desired_order]\n",
    "    except: pass        \n",
    "    AllDurationVigStates=pd.concat([AllDurationVigStates, DurationVigStates], axis=0)\n",
    "\n",
    "    TotDurationVigStates = combined_df2.pivot_table(index='Session_ID', columns=[combined_df2['Drug'], combined_df2['Substate']], values='DurationSubstate', aggfunc='sum', fill_value=None)\n",
    "    try: TotDurationVigStates = TotDurationVigStates[desired_order]\n",
    "    except: pass\n",
    "    AllTotDurationVigStates=pd.concat([AllTotDurationVigStates, TotDurationVigStates], axis=0)\n",
    "\n",
    "AllDurationVigStates.to_excel(writer, sheet_name=f'MeanEpisodeDurations')\n",
    "AllTotDurationVigStates.to_excel(writer, sheet_name=f'TotalEpisodeDurations')\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultNormalizedAUC_calcium_perUnit = combined_df_Drug.pivot_table(index='Unit_ID', columns=[combined_df_Drug['Substate'],combined_df_Drug['Session']], values='NormalizedAUC_calcium', aggfunc='mean')   \n",
    "A=(resultNormalizedAUC_calcium_perUnit['NREM']-resultNormalizedAUC_calcium_perUnit['REM'])/(resultNormalizedAUC_calcium_perUnit['NREM']+resultNormalizedAUC_calcium_perUnit['REM'])\n",
    "A = A[A.notna().sum(axis=1)>1]\n",
    "A['first_non_nan'] = A.bfill(axis=1).iloc[:, 0]\n",
    "A['last_non_nan'] = A.ffill(axis=1).iloc[:, -2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian311new2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
