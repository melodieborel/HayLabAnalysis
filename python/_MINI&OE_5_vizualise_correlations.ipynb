{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93cc96b",
   "metadata": {},
   "source": [
    "# Vizualise correlations & cell assemblies activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38784a29",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "from scipy import fftpack\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "from ephyviewer import AnalogSignalSourceWithScatter\n",
    "import ephyviewer\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "from itertools import groupby\n",
    "import sys \n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "from scipy import stats\n",
    "import matplotlib.colors as mcolors\n",
    "import warnings\n",
    "from scipy import interpolate\n",
    "import re\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import ks_2samp\n",
    "import diptest\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import ast\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef8488",
   "metadata": {},
   "source": [
    "### Correlation across vigilance states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dfilepath either from a previous run or from a previous notebook\n",
    "    %store -r dfilepath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "dfilepath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/\"\n",
    "\n",
    "fc1 = FileChooser(dfilepath,select_default=True, show_only_dirs = False, title = \"<b>Load excel or pkl file</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dfilepath\n",
    "    dfilepath = chooser.selected\n",
    "    %store dfilepath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a002fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    combined_df = pd.read_excel(dfilepath, index_col=0 , sheet_name=None)\n",
    "except:\n",
    "    with open(dfilepath, 'rb') as pickle_file:\n",
    "        combined_df = pickle.load(pickle_file)\n",
    "        \n",
    "# dfilepath=\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis/AVG_VigSt_2025-04-17_15_22_48_TEST/Baseline/Cluster0units/L1NDNF_mice_VigSt_PairCorrCa_Cluster0units.xlsx\"\n",
    "everysheat=1\n",
    "nbplot=int(len(combined_df)/everysheat)\n",
    "fig, axes = plt.subplots(1, nbplot, figsize=(15, 5))\n",
    "axes = np.atleast_1d(axes)  # Makes axes indexable even if it's just one\n",
    "VMAX=1\n",
    "VMIN=-.2\n",
    "\n",
    "plotnb=0\n",
    "\n",
    "for i in np.arange(len(combined_df))[::everysheat]:\n",
    "    key = list(combined_df)[i]\n",
    "        \n",
    "    CaCorrMatrix=combined_df[key]\n",
    "    df = CaCorrMatrix.apply(pd.to_numeric, errors='coerce')\n",
    "    ax = sns.heatmap(df, ax=axes[plotnb], square=True, vmin=VMIN , vmax=VMAX , cmap='viridis',\n",
    "                                    cbar_kws={'shrink': 0.6, 'aspect': 20})\n",
    "    \n",
    "    try:\n",
    "        # Set only the first and last ticks for x and y axes\n",
    "        # Get the number of ticks\n",
    "        x_ticks = ax.get_xticks()\n",
    "        y_ticks = ax.get_yticks()\n",
    "        ax.set_xticks([x_ticks[0], x_ticks[-1]])\n",
    "        ax.set_yticks([y_ticks[0], y_ticks[-1]])\n",
    "\n",
    "        # Optionally, set the labels for these ticks if needed\n",
    "        ax.set_xticklabels([f'#{int(x_ticks[0])+1}', f'#{int(x_ticks[-1])+1}'],size=6)\n",
    "        ax.set_yticklabels([f'#{int(y_ticks[0])+1}', f'#{int(y_ticks[-1])+1}'],size=6)\n",
    "    except: pass\n",
    "\n",
    "    # Optionally, add labels for the axes if needed\n",
    "    ax.set_xlabel('Neurons', labelpad=-2,size=8) \n",
    "    ax.set_ylabel('Neurons', labelpad=-8,size=8) \n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=6)  # Adjust the font size here\n",
    "    cbar.set_label('Correlation coefficient (r)', fontsize=8, font='Arial', rotation=-90, labelpad=10)\n",
    "    ax.xaxis.set_ticks_position('top')  # Move ticks to the top\n",
    "    ax.xaxis.set_label_position('top')  # Move label to the top\n",
    "    axes[plotnb].set_title(f'{key} (r={(np.round(np.nanmean(CaCorrMatrix),2))})', fontsize=12)\n",
    "    plotnb+=1\n",
    "\n",
    "\n",
    "#plt.savefig(f'C:/Users/Manip2/Documents/ElifePaper/Rawdata/Extract{mice}_{folder_base.parts[-2]}_3VigSt_{beg}to{fin}s_2heatmap.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8d562",
   "metadata": {},
   "source": [
    "### Cell assemblies activity across vigilance states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71041a",
   "metadata": {},
   "source": [
    "Plot Cell assembly activity relative to Vig States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfilepath=\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/VigSt_2025-05-03_10_01_32/CellAssembly_Global.pkl\"\n",
    "dfilepath=\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis/VigSt_2025-05-21_15_47_42_CGP/CellAssembly_Global.pkl\"\n",
    "\n",
    "drug= 'baseline'\n",
    "\n",
    "try :\n",
    "    combined_df0 = pd.read_excel(dfilepath, index_col=0)\n",
    "except:\n",
    "    with open(dfilepath, 'rb') as pickle_file:\n",
    "        combined_df0 = pickle.load(pickle_file)\n",
    "\n",
    "combined_df00=combined_df0.copy()\n",
    "combined_df00['Cells_in_Assembly']=combined_df00['Cells_in_Assembly'] = combined_df00['Cells_in_Assembly'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "combined_df00 = combined_df00[combined_df00['Cells_in_Assembly'].apply(len) == combined_df00['Assembly_size']]\n",
    "try :\n",
    "    combined_df00.to_excel(dfilepath)\n",
    "except:\n",
    "    with open(dfilepath, 'wb') as pickle_file:\n",
    "        pickle.dump(combined_df00, pickle_file)\n",
    "\n",
    "NrSubtype='L2_3_mice' # L1NDNF_mice OR L2_3_mice\n",
    "combined_df= combined_df00[combined_df00['NeuronType']==NrSubtype]\n",
    "combined_df=combined_df[combined_df['Drug'] == drug]\n",
    "print(NrSubtype)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "combined_df2 = combined_df.pivot_table(index='Assembly_ID', columns=[combined_df['Substate']], values='Avg_Activity', aggfunc='mean', fill_value=None)\n",
    "desired_order = ['AW','QW', 'NREM', 'REM']   \n",
    "try:del combined_df2['undefined']\n",
    "except: pass\n",
    "try:del combined_df2['IS']\n",
    "except: pass\n",
    "try: combined_df2 = combined_df2[desired_order]\n",
    "except: pass\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(combined_df2.columns, combined_df2.values.T, alpha=0.5, linewidth=2)\n",
    "plt.plot(combined_df2.columns, combined_df2.mean(), linewidth=2, color='black')\n",
    "plt.errorbar(combined_df2.columns, combined_df2.mean(), yerr=combined_df2.sem() ,\n",
    "             fmt='o', color='black', capsize=5)\n",
    "plt.ylabel('Avg activity per cell assemblies')\n",
    "plt.title(f'{NrSubtype}, n={len(combined_df2)}, {drug}')\n",
    "plt.tight_layout()\n",
    "\n",
    "groups = [combined_df2[col].dropna().values for col in combined_df2.columns]\n",
    "f_stat, p_value = f_oneway(*groups)\n",
    "print(f\"ANOVA result: F = {f_stat:.3f}, p = {p_value:.3e}\")\n",
    "df_melt = combined_df2.melt(var_name='Substates', value_name='Avg_Activity')\n",
    "df_melt = df_melt.dropna(subset=['Avg_Activity', 'Substates'])\n",
    "df_melt['Avg_Activity'] = pd.to_numeric(df_melt['Avg_Activity'], errors='coerce')\n",
    "tukey = pairwise_tukeyhsd(endog=df_melt['Avg_Activity'], groups=df_melt['Substates'], alpha=0.05)\n",
    "print(tukey.summary())\n",
    "print(len((df_melt)))\n",
    "\n",
    "\n",
    "combined_df2 = combined_df.pivot_table(index='Assembly_ID', columns=[combined_df['Substate']], values='EventFreq', aggfunc='mean', fill_value=None)\n",
    "try:del combined_df2['undefined']\n",
    "except: pass\n",
    "try:del combined_df2['IS']\n",
    "except: pass\n",
    "try: combined_df2 = combined_df2[desired_order]\n",
    "except: pass\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(combined_df2.columns, combined_df2.values.T, alpha=0.5, linewidth=2)\n",
    "plt.plot(combined_df2.columns, combined_df2.mean(), linewidth=2, color='black')\n",
    "plt.errorbar(combined_df2.columns, combined_df2.mean(), yerr=combined_df2.sem() ,\n",
    "             fmt='o', color='black', capsize=5)\n",
    "plt.ylabel('Event frequency per cell assemblies')\n",
    "\n",
    "groups = [combined_df2[col].dropna().values for col in combined_df2.columns]\n",
    "f_stat, p_value = f_oneway(*groups)\n",
    "print(f\"ANOVA result: F = {f_stat:.3f}, p = {p_value:.3e}\")\n",
    "df_melt = combined_df2.melt(var_name='Substates', value_name='EventFreq')\n",
    "df_melt = df_melt.dropna(subset=['EventFreq', 'Substates'])\n",
    "df_melt['EventFreq'] = pd.to_numeric(df_melt['EventFreq'], errors='coerce')\n",
    "tukey = pairwise_tukeyhsd(endog=df_melt['EventFreq'], groups=df_melt['Substates'], alpha=0.05)\n",
    "print(tukey.summary())\n",
    "print(len((df_melt)))\n",
    "\n",
    "NrSubtype='L1NDNF_mice' # L1NDNF_mice OR L2_3_mice\n",
    "print(NrSubtype)\n",
    "combined_df= combined_df00[combined_df00['NeuronType']==NrSubtype]\n",
    "#combined_df=combined_df[combined_df['Drug'] == drug]\n",
    "\n",
    "combined_df2 = combined_df.pivot_table(index='Assembly_ID', columns=[combined_df['Substate']], values='Avg_Activity', aggfunc='mean', fill_value=None)\n",
    "try:del combined_df2['undefined']\n",
    "except: pass\n",
    "try:del combined_df2['IS']\n",
    "except: pass\n",
    "try: combined_df2 = combined_df2[desired_order]\n",
    "except: pass\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(combined_df2.columns, combined_df2.values.T, alpha=0.5, linewidth=2)\n",
    "plt.plot(combined_df2.columns, combined_df2.mean(), linewidth=2, color='black')\n",
    "plt.errorbar(combined_df2.columns, combined_df2.mean(), yerr=combined_df2.sem() ,\n",
    "             fmt='o', color='black', capsize=5)\n",
    "plt.ylabel('Avg activity per cell assemblies')\n",
    "plt.title(f'{NrSubtype}, n={len(combined_df2)}, {drug}')\n",
    "plt.tight_layout()\n",
    "\n",
    "groups = [combined_df2[col].dropna().values for col in combined_df2.columns]\n",
    "f_stat, p_value = f_oneway(*groups)\n",
    "print(len((df_melt)))\n",
    "print(f\"ANOVA result: F = {f_stat:.3f}, p = {p_value:.3e}\")\n",
    "df_melt = combined_df2.melt(var_name='Substates', value_name='Avg_Activity')\n",
    "df_melt = df_melt.dropna(subset=['Avg_Activity', 'Substates'])\n",
    "df_melt['Avg_Activity'] = pd.to_numeric(df_melt['Avg_Activity'], errors='coerce')\n",
    "tukey = pairwise_tukeyhsd(endog=df_melt['Avg_Activity'], groups=df_melt['Substates'], alpha=0.05)\n",
    "print(tukey.summary())\n",
    "\n",
    "\n",
    "combined_df2 = combined_df.pivot_table(index='Assembly_ID', columns=[combined_df['Substate']], values='EventFreq', aggfunc='mean', fill_value=None)\n",
    "try:del combined_df2['undefined']\n",
    "except: pass\n",
    "try:del combined_df2['IS']\n",
    "except: pass\n",
    "try: combined_df2 = combined_df2[desired_order]\n",
    "except: pass\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(combined_df2.columns, combined_df2.values.T, alpha=0.5, linewidth=2)\n",
    "plt.plot(combined_df2.columns, combined_df2.mean(), linewidth=2, color='black')\n",
    "plt.errorbar(combined_df2.columns, combined_df2.mean(), yerr=combined_df2.sem() ,\n",
    "             fmt='o', color='black', capsize=5)\n",
    "plt.ylabel('Event frequency per cell assemblies')\n",
    "plt.tight_layout()\n",
    "\n",
    "groups = [combined_df2[col].dropna().values for col in combined_df2.columns]\n",
    "f_stat, p_value = f_oneway(*groups)\n",
    "print(f\"ANOVA result: F = {f_stat:.3f}, p = {p_value:.3e}\")\n",
    "df_melt = combined_df2.melt(var_name='Substates', value_name='EventFreq')\n",
    "df_melt = df_melt.dropna(subset=['EventFreq', 'Substates'])\n",
    "df_melt['EventFreq'] = pd.to_numeric(df_melt['EventFreq'], errors='coerce')\n",
    "tukey = pairwise_tukeyhsd(endog=df_melt['EventFreq'], groups=df_melt['Substates'], alpha=0.05)\n",
    "print(tukey.summary())\n",
    "print(len((df_melt)))\n",
    "plt.savefig(f'C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure2_revised/CellAssembly_VigStActivity_{drug}.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba658cd2",
   "metadata": {},
   "source": [
    "### Cell assembly identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4c635",
   "metadata": {},
   "source": [
    "Load VigSt_Global_cluster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7046e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{Path(dfilepath).parent}/VigStates_Global_cluster.pkl', 'rb') as pickle_file:\n",
    "    df_cluster = pickle.load(pickle_file)\n",
    "\n",
    "df_cluster = df_cluster[df_cluster['NeuronType'] == 'L1NDNF_mice']\n",
    "df_cluster_Drug = df_cluster.copy()\n",
    "\n",
    "#df_cluster_Drug = df_cluster_Drug[df_cluster_Drug['Drug'] == 'baseline']\n",
    "\n",
    "AllBaselineUnits = df_cluster_Drug['Unit_ID'].unique()\n",
    "Cluster0units = df_cluster_Drug[df_cluster_Drug['ClusterHDBSCAN'] == 0]['Unit_ID'].unique()\n",
    "Cluster1units = df_cluster_Drug[df_cluster_Drug['ClusterHDBSCAN'] == 1]['Unit_ID'].unique()\n",
    "Cluster2units = df_cluster_Drug[df_cluster_Drug['ClusterHDBSCAN'] == 2]['Unit_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de062dec",
   "metadata": {},
   "source": [
    "Identify Cell assembly Cluster ID and test proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup: Individuals and clusters\n",
    "new_df2 = combined_df.drop_duplicates(subset='Assembly_ID', keep='first')\n",
    "new_df2 = new_df2[new_df2['Cells_in_Assembly'].apply(len) == new_df2['Assembly_size']]\n",
    "groups = new_df2['Cells_in_Assembly'].tolist()\n",
    "df_unique = df_cluster_Drug.drop_duplicates(subset='Unit_ID', keep='first')\n",
    "df_unique = df_unique.dropna(subset=['ClusterHDBSCAN'])\n",
    "ids=df_unique['Unit_ID'].tolist()\n",
    "id_to_cluster = dict(zip(df_unique['Unit_ID'], np.floor(df_unique['ClusterHDBSCAN']).astype(str)))\n",
    "cluster_labels = ['0.0']*len(Cluster0units) + ['1.0']*len(Cluster1units) + ['2.0']*len(Cluster2units)\n",
    "#cluster_labels = new_df2_c['Assembly_Cluster_ID'].tolist()\n",
    "\n",
    "def classify_groups(groups, id_to_cluster):\n",
    "    labels = []\n",
    "    for group in groups:\n",
    "        clusters = [id_to_cluster.get(i, np.nan) for i in group]\n",
    "        if len(clusters) >= 1:\n",
    "            count = Counter(clusters)\n",
    "            top, n_top = count.most_common(1)[0]\n",
    "            top_clusters = [k for k, v in count.items() if v == n_top]        \n",
    "            # If there are multiple top clusters or the majority is less than 50%, label as \"mixte\"\n",
    "            if len(top_clusters) == 1 and (n_top / len(group) * 100) > 50 and not pd.isna(top):\n",
    "                labels.append(top)\n",
    "            else:\n",
    "                labels.append(\"mixte\")  \n",
    "        else:\n",
    "            labels.append(\"mixte\")    \n",
    "    return labels\n",
    "\n",
    "# --- Observed classification\n",
    "observed_labels = classify_groups(groups, id_to_cluster)\n",
    "observed_counts = Counter(observed_labels)\n",
    "new_df2['Assembly_Cluster_ID']= observed_labels\n",
    "\n",
    "# --- Permutation test\n",
    "n_perms = 5000\n",
    "null_dists = defaultdict(list)\n",
    "\n",
    "for _ in range(n_perms):\n",
    "    # Shuffle cluster labels across individuals\n",
    "    shuffled_clusters = dict(zip(ids, random.sample(cluster_labels, len(cluster_labels))))\n",
    "    shuffled_labels = classify_groups(groups, shuffled_clusters)\n",
    "    counts = Counter(shuffled_labels)\n",
    "    for label in observed_counts:\n",
    "        null_dists[label].append(counts.get(label, 0))\n",
    "\n",
    "# --- Z-scores and p-values\n",
    "results = []\n",
    "for label in observed_counts:\n",
    "    obs = observed_counts[label]\n",
    "    null = null_dists[label]\n",
    "    mean = np.mean(null)\n",
    "    std = np.std(null)\n",
    "    z = (obs - mean) / std if std > 0 else 0\n",
    "    # Two-tailed p-value\n",
    "    p = (np.sum(np.abs(np.array(null) - mean) >= abs(obs - mean)) + 1) / (n_perms + 1)\n",
    "    results.append((label, obs, mean, std, z, p))\n",
    "\n",
    "# --- Output\n",
    "print(\"\\nAssembly Cluster ID Distribution Test\")\n",
    "print(f\"{'ID':>10} {'Obs':>5} {'Mean':>7} {'Std':>7} {'Z':>6} {'p-value':>8}\")\n",
    "for label, obs, mean, std, z, p in sorted(results, key=lambda x: x[-1]):\n",
    "    print(f\"{label:>10} {obs:5} {mean:7.2f} {std:7.2f} {z:6.2f} {p:8.4f}\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"Cell_Assembly_ID\", \"Obs\", \"PermMean\", \"Std\", \"Z\", \"p\"])\n",
    "df['Obs_prop'] = df['Obs'] / df['Obs'].sum() *100\n",
    "df['Perm_prop'] = df['PermMean'] / df['PermMean'].sum() *100\n",
    "df[\"Perm_std\"] = df[\"Std\"] / df[\"PermMean\"].sum() *100\n",
    "\n",
    "df = df.sort_values(\"Cell_Assembly_ID\")  # or use a custom order\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.errorbar(df[\"Cell_Assembly_ID\"], df[\"Perm_prop\"], yerr=df[\"Perm_std\"], fmt='o', color='gray', label='Permuted Â± std')\n",
    "plt.scatter(df[\"Cell_Assembly_ID\"], df[\"Obs_prop\"], color='black', label='Observed')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.ylim(0, 100)\n",
    "plt.title(\"Observed vs Permuted Proportions\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure2_revised/CellAssembly_Proportion_permvsreal_{drug}.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2dff61",
   "metadata": {},
   "source": [
    "Save cell assembly ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(combined_df0, new_df2[['Assembly_ID', 'Assembly_Cluster_ID']], on='Assembly_ID', how='outer')\n",
    "merged.to_excel(f'{Path(dfilepath).parent}/CellAssembly_Global_cluster_ID.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9965d2",
   "metadata": {},
   "source": [
    "Activity of cell assemblies per ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[merged['Substate'] != 'IS']\n",
    "merged = merged[merged['Substate'] != 'undefined']\n",
    "combined_df2 = merged.pivot_table(index='Assembly_ID', columns=[merged['Assembly_Cluster_ID'], merged['Substate']], values='Avg_Activity', aggfunc='mean', fill_value=None)\n",
    "custom_order = ['AW', 'QW', 'NREM', 'REM']\n",
    "sort_key = {val: i for i, val in enumerate(custom_order)}\n",
    "sorted_cols = sorted(combined_df2.columns, key=lambda x: (x[0], sort_key.get(x[1], float('inf'))))\n",
    "combined_df2 = combined_df2[sorted_cols]\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "for idx, row in combined_df2.iterrows():\n",
    "    plt.plot(row.values, label=f'{idx}', alpha=0.5, linewidth=2)  # `idx` is the MultiIndex for each row\n",
    "plt.ylabel('Avg activity per cell assemblies')\n",
    "plt.tight_layout()\n",
    "plt.xticks(ticks= np.arange(len(combined_df2.columns.get_level_values(1))),  labels=combined_df2.columns.get_level_values(1)) \n",
    "plt.title('Cluster0                Cluster1                Cluster2                   Mixte')\n",
    "\n",
    "\n",
    "combined_df2 = merged.pivot_table(index='Assembly_ID', columns=[merged['Assembly_Cluster_ID'], merged['Substate']], values='EventFreq', aggfunc='mean', fill_value=None)\n",
    "custom_order = ['AW', 'QW', 'NREM', 'REM']\n",
    "sort_key = {val: i for i, val in enumerate(custom_order)}\n",
    "sorted_cols = sorted(combined_df2.columns, key=lambda x: (x[0], sort_key.get(x[1], float('inf'))))\n",
    "combined_df2 = combined_df2[sorted_cols]\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "for idx, row in combined_df2.iterrows():\n",
    "    plt.plot(row.values, label=f'{idx}', alpha=0.5, linewidth=2)  # `idx` is the MultiIndex for each row\n",
    "plt.ylabel('Event frequency per cell assemblies')\n",
    "plt.tight_layout()\n",
    "plt.xticks(ticks= np.arange(len(combined_df2.columns.get_level_values(1))),  labels=combined_df2.columns.get_level_values(1)) \n",
    "plt.title('Cluster0                Cluster1                Cluster2                   Mixte')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure2_revised/{NrSubtype}_.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c16a0",
   "metadata": {},
   "source": [
    "### Cell assemblies activity around oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/\"\n",
    "DrugExperiment=0\n",
    "all_expe_types=['postCGP'] if DrugExperiment else ['baseline', 'preCGP']\n",
    "AHmethod=0\n",
    "\n",
    "CA_PFC_L2_3_mice=pd.DataFrame()\n",
    "CA_PFC_L2_3_mice_n=pd.DataFrame()\n",
    "CA_PFC_L1NDNF_mice=pd.DataFrame()\n",
    "CA_PFC_L1NDNF_mice_n=pd.DataFrame()\n",
    "CA_PFC_L1NDNF_mice_m=pd.DataFrame()\n",
    "CA_PFC_L1NDNF_mice_0=pd.DataFrame()\n",
    "CA_PFC_L1NDNF_mice_1=pd.DataFrame()\n",
    "CA_PFC_L1NDNF_mice_2=pd.DataFrame()\n",
    "\n",
    "CA_S1_L2_3_mice=pd.DataFrame()\n",
    "CA_S1_L2_3_mice_n=pd.DataFrame()\n",
    "CA_S1_L1NDNF_mice=pd.DataFrame()\n",
    "CA_S1_L1NDNF_mice_n=pd.DataFrame()\n",
    "CA_S1_L1NDNF_mice_m=pd.DataFrame()\n",
    "CA_S1_L1NDNF_mice_0=pd.DataFrame()\n",
    "CA_S1_L1NDNF_mice_1=pd.DataFrame()\n",
    "CA_S1_L1NDNF_mice_2=pd.DataFrame()\n",
    "\n",
    "CA_S1PFC_L2_3_mice=pd.DataFrame()\n",
    "CA_S1PFC_L2_3_mice_n=pd.DataFrame()\n",
    "CA_S1PFC_L1NDNF_mice=pd.DataFrame()\n",
    "CA_S1PFC_L1NDNF_mice_n=pd.DataFrame()\n",
    "CA_S1PFC_L1NDNF_mice_m=pd.DataFrame()\n",
    "CA_S1PFC_L1NDNF_mice_0=pd.DataFrame()\n",
    "CA_S1PFC_L1NDNF_mice_1=pd.DataFrame()\n",
    "CA_S1PFC_L1NDNF_mice_2=pd.DataFrame()\n",
    "\n",
    "CA_SWR_L2_3_mice=pd.DataFrame()\n",
    "CA_SWR_L2_3_mice_n=pd.DataFrame()\n",
    "CA_SWR_L1NDNF_mice=pd.DataFrame()\n",
    "CA_SWR_L1NDNF_mice_n=pd.DataFrame()\n",
    "CA_SWR_L1NDNF_mice_m=pd.DataFrame()\n",
    "CA_SWR_L1NDNF_mice_0=pd.DataFrame()\n",
    "CA_SWR_L1NDNF_mice_1=pd.DataFrame()\n",
    "CA_SWR_L1NDNF_mice_2=pd.DataFrame()\n",
    "\n",
    "window = [-5, 5]  # from -10s to +10s around each event\n",
    "bin_width = 0.1\n",
    "bins = np.arange(window[0], window[1] + bin_width, bin_width)\n",
    "\n",
    "dfilepath=\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis/VigSt_2025-05-21_15_47_42_CGP/CellAssembly_Global_cluster_ID.xlsx\"\n",
    "try :\n",
    "    cellassemblydf0 = pd.read_excel(dfilepath, index_col=0)\n",
    "except:\n",
    "    with open(dfilepath, 'rb') as pickle_file:\n",
    "        cellassemblydf0 = pickle.load(pickle_file)\n",
    "\n",
    "for dpath in Path(dir).glob('**/mappingsAB.pkl'):\n",
    "    \n",
    "    mappfile = open(dpath.parents[0]/ f'mappingsAB.pkl', 'rb')\n",
    "    mapping = pickle.load(mappfile)\n",
    "    mapping_sess = mapping['session']   \n",
    "\n",
    "    mice = dpath.parents[0].parts[-1]\n",
    "    NeuronType = dpath.parents[1].parts[-1]\n",
    "    \n",
    "    subsessions = []\n",
    "    dict_S1PFCprop = {}\n",
    "    dict_Spindleprop = {}\n",
    "    dict_Path={}\n",
    "\n",
    "    minian_folders = [f for f in dpath.parents[0].rglob('minian') if f.is_dir()]\n",
    "\n",
    "    for minianpath in minian_folders: # for each minian folders found in this mouse\n",
    "\n",
    "        if any(p in all_expe_types for p in minianpath.parts): # have to be to the expe_types\n",
    "                        \n",
    "            session=minianpath.parents[0].name if len(minianpath.parts)==12 else minianpath.parents[1].name.split(\"_\")[-1]\n",
    "            session_path=minianpath.parents[2] if len(minianpath.parts)==12 else minianpath.parents[1]\n",
    "            expe_type=minianpath.parents[3].name if len(minianpath.parts)==12 else minianpath.parents[2].name\n",
    "            \n",
    "            session_date= minianpath.parents[2].name.split(\"_\")[0] if len(minianpath.parts)==12 else minianpath.parents[1].name.split(\"_\")[0]\n",
    "            session_time= minianpath.parents[2].name.split(\"_\")[1] if len(minianpath.parts)==12 else minianpath.parents[1].name.split(\"_\")[1]\n",
    "\n",
    "            drug='CGP' if expe_type == 'postCGP' else 'baseline'\n",
    "            dict_Path[session] = session_path\n",
    "            \n",
    "            SWRlist= pd.read_csv(session_path / f'OpenEphys/SWRproperties.csv' ) if AHmethod else pd.read_csv(session_path / f'OpenEphys/SWR_finedetection.csv' ) \n",
    "            SWRlist['toKeep'] = 'True' # SWRlist['toKeep'].astype(str)\n",
    "            SWRprop = SWRlist[SWRlist['toKeep'].isin(['VRAI', 'True'])]\n",
    "            \n",
    "            startSWRlist=SWRprop[\"start time\"]/1000\n",
    "            merged = cellassemblydf0.groupby(['Mice', 'Session_Date','Session_Time', 'Assembly_ID', 'Assembly_Cluster_ID'], dropna=False)['EventTime'].apply(lambda x: ', '.join(x)).reset_index() \n",
    "            for ass in merged.loc[(merged['Mice'] == mice) & (merged['Session_Date'] == session_date) & (merged['Session_Time'] == session_time)].index:\n",
    "                CA_SWR_matrix=locals()[f\"CA_SWR_{NeuronType}_{str(merged['Assembly_Cluster_ID'].loc[ass])[0]}\"]\n",
    "                CA_SWR_matrix2=locals()[f\"CA_SWR_{NeuronType}\"]\n",
    "                COUNT=[]\n",
    "                numbers = re.findall(r'[\\d.]+',  merged['EventTime'].loc[ass])\n",
    "                events = np.array(numbers, dtype=float)\n",
    "                if len(events)>0:\n",
    "                    for SWRstart in startSWRlist:                        \n",
    "                        relativedistance= SWRstart-events\n",
    "                        counts, _ = np.histogram(relativedistance, bins=bins)                  \n",
    "                        COUNT.append(counts)                               \n",
    "                    CA_SWR_matrix[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.nanmean(COUNT, axis=0)\n",
    "                    CA_SWR_matrix2[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.nanmean(COUNT, axis=0)\n",
    "                else: \n",
    "                    CA_SWR_matrix[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.zeros(len(bins)-1)\n",
    "                    CA_SWR_matrix2[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.zeros(len(bins)-1)\n",
    "                \n",
    "\n",
    "            \n",
    "            Spdllist = pd.read_csv(session_path / f'OpenEphys/Spindleproperties_S1&PFC.csv') if AHmethod else pd.read_csv(session_path / f'OpenEphys/SpindlesS1&PFC_finedetection.csv' ) \n",
    "            Spdllist['toKeep'] = 'True' # Spdllist['toKeep'].astype(str)\n",
    "            Spdlprop  = Spdllist[Spdllist['toKeep'].isin(['VRAI', 'True'])]\n",
    "\n",
    "            S1Spdlprop= Spdlprop[Spdlprop['CTX']=='S1']\n",
    "            S1PFCSpdlprop= Spdlprop[Spdlprop['CTX']=='S1PFC']\n",
    "            PFCSpdlprop= Spdlprop[Spdlprop['CTX']=='PFC']\n",
    "            \n",
    "            startPFClist=PFCSpdlprop[\"start time\"]/1000\n",
    "            merged = cellassemblydf0.groupby(['Mice', 'Session_Date','Session_Time', 'Assembly_ID', 'Assembly_Cluster_ID'], dropna=False)['EventTime'].apply(lambda x: ', '.join(x)).reset_index() \n",
    "            for ass in merged.loc[(merged['Mice'] == mice) & (merged['Session_Date'] == session_date) & (merged['Session_Time'] == session_time)].index:\n",
    "                CA_PFC_matrix=locals()[f\"CA_PFC_{NeuronType}_{str(merged['Assembly_Cluster_ID'].loc[ass])[0]}\"]\n",
    "                CA_PFC_matrix2=locals()[f\"CA_PFC_{NeuronType}\"]\n",
    "                COUNT=[]\n",
    "                numbers = re.findall(r'[\\d.]+',  merged['EventTime'].loc[ass])\n",
    "                events = np.array(numbers, dtype=float)\n",
    "                if len(events)>0:\n",
    "                    for spdlstart in startPFClist:                        \n",
    "                        relativedistance= spdlstart-events\n",
    "                        counts, _ = np.histogram(relativedistance, bins=bins)                  \n",
    "                        COUNT.append(counts)                               \n",
    "                    CA_PFC_matrix[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.nanmean(COUNT, axis=0)\n",
    "                    CA_PFC_matrix2[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.nanmean(COUNT, axis=0)\n",
    "                else: \n",
    "                    CA_PFC_matrix[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.zeros(len(bins)-1)\n",
    "                    CA_PFC_matrix2[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.zeros(len(bins)-1)\n",
    "                \n",
    "            \n",
    "            startS1list=S1Spdlprop[\"start time\"]/1000\n",
    "            merged = cellassemblydf0.groupby(['Mice', 'Session_Date','Session_Time', 'Assembly_ID', 'Assembly_Cluster_ID'], dropna=False)['EventTime'].apply(lambda x: ', '.join(x)).reset_index() \n",
    "            for ass in merged.loc[(merged['Mice'] == mice) & (merged['Session_Date'] == session_date) & (merged['Session_Time'] == session_time)].index:\n",
    "                CA_S1_matrix=locals()[f\"CA_S1_{NeuronType}_{str(merged['Assembly_Cluster_ID'].loc[ass])[0]}\"]\n",
    "                CA_S1_matrix2=locals()[f\"CA_S1_{NeuronType}\"]\n",
    "                COUNT=[]\n",
    "                numbers = re.findall(r'[\\d.]+',  merged['EventTime'].loc[ass])\n",
    "                events = np.array(numbers, dtype=float)\n",
    "                if len(events)>0:\n",
    "                    for spdlstart in startS1list:                        \n",
    "                        relativedistance= spdlstart-events\n",
    "                        counts, _ = np.histogram(relativedistance, bins=bins)                  \n",
    "                        COUNT.append(counts)                               \n",
    "                    CA_S1_matrix[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.nanmean(COUNT, axis=0)\n",
    "                    CA_S1_matrix2[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.nanmean(COUNT, axis=0)\n",
    "                else: \n",
    "                    CA_S1_matrix[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.zeros(len(bins)-1)\n",
    "                    CA_S1_matrix2[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.zeros(len(bins)-1)\n",
    "\n",
    "            \n",
    "            startS1PFClist=S1PFCSpdlprop[\"start time\"]/1000\n",
    "            merged = cellassemblydf0.groupby(['Mice', 'Session_Date','Session_Time', 'Assembly_ID', 'Assembly_Cluster_ID'], dropna=False)['EventTime'].apply(lambda x: ', '.join(x)).reset_index() \n",
    "            for ass in merged.loc[(merged['Mice'] == mice) & (merged['Session_Date'] == session_date) & (merged['Session_Time'] == session_time)].index:\n",
    "                CA_S1PFC_matrix=locals()[f\"CA_S1PFC_{NeuronType}_{str(merged['Assembly_Cluster_ID'].loc[ass])[0]}\"]\n",
    "                CA_S1PFC_matrix2=locals()[f\"CA_S1PFC_{NeuronType}\"]\n",
    "                COUNT=[]\n",
    "                numbers = re.findall(r'[\\d.]+',  merged['EventTime'].loc[ass])\n",
    "                events = np.array(numbers, dtype=float)\n",
    "                if len(events)>0:\n",
    "                    for spdlstart in startS1PFClist:                        \n",
    "                        relativedistance= spdlstart-events\n",
    "                        counts, _ = np.histogram(relativedistance, bins=bins)                  \n",
    "                        COUNT.append(counts)                               \n",
    "                    CA_S1PFC_matrix[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.nanmean(COUNT, axis=0)\n",
    "                    CA_S1PFC_matrix2[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.nanmean(COUNT, axis=0)\n",
    "                else: \n",
    "                    CA_S1PFC_matrix[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.zeros(len(bins)-1)\n",
    "                    CA_S1PFC_matrix2[merged['Assembly_ID'].loc[ass]+ '_' + str(merged['Assembly_Cluster_ID'].loc[ass])[0]]=np.zeros(len(bins)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f2bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_matrix_all = ['CA_S1PFC_L2_3_mice', 'CA_S1PFC_L1NDNF_mice', 'CA_S1_L2_3_mice', 'CA_S1_L1NDNF_mice', 'CA_PFC_L2_3_mice', 'CA_PFC_L1NDNF_mice', 'CA_SWR_L2_3_mice', 'CA_SWR_L1NDNF_mice']#, 'CA_S1PFC_L1NDNF_mice_n', 'CA_S1PFC_L1NDNF_mice_m',                      'CA_S1PFC_L1NDNF_mice_0', 'CA_S1PFC_L1NDNF_mice_1', 'CA_S1PFC_L1NDNF_mice_2']\n",
    "label_colors = {    'n': 'white',    'm': 'grey',    '0': 'blue',     '1': 'cyan',     '2': 'green'}\n",
    "drug='CGP' if DrugExperiment else 'baseline'\n",
    "\n",
    "plt.close()\n",
    "for CA_SWR_matrix_name in CA_matrix_all: \n",
    "    CA_SWR_matrix= locals()[CA_SWR_matrix_name]\n",
    "    CA_SWR_matrix_n = CA_SWR_matrix/ CA_SWR_matrix.max() \n",
    "    CA_SWR_matrix_n = CA_SWR_matrix_n.replace(np.nan, 0)\n",
    "    max_row_pos = CA_SWR_matrix_n.values.argmax(axis=0)\n",
    "    col_sums = CA_SWR_matrix_n.sum()\n",
    "    col_info = pd.DataFrame({'col': CA_SWR_matrix_n.columns,'max_pos': max_row_pos,'sum': col_sums.values})\n",
    "    col_info_sorted = col_info.sort_values(by=['max_pos', 'sum'])\n",
    "    CA_SWR_matrix_s = CA_SWR_matrix_n[col_info_sorted['col'].values]\n",
    "    CA_SWR_matrix_s = CA_SWR_matrix_s.loc[:, (CA_SWR_matrix_s != 0).any(axis=0)]\n",
    "    df= CA_SWR_matrix_s.T\n",
    "\n",
    "    # Row label to color index mapping\n",
    "    row_labels = df.index.str[-1]\n",
    "    color_codes = [list(label_colors).index(lbl) for lbl in row_labels]\n",
    "    color_array = np.array(color_codes).reshape(-1, 1)\n",
    "    cmap = ListedColormap([label_colors[k] for k in label_colors])\n",
    "    fig = plt.figure(figsize=(3, 3))\n",
    "    gs = fig.add_gridspec(nrows=2, ncols=2, height_ratios=[3, 2],   width_ratios=[0.5, 10], hspace=0.3, wspace=0.05 )\n",
    "    ax_ann = fig.add_subplot(gs[0, 0])\n",
    "    sns.heatmap(color_array, ax=ax_ann, cmap=cmap, cbar=False)\n",
    "    ax_ann.set_xticks([])\n",
    "    ax_ann.set_yticks([])\n",
    "    ax_ann.tick_params(left=False, right=False)\n",
    "    ax_heatmap = fig.add_subplot(gs[0, 1])\n",
    "    sns.heatmap(df, ax=ax_heatmap, cmap=\"viridis\", cbar=False, cbar_kws={'location': 'top'}, yticklabels=False)\n",
    "    ax_heatmap.set_yticklabels([]) \n",
    "    ax_heatmap.set_title(f\"n = {len(df)}/{len(CA_SWR_matrix_n.T)}\") \n",
    "    ax_ann.set_ylabel(CA_SWR_matrix_name)\n",
    "\n",
    "    time_bins = np.linspace(window[0], window[1], len(bins)-1)\n",
    "    ax_bottom = fig.add_subplot(gs[1, 1])  # span both columns\n",
    "    ax_bottom.plot(time_bins, zscore(np.mean(df, axis=0)))\n",
    "    ax_bottom.set_xlabel(f\"Time from {CA_SWR_matrix_name.split('_')[1]} (s)\")\n",
    "    ax_bottom.set_xticks([])\n",
    "    ax_bottom.set_xlim(window[0], window[1])\n",
    "    ax_bottom.set_ylim(-2.5, 5)\n",
    "\n",
    "    # Monte Carlo parameters\n",
    "    n_permutations = 5000\n",
    "    shuffled_psths = []\n",
    "    for _ in range(n_permutations):\n",
    "        shuffled_counts = np.apply_along_axis(np.random.permutation, 1, df)\n",
    "        shuffled_psth = shuffled_counts.mean(axis=0)\n",
    "        shuffled_psths.append(shuffled_psth)\n",
    "    shuffled_psths = np.array(shuffled_psths)\n",
    "    alpha = 0.05\n",
    "    lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "    upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "    significant_bins05 = (np.mean(df, axis=0) < lower_bound) | (np.mean(df, axis=0) > upper_bound)\n",
    "    ax_bottom.scatter(time_bins[significant_bins05], np.linspace(4, 4, len(time_bins))[significant_bins05], marker='_', s=5, color= 'r')\n",
    "    plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure4_revised/CellAssembly_Heatmap_{CA_SWR_matrix_name.split('_')[2]}_{CA_SWR_matrix_name.split('_')[1]}_{drug}.svg\", format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
