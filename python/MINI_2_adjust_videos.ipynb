{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "import subprocess\n",
    "import os\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import display, Video, clear_output \n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dpath either from a previous run or from a previous notebook\n",
    "    %store -r dpath\n",
    "    #dpath=dpath.parent\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    dpath = \"//10.69.168.1/crnldata/forgetting/\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Go inside the folder containing the LFP raw file</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first video\n",
    "video_path = sorted(glob.glob(os.path.join(dpath, \"*.avi\")))[0]\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "# Initialize accumulator\n",
    "avg_frame = np.zeros((height, width, 3), np.float32)\n",
    "\n",
    "# Read and accumulate frames\n",
    "count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    avg_frame += frame.astype(np.float32)\n",
    "    count += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Compute the average frame\n",
    "avg_frame /= count\n",
    "avg_frame = avg_frame.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust brightness and contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase contrast and brightness\n",
    "alpha = 4 # Contrast control (>1 increases contrast)\n",
    "beta = -50   # Brightness control (>0 increases brightness)\n",
    "alpha = 4 # Contrast control (>1 increases contrast)\n",
    "beta = -150   # Brightness control (>0 increases brightness)\n",
    "enhanced_frame = cv2.convertScaleAbs(avg_frame, alpha=alpha, beta=beta)\n",
    "\n",
    "# Convert BGR to RGB for Matplotlib\n",
    "avg_frame_rgb = cv2.cvtColor(avg_frame, cv2.COLOR_BGR2RGB)\n",
    "enhanced_frame_rgb = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(avg_frame_rgb)\n",
    "axes[0].set_title(\"Original Average Frame\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(enhanced_frame_rgb)\n",
    "axes[1].set_title(\"Enhanced Frame (Brightness & Contrast Adjusted)\")\n",
    "axes[1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/BlueLines_session3_2.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(enhanced_frame_rgb)\n",
    "plt.savefig(f'C:/Users/Manip2/Documents/Manuscripts/RedLines_firstsessionJune17th2022.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display video until the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties \n",
    "fps = 30 #cap.get(cv2.CAP_PROP_FPS)\n",
    "speed= 10 # 5 times more rapid\n",
    "\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "mousename=Path(dpath).parents[3].name\n",
    "date=Path(dpath).parents[1].name\n",
    "hour=Path(dpath).parents[0].name\n",
    "datehour=f\"{date} {hour}\"\n",
    "\n",
    "processed_frames=[]\n",
    "\n",
    "# Play video frame by frame with modifications\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Stop if the video ends\n",
    "\n",
    "    # Get the current frame number\n",
    "    frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    frame_position = (10, 30)    # Position for frame in seconds\n",
    "\n",
    "    # Calculate the time in seconds\n",
    "    time_sec = frame_number / fps\n",
    "\n",
    "    # Apply contrast and brightness adjustment\n",
    "    enhanced_frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "\n",
    "    # Define the position for the text (fixed position for frame number and time)\n",
    "    time_position = (10, frame_height - 10)    # Position for time in seconds\n",
    "    fixed_text_position= (380, frame_height - 10)    # Position for time in seconds\n",
    "\n",
    "    # Display the time in seconds\n",
    "    cv2.putText(enhanced_frame, f'{time_sec:.1f} s', time_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(enhanced_frame, f'Speed : x {speed}', fixed_text_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(enhanced_frame, datehour, frame_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Show the enhanced video\n",
    "    cv2.imshow(\"Enhanced Video (Contrast & Brightness Adjusted)\", enhanced_frame)\n",
    "\n",
    "    processed_frames.append(enhanced_frame)\n",
    "\n",
    "    # Press 'q' to exit the video\n",
    "    if cv2.waitKey(round(1/fps*1000/speed)) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the processed video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"output_video.mp4\"  # Define the output file path\n",
    "\n",
    "# Create a VideoWriter object to save the processed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MP4 codec\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps*speed, (frame_width, frame_height))\n",
    "\n",
    "# Save all the processed frames into the output video file\n",
    "for frame in processed_frames:\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the VideoWriter\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a merged video from all .avi files of the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 30 # cap.get(cv2.CAP_PROP_FPS) \n",
    "speed = 3 # times more rapid\n",
    "\n",
    "# Get all .avi files and sort them numerically\n",
    "avi_files = sorted(glob.glob(os.path.join(dpath, \"*.avi\")), key=lambda x: int(os.path.basename(x).split(\".\")[0]))\n",
    "\n",
    "# Check if there are any .avi files\n",
    "if not avi_files:\n",
    "    print(\"No .avi files found in the folder.\")\n",
    "    exit()\n",
    "\n",
    "# Read the first video to get properties\n",
    "first_video = cv2.VideoCapture(avi_files[0])\n",
    "frame_width = int(first_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(first_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(first_video.get(cv2.CAP_PROP_FPS))\n",
    "first_video.release()\n",
    "\n",
    "\n",
    "mousename=Path(dpath).parents[3].name\n",
    "date=Path(dpath).parents[1].name\n",
    "hour=Path(dpath).parents[0].name\n",
    "datehour=f\"{date} {hour}\"\n",
    "\n",
    "\n",
    "# Define the output file\n",
    "#output_file = os.path.join(dpath, \"merged.avi\")\n",
    "#fourcc = cv2.VideoWriter_fourcc(*\"XVID\")  # Codec for AVI format\n",
    "#out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "output_file = os.path.join(dpath, \"merged.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')  # H264 or MP4 codec\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps*speed, (frame_width, frame_height))\n",
    "\n",
    "f = 1\n",
    "tot_time = 0\n",
    "\n",
    "\n",
    "# Process each .avi file\n",
    "for file in avi_files:\n",
    "    cap = cv2.VideoCapture(file)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Calculate the time in seconds\n",
    "        tot_time = f / fps\n",
    "\n",
    "        # Define the position for the text (fixed position for frame number and time)\n",
    "        time_position = (10, frame_height - 10)    # Position for time in seconds\n",
    "        frame_position = (10, 30)    # Position for frame in seconds\n",
    "        fixed_text_position= (380, frame_height - 10)    # Position for time in seconds\n",
    "\n",
    "        # Adjust contrast and brightness\n",
    "        adjusted_frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "        # Flip the frame horizontally\n",
    "        flipped_frame = cv2.flip(adjusted_frame, 1)\n",
    "\n",
    "        # Display the time in seconds\n",
    "        cv2.putText(adjusted_frame, f'{tot_time:.1f} s', time_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(adjusted_frame, f'Speed : x {speed}', fixed_text_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        #cv2.putText(adjusted_frame, f'Frame #{f}', frame_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(adjusted_frame, datehour, frame_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # Write the modified frame\n",
    "        out.write(adjusted_frame)\n",
    "        f += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Release the output video writer\n",
    "out.release()\n",
    "print(f\"Merged video saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an average image of the merged video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(output_file)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "# Initialize accumulator\n",
    "avg_frame = np.zeros((height, width, 3), np.float32)\n",
    "\n",
    "# Read and accumulate frames\n",
    "count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    avg_frame += frame.astype(np.float32)\n",
    "    count += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Compute the average frame\n",
    "avg_frame /= count\n",
    "avg_frame = avg_frame.astype(np.uint8)\n",
    "\n",
    "plt.close()\n",
    "plt.imshow(avg_frame)\n",
    "#plt.savefig(f'C:/Users/Manip2/Documents/Manuscripts/GreenLines_lastsessionJune24th2022.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
