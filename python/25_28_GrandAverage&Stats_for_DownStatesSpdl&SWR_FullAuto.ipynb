{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spdl oscillations analysis...\n",
      "... for L1 neurons...\n",
      "Spdl_Global_BlueLinesOK.pkl\n",
      "Spdl_Global_RedLinesOK.pkl\n",
      "Spdl_Global_BlackLinesOK.pkl\n",
      "Spdl_Global_GreenLinesOK.pkl\n",
      "Spdl_Global_GreenDotsOK.pkl\n",
      "Spdl_Global_BlueLinesOK.pkl\n",
      "Spdl_Global_BlackLinesOK.pkl\n",
      "Spdl_Global_GreenDotsOK.pkl\n",
      "180 L1 neurons recorded\n",
      "179 L1 neurons in the cross-registration\n",
      "2068 Spdl recorded in total\n",
      "Spdl_CaPSTH_Baseline\n",
      "Spdl_CaPSTH_UnCoupledBaseline\n",
      "Spdl_CaPSTH_CoupledBaseline\n",
      "Spdl_CaPSTH_S1Baseline\n",
      "Spdl_CaPSTH_UnCoupledS1Baseline\n",
      "Spdl_CaPSTH_CoupledS1Baseline\n",
      "Spdl_CaPSTH_PFCBaseline\n",
      "Spdl_CaPSTH_UnCoupledPFCBaseline\n",
      "Spdl_CaPSTH_CoupledPFCBaseline\n",
      "Spdl_CaPSTH_S1PFCBaseline\n",
      "Spdl_CaPSTH_UnCoupledS1PFCBaseline\n",
      "Spdl_CaPSTH_CoupledS1PFCBaseline\n",
      "Spdl_SpPSTH_Baseline\n",
      "Spdl_SpPSTH_UnCoupledBaseline\n",
      "Spdl_SpPSTH_CoupledBaseline\n",
      "Spdl_SpPSTH_S1Baseline\n",
      "Spdl_SpPSTH_UnCoupledS1Baseline\n",
      "Spdl_SpPSTH_CoupledS1Baseline\n",
      "Spdl_SpPSTH_PFCBaseline\n",
      "Spdl_SpPSTH_UnCoupledPFCBaseline\n",
      "Spdl_SpPSTH_CoupledPFCBaseline\n",
      "Spdl_SpPSTH_S1PFCBaseline\n",
      "Spdl_SpPSTH_UnCoupledS1PFCBaseline\n",
      "Spdl_SpPSTH_CoupledS1PFCBaseline\n",
      "... for L2&3 neurons...\n",
      "Spdl_Global_ThreeBlueCrossesOK.pkl\n",
      "Spdl_Global_Purple.pkl\n",
      "Spdl_Global_ThreeColDotsOK.pkl\n",
      "Spdl_Global_Purple.pkl\n",
      "538 L2&3 neurons recorded\n",
      "537 L2&3 neurons in the cross-registration\n",
      "1728 Spdl recorded in total\n",
      "Spdl_CaPSTH_Baseline\n",
      "Spdl_CaPSTH_UnCoupledBaseline\n",
      "Spdl_CaPSTH_CoupledBaseline\n",
      "Spdl_CaPSTH_S1Baseline\n",
      "Spdl_CaPSTH_UnCoupledS1Baseline\n",
      "Spdl_CaPSTH_CoupledS1Baseline\n",
      "Spdl_CaPSTH_PFCBaseline\n",
      "Spdl_CaPSTH_UnCoupledPFCBaseline\n",
      "Spdl_CaPSTH_CoupledPFCBaseline\n",
      "Spdl_CaPSTH_S1PFCBaseline\n",
      "Spdl_CaPSTH_UnCoupledS1PFCBaseline\n",
      "Spdl_CaPSTH_CoupledS1PFCBaseline\n",
      "Spdl_SpPSTH_Baseline\n",
      "Spdl_SpPSTH_UnCoupledBaseline\n",
      "Spdl_SpPSTH_CoupledBaseline\n",
      "Spdl_SpPSTH_S1Baseline\n",
      "Spdl_SpPSTH_UnCoupledS1Baseline\n",
      "Spdl_SpPSTH_CoupledS1Baseline\n",
      "Spdl_SpPSTH_PFCBaseline\n",
      "Spdl_SpPSTH_UnCoupledPFCBaseline\n",
      "Spdl_SpPSTH_CoupledPFCBaseline\n",
      "Spdl_SpPSTH_S1PFCBaseline\n",
      "Spdl_SpPSTH_UnCoupledS1PFCBaseline\n",
      "Spdl_SpPSTH_CoupledS1PFCBaseline\n",
      "SWR oscillations analysis...\n",
      "... for L1 neurons...\n",
      "SWR_Global_BlueLinesOK.pkl\n",
      "SWR_Global_GreenDotsOK.pkl\n",
      "SWR_Global_RedLinesOK.pkl\n",
      "SWR_Global_BlackLinesOK.pkl\n",
      "SWR_Global_GreenLinesOK.pkl\n",
      "SWR_Global_BlueLinesOK.pkl\n",
      "SWR_Global_GreenDotsOK.pkl\n",
      "SWR_Global_BlackLinesOK.pkl\n",
      "180 L1 neurons recorded\n",
      "179 L1 neurons in the cross-registration\n",
      "7643 SWR recorded in total\n",
      "SWR_CaPSTH_Baseline\n",
      "SWR_CaPSTH_UnCoupledBaseline\n",
      "SWR_CaPSTH_CoupledBaseline\n",
      "SWR_CaPSTH_S1Baseline\n",
      "SWR_CaPSTH_UnCoupledS1Baseline\n",
      "SWR_CaPSTH_CoupledS1Baseline\n",
      "SWR_CaPSTH_PFCBaseline\n",
      "SWR_CaPSTH_UnCoupledPFCBaseline\n",
      "SWR_CaPSTH_CoupledPFCBaseline\n",
      "SWR_CaPSTH_S1PFCBaseline\n",
      "SWR_CaPSTH_UnCoupledS1PFCBaseline\n",
      "SWR_CaPSTH_CoupledS1PFCBaseline\n",
      "SWR_SpPSTH_Baseline\n",
      "SWR_SpPSTH_UnCoupledBaseline\n",
      "SWR_SpPSTH_CoupledBaseline\n",
      "SWR_SpPSTH_S1Baseline\n",
      "SWR_SpPSTH_UnCoupledS1Baseline\n",
      "SWR_SpPSTH_CoupledS1Baseline\n",
      "SWR_SpPSTH_PFCBaseline\n",
      "SWR_SpPSTH_UnCoupledPFCBaseline\n",
      "SWR_SpPSTH_CoupledPFCBaseline\n",
      "SWR_SpPSTH_S1PFCBaseline\n",
      "SWR_SpPSTH_UnCoupledS1PFCBaseline\n",
      "SWR_SpPSTH_CoupledS1PFCBaseline\n",
      "... for L2&3 neurons...\n",
      "SWR_Global_Purple.pkl\n",
      "SWR_Global_ThreeBlueCrossesOK.pkl\n",
      "SWR_Global_ThreeColDotsOK.pkl\n",
      "SWR_Global_Purple.pkl\n",
      "538 L2&3 neurons recorded\n",
      "537 L2&3 neurons in the cross-registration\n",
      "8822 SWR recorded in total\n",
      "SWR_CaPSTH_Baseline\n",
      "SWR_CaPSTH_UnCoupledBaseline\n",
      "SWR_CaPSTH_CoupledBaseline\n",
      "SWR_CaPSTH_S1Baseline\n",
      "SWR_CaPSTH_UnCoupledS1Baseline\n",
      "SWR_CaPSTH_CoupledS1Baseline\n",
      "SWR_CaPSTH_PFCBaseline\n",
      "SWR_CaPSTH_UnCoupledPFCBaseline\n",
      "SWR_CaPSTH_CoupledPFCBaseline\n",
      "SWR_CaPSTH_S1PFCBaseline\n",
      "SWR_CaPSTH_UnCoupledS1PFCBaseline\n",
      "SWR_CaPSTH_CoupledS1PFCBaseline\n",
      "SWR_SpPSTH_Baseline\n",
      "SWR_SpPSTH_UnCoupledBaseline\n",
      "SWR_SpPSTH_CoupledBaseline\n",
      "SWR_SpPSTH_S1Baseline\n",
      "SWR_SpPSTH_UnCoupledS1Baseline\n",
      "SWR_SpPSTH_CoupledS1Baseline\n",
      "SWR_SpPSTH_PFCBaseline\n",
      "SWR_SpPSTH_UnCoupledPFCBaseline\n",
      "SWR_SpPSTH_CoupledPFCBaseline\n",
      "SWR_SpPSTH_S1PFCBaseline\n",
      "SWR_SpPSTH_UnCoupledS1PFCBaseline\n",
      "SWR_SpPSTH_CoupledS1PFCBaseline\n",
      "DS oscillations analysis...\n",
      "... for L1 neurons...\n",
      "DS_Global_RedLinesOK.pkl\n",
      "DS_Global_GreenLinesOK.pkl\n",
      "DS_Global_BlueLinesOK.pkl\n",
      "DS_Global_GreenDotsOK.pkl\n",
      "DS_Global_BlackLinesOK.pkl\n",
      "DS_Global_BlueLinesOK.pkl\n",
      "DS_Global_GreenDotsOK.pkl\n",
      "DS_Global_BlackLinesOK.pkl\n",
      "180 L1 neurons recorded\n",
      "179 L1 neurons in the cross-registration\n",
      "6044 DS recorded in total\n",
      "DS_CaPSTH_Baseline\n",
      "DS_CaPSTH_UnCoupledBaseline\n",
      "DS_CaPSTH_CoupledBaseline\n",
      "DS_CaPSTH_S1Baseline\n",
      "DS_CaPSTH_UnCoupledS1Baseline\n",
      "DS_CaPSTH_CoupledS1Baseline\n",
      "DS_CaPSTH_PFCBaseline\n",
      "DS_CaPSTH_UnCoupledPFCBaseline\n",
      "DS_CaPSTH_CoupledPFCBaseline\n",
      "DS_CaPSTH_S1PFCBaseline\n",
      "DS_CaPSTH_UnCoupledS1PFCBaseline\n",
      "DS_CaPSTH_CoupledS1PFCBaseline\n",
      "DS_SpPSTH_Baseline\n",
      "DS_SpPSTH_UnCoupledBaseline\n",
      "DS_SpPSTH_CoupledBaseline\n",
      "DS_SpPSTH_S1Baseline\n",
      "DS_SpPSTH_UnCoupledS1Baseline\n",
      "DS_SpPSTH_CoupledS1Baseline\n",
      "DS_SpPSTH_PFCBaseline\n",
      "DS_SpPSTH_UnCoupledPFCBaseline\n",
      "DS_SpPSTH_CoupledPFCBaseline\n",
      "DS_SpPSTH_S1PFCBaseline\n",
      "DS_SpPSTH_UnCoupledS1PFCBaseline\n",
      "DS_SpPSTH_CoupledS1PFCBaseline\n",
      "... for L2&3 neurons...\n",
      "DS_Global_Purple.pkl\n",
      "DS_Global_ThreeColDotsOK.pkl\n",
      "DS_Global_ThreeBlueCrossesOK.pkl\n",
      "DS_Global_Purple.pkl\n",
      "538 L2&3 neurons recorded\n",
      "537 L2&3 neurons in the cross-registration\n",
      "5964 DS recorded in total\n",
      "DS_CaPSTH_Baseline\n",
      "DS_CaPSTH_UnCoupledBaseline\n",
      "DS_CaPSTH_CoupledBaseline\n",
      "DS_CaPSTH_S1Baseline\n",
      "DS_CaPSTH_UnCoupledS1Baseline\n",
      "DS_CaPSTH_CoupledS1Baseline\n",
      "DS_CaPSTH_PFCBaseline\n",
      "DS_CaPSTH_UnCoupledPFCBaseline\n",
      "DS_CaPSTH_CoupledPFCBaseline\n",
      "DS_CaPSTH_S1PFCBaseline\n",
      "DS_CaPSTH_UnCoupledS1PFCBaseline\n",
      "DS_CaPSTH_CoupledS1PFCBaseline\n",
      "DS_SpPSTH_Baseline\n",
      "DS_SpPSTH_UnCoupledBaseline\n",
      "DS_SpPSTH_CoupledBaseline\n",
      "DS_SpPSTH_S1Baseline\n",
      "DS_SpPSTH_UnCoupledS1Baseline\n",
      "DS_SpPSTH_CoupledS1Baseline\n",
      "DS_SpPSTH_PFCBaseline\n",
      "DS_SpPSTH_UnCoupledPFCBaseline\n",
      "DS_SpPSTH_CoupledPFCBaseline\n",
      "DS_SpPSTH_S1PFCBaseline\n",
      "DS_SpPSTH_UnCoupledS1PFCBaseline\n",
      "DS_SpPSTH_CoupledS1PFCBaseline\n"
     ]
    }
   ],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Osc\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=0 # 1 if CGP Experiment, 0 if Baseline Experiment\n",
    "\n",
    "suffix='_AH_newScor'\n",
    "\n",
    "Local=1\n",
    "\n",
    "#choosed_folder='Osc_2024_08_04_10_35_33_AH_FINAL' if DrugExperiment else 'Osc_2024_08_04_09_24_52_AH_FINAL'\n",
    "choosed_folder1='Osc_2024_10_04_10_28_42_AH_newScor' # for Baseline Expe\n",
    "choosed_folder2='Osc_2024_10_04_13_02_59_AH_newScor' # for CGP Expe\n",
    "\n",
    "PrefVigExcel_file = 'AVG_VigSt_2024-10-03_17_36_46_AB_newScor_CGP' if DrugExperiment else 'AVG_VigSt_2024-10-03_16_09_22_AB_newScor'\n",
    "#PrefVigExcel_file = 'AVG_VigSt_2024-08-22_13_50_33_AB_Clustering_forCGP' if DrugExperiment else 'AVG_VigSt_2024-08-22_13_28_19_AB_Clustering'\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import sem\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def column_with_max_single_per_row(row):\n",
    "    max_val = row.max()  # Find the max value in the row\n",
    "    max_columns = row == max_val  # Boolean Series of columns with max value\n",
    "    \n",
    "    if max_columns.sum() > 1:\n",
    "        return 'NoPref'  # More than one column has the max value\n",
    "    else:\n",
    "        return max_columns.idxmax()  # Return the name of the column with max value\n",
    "\n",
    "def divide_keys(data):\n",
    "    it=list(data.keys())[0]\n",
    "    d=data[it]\n",
    "    data[it]=d.replace(0, np.nan)\n",
    "    for sheet in list(data.keys())[1:]: \n",
    "        data[sheet].div(data[it][sheet], axis=0)\n",
    "    del data[it]\n",
    "    return data    \n",
    "\n",
    "########################################################################\n",
    "        # SCRIPT 27AB_GrandAverages&Stats_for_Osc\n",
    "########################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory1 = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\" \n",
    "directory1= f'{InitialDirectory1}/{choosed_folder1}'\n",
    "InitialDirectory2 =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\" if Local else \"/crnldata/waking///L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\"\n",
    "directory2= f'{InitialDirectory2}/{choosed_folder2}'\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/AVG_Osc_{FolderNameSave}{suffix}/\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.ipynb\"\n",
    "destination_file_path = f\"{destination_folder}/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "NrSubtypeList=['L1', 'L2&3']\n",
    "CTX=['', 'S1', 'PFC', 'S1PFC']\n",
    "Coupling=['', 'UnCoupled', 'Coupled']\n",
    "OscList=['Spdl', 'SWR', 'DS']\n",
    "Drugs= ['Baseline', 'CGP'] if DrugExperiment else ['Baseline']\n",
    "\n",
    "for o, Osc in enumerate(OscList): \n",
    "    \n",
    "    print(Osc, 'oscillations analysis...')\n",
    "\n",
    "    AllOscStatut=pd.DataFrame()\n",
    "    AllOscDuration=pd.DataFrame()\n",
    "    AllGlobalSpindle=pd.DataFrame()\n",
    "    AllOscStartLocation=pd.DataFrame()\n",
    "    AllOscSWRinside=pd.DataFrame()\n",
    "    AllOscCoupling=pd.DataFrame()\n",
    "\n",
    "    for NrSubtype in NrSubtypeList: \n",
    "        \n",
    "        print('... for', NrSubtype, 'neurons...')\n",
    "        \n",
    "        # Initialize an empty list to store the dataframes\n",
    "        dfs = []\n",
    "        filtered_df=[]\n",
    "\n",
    "        if NrSubtype=='L1':\n",
    "            MiceList=['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK', 'GreenLinesOK', 'RedLinesOK']\n",
    "        else:\n",
    "            MiceList=['Purple', 'ThreeColDotsOK', 'ThreeBlueCrossesOK']\n",
    "\n",
    "        nametofind=f'{Osc}_Global'\n",
    "\n",
    "        ###########################################################################\n",
    "                                    ##### GLOBAL #####\n",
    "        ###########################################################################\n",
    "\n",
    "        # Recursively traverse the directory structure\n",
    "        for directory in [directory1, directory2]: #both Baseline & CGP experiments \n",
    "            for root, _, files in os.walk(directory):\n",
    "                for filename in files:\n",
    "                    # Check if the file is an Excel file and contains the specified name\n",
    "                    if filename.endswith('.pkl') and nametofind in filename:\n",
    "                        if any(name in filename for name in MiceList):  \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the file and append it to the list\n",
    "                            with open(filepath, 'rb') as pickle_file:\n",
    "                                df = pickle.load(pickle_file)\n",
    "                            dfs.append(df)\n",
    "                            print(filename)\n",
    "\n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(str)\n",
    "        combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "        combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "\n",
    "        combined_df[f'{Osc}Statut'] = combined_df[f'{Osc}Statut'].astype(str)\n",
    "\n",
    "        combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "        combined_df['Session_ID'] = combined_df['Mice'] + combined_df['Session'].astype(str)\n",
    "\n",
    "        unique_count = combined_df['Unit_ID'].nunique()\n",
    "        print(unique_count, f'{NrSubtype} neurons recorded') \n",
    "\n",
    "        # Remove non defined Unique Units \n",
    "        combined_df = combined_df[combined_df['Unique_Unit'] != '[]']\n",
    "        combined_df = combined_df.dropna(subset=['Unique_Unit'])\n",
    "        unique_count = combined_df['Unit_ID'].nunique()\n",
    "        print(unique_count, f'{NrSubtype} neurons in the cross-registration') \n",
    "        \n",
    "        combined_df[f'{Osc}_ID'] = combined_df['Mice'] + combined_df['Session'] + combined_df[f'{Osc}Number'].astype(str)\n",
    "        \n",
    "        unique_count = combined_df[f'{Osc}_ID'].nunique()\n",
    "        print(unique_count, f'{Osc} recorded in total')\n",
    "\n",
    "        filenameOut = f'{folder_to_save}/{NrSubtype}_{Osc}_Global.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "        combined_df.to_excel(writer)\n",
    "        writer.close()\n",
    "\n",
    "        ###########################################################################\n",
    "                                    ##### PSTH #####\n",
    "        ###########################################################################\n",
    "\n",
    "        Data=['Ca', 'Sp']\n",
    "        for data in Data:\n",
    "            for drug in Drugs: \n",
    "                for ctx in CTX:\n",
    "                    for coup in Coupling:  \n",
    "\n",
    "                        #ctx= '' if Osc=='SWR' else ctx  \n",
    "                        \n",
    "                        locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']={}\n",
    "                        dfsPSTH_per_sheet = locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']\n",
    "                        nametofind2=f'{Osc}_{data}PSTH_{coup}{ctx}{drug}'\n",
    "                        print(nametofind2)\n",
    "                        # Recursively traverse the directory structure\n",
    "                        for directory in [directory1, directory2]:\n",
    "                            for root, _, files in os.walk(directory):\n",
    "                                for filename in files:\n",
    "                                    if filename.endswith('.pkl') and nametofind2 in filename: \n",
    "                                        if any(name in filename for name in MiceList): \n",
    "                                            # Construct the full path to the file\n",
    "                                            filepath = os.path.join(root, filename)\n",
    "                                            with open(filepath, 'rb') as pickle_file:\n",
    "                                                df = pickle.load(pickle_file)\n",
    "                                            for key, value in df.items():\n",
    "                                                if key in dfsPSTH_per_sheet:\n",
    "                                                    dfsPSTH_per_sheet[key]=pd.concat([pd.DataFrame(dfsPSTH_per_sheet[key]),pd.DataFrame(value)], ignore_index=False, axis=0)\n",
    "                                                else:\n",
    "                                                    dfsPSTH_per_sheet[key]=pd.DataFrame(value)\n",
    "\n",
    "\n",
    "        ###########################################################################\n",
    "                                ##### PREFERENCE #####\n",
    "        ########################################################################### \n",
    "\n",
    "        for drug in Drugs: \n",
    "            \n",
    "            combined_df_Drug = combined_df.copy()\n",
    "            try:\n",
    "                combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == drug]\n",
    "            except: \n",
    "                combined_df_Drug=combined_df_Drug\n",
    "            \n",
    "            folder_to_save2= f'{folder_to_save}/{drug}/'\n",
    "            if NrSubtype=='L1' and o==0 :\n",
    "                os.makedirs(folder_to_save2)\n",
    "                        \n",
    "            # Load the Excel file and read each sheet into a separate DataFrame\n",
    "            excel_file = f'//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/{PrefVigExcel_file}/Baseline/{NrSubtype}_ActivityPreference.xlsx'\n",
    "            sheets = pd.read_excel(excel_file, sheet_name=None, header=None, index_col=0)  # sheet_name=None reads all sheets\n",
    "            AllUnits=combined_df_Drug['Unit_ID'].unique()\n",
    "            sheets['AllUnits']=pd.DataFrame(AllUnits)\n",
    "\n",
    "            # Print the names of the sheets and their corresponding DataFrames\n",
    "            for List_name, listI in sheets.items():\n",
    "                \n",
    "                thelist=listI[0].tolist() if List_name=='AllUnits' else listI[1].tolist()\n",
    "                filtered_df = combined_df_Drug[combined_df_Drug['Unit_ID'].isin(thelist)]\n",
    "                List_name=List_name.replace( '\\\\', '/')\n",
    "\n",
    "                GroupList=['AllNr', 'PsNr', 'NoModNr', 'NgNr']\n",
    "\n",
    "                if NrSubtype=='L1' :#and o==0:\n",
    "                    new_folder= f\"{folder_to_save2}/{List_name}/{Osc}/\"\n",
    "                    os.makedirs(new_folder)\n",
    "\n",
    "                ###########################################################################\n",
    "                                        ##### AVERAGE PSTH #####\n",
    "                ###########################################################################\n",
    "\n",
    "                for coup in Coupling:\n",
    "                    filenameOutAVG = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}AVG&SEM.xlsx'\n",
    "                    locals()[f'excel_writerAVG{coup}']= pd.ExcelWriter(filenameOutAVG)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}During.xlsx'\n",
    "                    locals()[f'excel_writerMean{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}PSTH.xlsx'\n",
    "                    locals()[f'excel_writer{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "                \n",
    "                for data in Data:\n",
    "                    \n",
    "                    if data=='Ca':\n",
    "                        filenameOutPN = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_NrProportion.xlsx'\n",
    "                        excel_writerPN= pd.ExcelWriter(filenameOutPN)\n",
    "                    \n",
    "                    NbNr=pd.DataFrame()\n",
    "\n",
    "                    for coup in Coupling:  \n",
    "\n",
    "                        BigArray=pd.DataFrame()\n",
    "                        BigArrayBSL=pd.DataFrame()\n",
    "                        AVGArray=pd.DataFrame()\n",
    "                        AVGArrayBSL=pd.DataFrame()\n",
    "                        \n",
    "                        for ctx in CTX:\n",
    "                            \n",
    "                            if f'{data}PSTH{Osc}_{coup}{ctx}{drug}' in locals(): #cause no ctx if uncoupled\n",
    "\n",
    "                                df_per_sheet=locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']\n",
    "\n",
    "                                #filenameOut = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{data}PSTH_{coup}{ctx}_{drug}.pkl' #keep each responses of each cells for all rec Osc\n",
    "                                #with open(filenameOut, 'wb') as pickle_file:\n",
    "                                #    pickle.dump(df_per_sheet, pickle_file)\n",
    "\n",
    "                                if len(df_per_sheet.keys()): # not empty\n",
    "\n",
    "                                    # if PSTH is full lenght\n",
    "                                    arrayLen = 0\n",
    "                                    for key, value in df_per_sheet.items():\n",
    "                                        if value.size > 0:\n",
    "                                            arrayLen = np.shape(value)[1]\n",
    "                                            break  \n",
    "                                    # if PSTH is 2 sec lenght    \n",
    "                                    arrayLen=40\n",
    "                                    \n",
    "                                    for group in GroupList:\n",
    "                                        locals()[f'{group}Array']=pd.DataFrame(columns=np.arange(0,arrayLen,1))\n",
    "                                    \n",
    "                                    for nr in df_per_sheet.keys():\n",
    "                                    \n",
    "                                        if df_per_sheet[nr].shape[0] >= 10 : # at least 10 oscillations recorded\n",
    "                                            \n",
    "                                            if arrayLen==40: # All Osc at 1second \n",
    "                                                if Osc== 'Spdl':\n",
    "                                                    PSTH=df_per_sheet[nr].iloc[:, df_per_sheet[nr].shape[1] // 10 *4  : df_per_sheet[nr].shape[1] // 10 * 6] # -1 to 1 sec for Spdl (-5 to 5s)\n",
    "                                                else:\n",
    "                                                    PSTH=df_per_sheet[nr].iloc[:, df_per_sheet[nr].shape[1] // 6 *2  : df_per_sheet[nr].shape[1] // 6 * 4] # -1 to 1 sec for SWR & DS (-3 to 3s)\n",
    "                                            else: # full lenght\n",
    "                                                PSTH=df_per_sheet[nr]\n",
    "\n",
    "                                            AVGtrace=np.nanmean(PSTH, axis=0)\n",
    "                                            \n",
    "                                            BaselineSTD=np.std(AVGtrace[:PSTH.shape[1]//4], axis=0)\n",
    "\n",
    "                                            upperThrs=np.nanmean(AVGtrace[:PSTH.shape[1]//4], axis=0) + BaselineSTD*2\n",
    "                                            lowerThrs=np.nanmean(AVGtrace[:PSTH.shape[1]//4], axis=0) - BaselineSTD*2\n",
    "\n",
    "                                            AVGbefore=np.nanmean(AVGtrace[PSTH.shape[1]//4:PSTH.shape[1]//4*2], axis=0)\n",
    "                                            AVGearly=np.nanmean(AVGtrace[PSTH.shape[1]//4*2:PSTH.shape[1]//4*3], axis=0)\n",
    "                                            AVGlate=np.nanmean(AVGtrace[PSTH.shape[1]//4*3:PSTH.shape[1]//4*4], axis=0)\n",
    "                                            \n",
    "                                            if AVGearly > upperThrs:\n",
    "                                                group='PsNr'\n",
    "                                            elif AVGearly < lowerThrs:\n",
    "                                                group='NgNr'\n",
    "                                            else: \n",
    "                                                group='NoModNr'\n",
    "                                            \n",
    "                                            Array=locals()[f'{group}Array']\n",
    "                                            Array.loc[nr]=AVGtrace\n",
    "                                            Array=locals()[f'AllNrArray']\n",
    "                                            Array.loc[nr]=AVGtrace\n",
    "\n",
    "                                    for group in GroupList:\n",
    "\n",
    "                                        ArrayO=locals()[f'{group}Array']\n",
    "\n",
    "                                        if not ArrayO.isna().all().all():\n",
    "\n",
    "                                            # Only keep the neurons belonging to the list (All units, NREM active, REM active, etc)\n",
    "                                            present_indices = [idx for idx in thelist if idx in ArrayO.index]\n",
    "                                            Array = ArrayO.loc[present_indices] \n",
    "\n",
    "                                            n=Array.shape[0]\n",
    "                                            NbNr.loc[group,f'{ctx}{coup}']=n\n",
    "\n",
    "                                            # Leave a blanck space for units not recorded in that condition\n",
    "                                            missing_indexes = set(thelist) - set(Array.index)\n",
    "                                            Array = Array.reindex(Array.index.union(missing_indexes))\n",
    "                                            Array = Array.sort_index()\n",
    "\n",
    "                                            ArrayO=Array.copy()\n",
    "                                            mArray=Array.mean(axis=0)\n",
    "                                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                                            #SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray]), columns=[f'{group}{ctx}mean', f'{group}{ctx}sem'])\n",
    "                                        \n",
    "                                            BigArray=pd.concat([BigArray,SmallArray], axis=1)\n",
    "\n",
    "                                            SecondHalf_columns = Array.iloc[:, Array.shape[1] //2:]\n",
    "                                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArray=pd.concat([AVGArray,avgarray], axis=1)\n",
    "                                            \n",
    "                                            # Baseline signals\n",
    "                                            baseline_columns = Array.iloc[:, :Array.shape[1] // 4]\n",
    "                                            mean_baseline = baseline_columns.mean(axis=1)\n",
    "                                            Array = Array.sub(mean_baseline, axis=0)\n",
    "                                        \n",
    "                                            excel_writer=locals()[f'excel_writer{coup}']\n",
    "                                            Array.to_excel(excel_writer, sheet_name=f'{data}BSL_{group}{ctx}', index=True, header=False)\n",
    "                                            ArrayO.to_excel(excel_writer, sheet_name=f'{data}{group}{ctx}', index=True, header=False)\n",
    "\n",
    "                                            mArray=Array.mean(axis=0)\n",
    "                                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                                            #SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray]), columns=[f'{group}{ctx}mean', f'{group}{ctx}sem'])\n",
    "                                            \n",
    "                                            BigArrayBSL=pd.concat([BigArrayBSL,SmallArray], axis=1)\n",
    "\n",
    "                                            SecondHalf_columns = Array.iloc[:, Array.shape[1]//2:]\n",
    "                                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayBSL=pd.concat([AVGArrayBSL,avgarray], axis=1)\n",
    "                                            \n",
    "                        excel_writer=locals()[f'excel_writer{coup}']\n",
    "                        excel_writer.close()\n",
    "                        excel_writerAVGn=locals()[f'excel_writerAVG{coup}']\n",
    "                        excel_writerMeann=locals()[f'excel_writerMean{coup}']\n",
    "                        \n",
    "                        BigArrayBSL = BigArrayBSL.sort_index(axis=1)\n",
    "                        AVGArrayBSL = AVGArrayBSL.sort_index(axis=1)\n",
    "                        BigArrayBSL.to_excel(excel_writerAVGn, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                        AVGArrayBSL.to_excel(excel_writerMeann, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "\n",
    "                        BigArray = BigArray.sort_index(axis=1)\n",
    "                        AVGArray = AVGArray.sort_index(axis=1)\n",
    "                        BigArray.to_excel(excel_writerAVGn, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                        AVGArray.to_excel(excel_writerMeann, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "\n",
    "                    if data=='Ca':\n",
    "                        try: \n",
    "                            NbNr.loc['PsNr %'] = round(NbNr.loc['PsNr'] / NbNr.loc['AllNr'] *100)\n",
    "                            NbNr.loc['NoModNr %'] = round(NbNr.loc['NoModNr'] / NbNr.loc['AllNr'] *100)\n",
    "                            NbNr.loc['NgNr %'] = round(NbNr.loc['NgNr'] / NbNr.loc['AllNr']*100)\n",
    "                        except:                        \n",
    "                            None\n",
    "                        NbNr.to_excel(excel_writerPN, sheet_name=f'{data}', index=True, header=True)\n",
    "                        excel_writerPN.close()\n",
    "\n",
    "                for coup in Coupling:\n",
    "                    excel_writerAVGn=locals()[f'excel_writerAVG{coup}']\n",
    "                    excel_writerMeann=locals()[f'excel_writerMean{coup}']\n",
    "                    excel_writerAVGn.close()                   \n",
    "                    excel_writerMeann.close()                   \n",
    "        \n",
    "        #######################\n",
    "        # Propreties Osc\n",
    "        #######################\n",
    "        filenameOut = f'{folder_to_save}/{Osc}Propreties.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "        combined_dfOsc = combined_df.drop_duplicates(subset=f'{Osc}_ID', keep='first')\n",
    "\n",
    "        if Osc== 'SWR':\n",
    "            Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'SWR_inside_Spdl']])\n",
    "            AllOscSWRinside=pd.concat([AllOscSWRinside, Count], axis=0) \n",
    "            Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}Statut']])\n",
    "            AllOscStatut=pd.concat([AllOscStatut, Count], axis=0)    \n",
    "            OscDuration = combined_dfOsc.pivot_table(index='Mice', columns=[combined_dfOsc['Drug'],combined_dfOsc[f'{Osc}Statut']] , values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)       \n",
    "        elif Osc== 'DS':\n",
    "            OscDuration = combined_dfOsc.pivot_table(index='Mice', columns=[combined_dfOsc['Drug'],combined_dfOsc[f'{Osc}Statut']] , values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}Statut']])\n",
    "            AllOscStatut=pd.concat([AllOscStatut, Count], axis=0)\n",
    "        elif Osc== 'Spdl':\n",
    "            Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'SWR_inside_Spdl']])\n",
    "            AllOscSWRinside=pd.concat([AllOscSWRinside, Count], axis=0) \n",
    "            GlobalSpindle = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle'], combined_dfOsc[f'{Osc}StartLocation']])\n",
    "            AllGlobalSpindle=pd.concat([AllGlobalSpindle, GlobalSpindle], axis=0)\n",
    "            Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'],combined_dfOsc['GlobalSpindle'], combined_dfOsc[f'{Osc}StartLocation']])\n",
    "            AllOscStartLocation=pd.concat([AllOscStartLocation, Count], axis=0)\n",
    "            OscDuration = combined_dfOsc.pivot_table(index='Mice', columns=[combined_dfOsc['Drug'],combined_dfOsc['GlobalSpindle'], combined_dfOsc[f'{Osc}StartLocation']] , values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle'],  combined_dfOsc[f'{Osc}StartLocation'], combined_dfOsc[f'{Osc}Statut']])\n",
    "            AllOscCoupling=pd.concat([AllOscCoupling, Count], axis=0)\n",
    "            Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle'],  combined_dfOsc[f'{Osc}Statut']])\n",
    "            AllOscStatut=pd.concat([AllOscStatut, Count], axis=0)\n",
    "          \n",
    "    AllOscStatut.to_excel(writer, sheet_name=f'CouplingStatut')\n",
    "    AllOscDuration.to_excel(writer, sheet_name=f'MeanDuration')\n",
    "    AllOscSWRinside.to_excel(writer, sheet_name=f'SWR_inside_Spdl')\n",
    "    if Osc== 'Spdl':\n",
    "        AllOscCoupling.to_excel(writer, sheet_name=f'CouplingPerSpdlLoc')    \n",
    "        AllGlobalSpindle.to_excel(writer, sheet_name=f'GlobalSpindle')\n",
    "        AllOscStartLocation.to_excel(writer, sheet_name=f'StartLocation')\n",
    "       \n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian311new2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
