{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spdl oscillations analysis...\n",
      "... for All neurons...\n",
      "... in the PFC\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_Purple.xlsx\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_ThreeColDotsOK.xlsx\n",
      "Spindles_PFC_ABdetection_GlobalResultsAB_Purple.xlsx\n",
      "Spindles_PFC_ABdetection_GlobalResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "Spindles_PFC_ABdetection_GlobalResultsAB_ThreeColDotsOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeAvgResultsAB_Purple.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeAvgResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeAvgResultsAB_ThreeColDotsOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeSumResultsAB_Purple.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeSumResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeSumResultsAB_ThreeColDotsOK.xlsx\n",
      "339 All neurons recorded\n",
      "338 All neurons in the cross-registration\n",
      "690 Spdl recorded in total in the PFC\n",
      "... in the S1\n",
      "Spindles_S1_ABdetection_CalciumAvgResultsAB_Purple.xlsx\n",
      "Spindles_S1_ABdetection_CalciumAvgResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "Spindles_S1_ABdetection_CalciumAvgResultsAB_ThreeColDotsOK.xlsx\n",
      "Spindles_S1_ABdetection_GlobalResultsAB_Purple.xlsx\n",
      "Spindles_S1_ABdetection_GlobalResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "Spindles_S1_ABdetection_GlobalResultsAB_ThreeColDotsOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeAvgResultsAB_Purple.xlsx\n",
      "Spindles_S1_ABdetection_SpikeAvgResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeAvgResultsAB_ThreeColDotsOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeSumResultsAB_Purple.xlsx\n",
      "Spindles_S1_ABdetection_SpikeSumResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeSumResultsAB_ThreeColDotsOK.xlsx\n",
      "310 All neurons recorded\n",
      "309 All neurons in the cross-registration\n",
      "1166 Spdl recorded in total in the S1\n",
      "... for L1 neurons...\n",
      "... in the PFC\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_BlackLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_BlueLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_GreenDotsOK.xlsx\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_GreenLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_RedLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_GlobalResultsAB_BlackLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_GlobalResultsAB_BlueLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_GlobalResultsAB_GreenDotsOK.xlsx\n",
      "Spindles_PFC_ABdetection_GlobalResultsAB_GreenLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_GlobalResultsAB_RedLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeAvgResultsAB_BlackLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeAvgResultsAB_BlueLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeAvgResultsAB_GreenDotsOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeAvgResultsAB_GreenLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeAvgResultsAB_RedLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeSumResultsAB_BlackLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeSumResultsAB_BlueLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeSumResultsAB_GreenDotsOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeSumResultsAB_GreenLinesOK.xlsx\n",
      "Spindles_PFC_ABdetection_SpikeSumResultsAB_RedLinesOK.xlsx\n",
      "130 L1 neurons recorded\n",
      "129 L1 neurons in the cross-registration\n",
      "965 Spdl recorded in total in the PFC\n",
      "... in the S1\n",
      "Spindles_S1_ABdetection_CalciumAvgResultsAB_BlackLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_CalciumAvgResultsAB_BlueLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_CalciumAvgResultsAB_GreenDotsOK.xlsx\n",
      "Spindles_S1_ABdetection_CalciumAvgResultsAB_GreenLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_CalciumAvgResultsAB_RedLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_GlobalResultsAB_BlackLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_GlobalResultsAB_BlueLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_GlobalResultsAB_GreenDotsOK.xlsx\n",
      "Spindles_S1_ABdetection_GlobalResultsAB_GreenLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_GlobalResultsAB_RedLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeAvgResultsAB_BlackLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeAvgResultsAB_BlueLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeAvgResultsAB_GreenDotsOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeAvgResultsAB_GreenLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeAvgResultsAB_RedLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeSumResultsAB_BlackLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeSumResultsAB_BlueLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeSumResultsAB_GreenDotsOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeSumResultsAB_GreenLinesOK.xlsx\n",
      "Spindles_S1_ABdetection_SpikeSumResultsAB_RedLinesOK.xlsx\n",
      "121 L1 neurons recorded\n",
      "120 L1 neurons in the cross-registration\n",
      "975 Spdl recorded in total in the S1\n",
      "SWR oscillations analysis...\n",
      "... for All neurons...\n",
      "... in the PFC\n",
      "SWR_PFC_ABdetection_CalciumAvgResultsAB_Purple.xlsx\n",
      "SWR_PFC_ABdetection_CalciumAvgResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "SWR_PFC_ABdetection_CalciumAvgResultsAB_ThreeColDotsOK.xlsx\n",
      "SWR_PFC_ABdetection_GlobalResultsAB_Purple.xlsx\n",
      "SWR_PFC_ABdetection_GlobalResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "SWR_PFC_ABdetection_GlobalResultsAB_ThreeColDotsOK.xlsx\n",
      "SWR_PFC_ABdetection_SpikeAvgResultsAB_Purple.xlsx\n",
      "SWR_PFC_ABdetection_SpikeAvgResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "SWR_PFC_ABdetection_SpikeAvgResultsAB_ThreeColDotsOK.xlsx\n",
      "SWR_PFC_ABdetection_SpikeSumResultsAB_Purple.xlsx\n",
      "SWR_PFC_ABdetection_SpikeSumResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "SWR_PFC_ABdetection_SpikeSumResultsAB_ThreeColDotsOK.xlsx\n",
      "339 All neurons recorded\n",
      "338 All neurons in the cross-registration\n",
      "8577 SWR recorded in total in the PFC\n",
      "... in the S1\n",
      "SWR_S1_ABdetection_CalciumAvgResultsAB_Purple.xlsx\n",
      "SWR_S1_ABdetection_CalciumAvgResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "SWR_S1_ABdetection_CalciumAvgResultsAB_ThreeColDotsOK.xlsx\n",
      "SWR_S1_ABdetection_GlobalResultsAB_Purple.xlsx\n",
      "SWR_S1_ABdetection_GlobalResultsAB_ThreeBlueCrossesOK.xlsx\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Osc\n",
    "\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=0 #if CGP Experiment\n",
    "#DrugExperiment=0 #if Baseline Experiment\n",
    "\n",
    "choosed_folder='OscillationsAnalysis_PerMouse_2024_07_18_15_18_02_396776_AH_Zscored'\n",
    "PrefVigExcel_file = 'Analysis_AVG_VigStates_2024-07-16_22_23_09_057850_AB_Zscored_Ultimate'\n",
    "                \n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import sem\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def column_with_max_single_per_row(row):\n",
    "    max_val = row.max()  # Find the max value in the row\n",
    "    max_columns = row == max_val  # Boolean Series of columns with max value\n",
    "    \n",
    "    if max_columns.sum() > 1:\n",
    "        return 'NoPref'  # More than one column has the max value\n",
    "    else:\n",
    "        return max_columns.idxmax()  # Return the name of the column with max value\n",
    "\n",
    "########################################################################\n",
    "        # SCRIPT 27AB_GrandAverages&Stats_for_Osc\n",
    "########################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\" if DrugExperiment else \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\"\n",
    "directory= f'{InitialDirectory}/{choosed_folder}'\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis/AVG_Osc_{FolderNameSave}/\" if DrugExperiment else f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis/AVG_Osc_{FolderNameSave}/\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.ipynb\"\n",
    "destination_file_path = f\"{destination_folder}/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "NrSubtypeList=['All', 'L1']\n",
    "CortexList=['PFC', 'S1']\n",
    "\n",
    "OscList=['Spdl', 'SWR', 'DS']\n",
    "OscillationList=['Spindles', 'SWR', 'DS']\n",
    "\n",
    "Drugs= ['Baseline', 'CGP'] if DrugExperiment else ['Baseline']\n",
    "\n",
    "for o, Osc in enumerate(OscList): \n",
    "    \n",
    "    print(Osc, 'oscillations analysis...')\n",
    "\n",
    "    for NrSubtype in NrSubtypeList: \n",
    "        \n",
    "        print('... for', NrSubtype, 'neurons...')\n",
    "\n",
    "        for Cortex in CortexList:\n",
    "            \n",
    "            print('... in the', Cortex)\n",
    "\n",
    "            # Initialize an empty list to store the dataframes\n",
    "            dfs = []\n",
    "            df=[]\n",
    "            dfs2 = []\n",
    "            df2=[]\n",
    "            dfs2_per_sheet = {}\n",
    "            dfs3 = []\n",
    "            df3=[]\n",
    "            dfs3_per_sheet = {}\n",
    "            dfs4 = []\n",
    "            df4=[]\n",
    "            dfs4_per_sheet = {}\n",
    "            filtered_df=[]\n",
    "\n",
    "            if NrSubtype=='L1':\n",
    "                MiceList=['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK', 'GreenLinesOK', 'RedLinesOK']\n",
    "            else:\n",
    "                MiceList=['Purple', 'ThreeColDotsOK', 'ThreeBlueCrossesOK']\n",
    "\n",
    "            nametofind=f'{OscillationList[o]}_{Cortex}_Global'\n",
    "            nametofind2=f'{OscillationList[o]}_{Cortex}_CalciumAvg'\n",
    "            nametofind3=f'{OscillationList[o]}_{Cortex}_SpikeAvg'\n",
    "            #nametofind4=f'{OscillationList[o]}_{Cortex}_SpikeSum'\n",
    "\n",
    "            # Recursively traverse the directory structure\n",
    "            for root, _, files in os.walk(directory):\n",
    "                for filename in files:\n",
    "                    # Check if the file is an Excel file and contains the specified name\n",
    "                    if filename.endswith('.xlsx') and nametofind in filename:\n",
    "                        if any(name in filename for name in MiceList):  \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the Excel file into a dataframe and append it to the list\n",
    "                            df = pd.read_excel(filepath, index_col=0)\n",
    "                            dfs.append(df)\n",
    "                            print(filename)\n",
    "                    if filename.endswith('.xlsx') and nametofind2 in filename: \n",
    "                        if any(name in filename for name in MiceList): \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the Excel file into a dataframe and append it to the list\n",
    "                            excel_data = pd.read_excel(filepath, sheet_name=None, index_col=0, header=None)           \n",
    "                            for sheet_name, df2 in excel_data.items():\n",
    "                                if len(df2)>0:\n",
    "                                    if sheet_name in dfs2_per_sheet:                                       \n",
    "                                        updated_matrix = pd.concat([dfs2_per_sheet[sheet_name], df2], ignore_index=False, axis=0)                    \n",
    "                                        dfs2_per_sheet[sheet_name] = updated_matrix    \n",
    "                                    else:\n",
    "                                        dfs2_per_sheet[sheet_name] = df2  #one average trace per unique unit, len(df2)==nb unit recorded for that mouse\n",
    "                            print(filename)\n",
    "                    if filename.endswith('.xlsx') and nametofind3 in filename: \n",
    "                        if any(name in filename for name in MiceList): \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the Excel file into a dataframe and append it to the list\n",
    "                            excel_data = pd.read_excel(filepath, sheet_name=None, index_col=0, header=None)           \n",
    "                            for sheet_name, df3 in excel_data.items():\n",
    "                                if sheet_name in dfs3_per_sheet:   \n",
    "                                    updated_matrix = pd.concat((dfs3_per_sheet[sheet_name],df3), ignore_index=False, axis=0)                \n",
    "                                    dfs3_per_sheet[sheet_name] = updated_matrix                    \n",
    "                                else:                    \n",
    "                                    dfs3_per_sheet[sheet_name] = df3 #one average trace per unique unit, len(df3)==nb unit recorded for that mouse\n",
    "                            print(filename)\n",
    "                    \"\"\"if filename.endswith('.xlsx') and nametofind4 in filename: \n",
    "                        if any(name in filename for name in MiceList): \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the Excel file into a dataframe and append it to the list\n",
    "                            excel_data = pd.read_excel(filepath, sheet_name=None, index_col=0, header=None)           \n",
    "                            for sheet_name, df4 in excel_data.items():\n",
    "                                if sheet_name in dfs4_per_sheet:   \n",
    "                                    updated_matrix = pd.concat((dfs4_per_sheet[sheet_name],df4), ignore_index=False, axis=0)                \n",
    "                                    dfs4_per_sheet[sheet_name] = updated_matrix                    \n",
    "                                else:                    \n",
    "                                    dfs4_per_sheet[sheet_name] = df4 #one average trace per unique unit, len(df4)==nb unit recorded for that mouse\n",
    "                            print(filename)\n",
    "                    \"\"\"\n",
    "\n",
    "            ###########################################################################\n",
    "                                        ##### GLOBAL #####\n",
    "            ###########################################################################\n",
    "\n",
    "            # Concatenate all dataframes into a single dataframe\n",
    "            combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "            combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(str)\n",
    "            combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "            combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "\n",
    "            combined_df[f'{Osc}Statut'] = combined_df[f'{Osc}Statut'].astype(str)\n",
    "\n",
    "            combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "\n",
    "            unique_count = combined_df['Unit_ID'].nunique()\n",
    "            print(unique_count, f'{NrSubtype} neurons recorded') \n",
    "\n",
    "            # Remove non defined Unique Units \n",
    "            combined_df = combined_df[combined_df['Unique_Unit'] != '[]']\n",
    "            combined_df = combined_df.dropna(subset=['Unique_Unit'])\n",
    "            unique_count = combined_df['Unit_ID'].nunique()\n",
    "            print(unique_count, f'{NrSubtype} neurons in the cross-registration') \n",
    "            \n",
    "            combined_df[f'{Osc}_ID'] = combined_df['Mice'] + combined_df['Session'] + combined_df[f'{Osc}Number'].astype(str)\n",
    "            \n",
    "            unique_count = combined_df[f'{Osc}_ID'].nunique()\n",
    "            print(unique_count, f'{Osc} recorded in total in the {Cortex}')\n",
    "\n",
    "            filenameOut = f'{folder_to_save}/{NrSubtype}_{Osc}_{Cortex}_Global.xlsx'\n",
    "            writer = pd.ExcelWriter(filenameOut)\n",
    "            combined_df.to_excel(writer)\n",
    "            writer.close()\n",
    "\n",
    "            Drugs= ['Baseline', 'CGP'] if DrugExperiment else ['Baseline']\n",
    "\n",
    "            for Drug in Drugs: \n",
    "                \n",
    "                combined_df_Drug = combined_df.copy()\n",
    "                try:\n",
    "                    combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == Drug]\n",
    "                except: \n",
    "                    combined_df_Drug=combined_df_Drug\n",
    "                \n",
    "                folder_to_save2= f'{folder_to_save}/{Drug}/'\n",
    "                if NrSubtype=='All' and o==0 and Cortex=='PFC':\n",
    "                    os.makedirs(folder_to_save2)\n",
    "\n",
    "                #####################\n",
    "                # PREFERENCE #\n",
    "                #####################\n",
    "                            \n",
    "                # Load the Excel file and read each sheet into a separate DataFrame\n",
    "                excel_file = f'{InitialDirectory}/{PrefVigExcel_file}/Baseline/{NrSubtype}_ActivityPreference.xlsx'\n",
    "                sheets = pd.read_excel(excel_file, sheet_name=None, header=None, index_col=0)  # sheet_name=None reads all sheets\n",
    "\n",
    "                # Print the names of the sheets and their corresponding DataFrames\n",
    "                for List_name, listI in sheets.items():\n",
    "                    \n",
    "                    list=listI[1].tolist() #convert df to list\n",
    "                    filtered_df = combined_df_Drug[combined_df_Drug['Unit_ID'].isin(list)]\n",
    "                    List_name=List_name.replace( '\\\\', '/')\n",
    "\n",
    "                    if NrSubtype=='All' and o==0 and Cortex=='PFC':\n",
    "                        new_folder= f\"{folder_to_save2}/{List_name}/\"\n",
    "                        os.makedirs(new_folder)\n",
    "\n",
    "                    ###########################################################################\n",
    "                                                ##### Before/During/After #####\n",
    "                    ###########################################################################\n",
    "                    \"\"\"\n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_{Cortex}_SpikeAct_BeforeDuringAfter.xlsx'          \n",
    "                    excel_writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "                    SpikeActivityBefore_perUnit = filtered_df.groupby('Unit_ID')['SpikeActivityBefore'].sum()\n",
    "                    SpikeActivityDuring_perUnit = filtered_df.groupby('Unit_ID')['SpikeActivityDuring'].sum()\n",
    "                    SpikeActivityAfter_perUnit = filtered_df.groupby('Unit_ID')['SpikeActivityAfter'].sum()\n",
    "                    \n",
    "                    allSPresult = pd.concat([SpikeActivityBefore_perUnit,SpikeActivityDuring_perUnit,SpikeActivityAfter_perUnit], axis=1).rename(columns={'SpikeActivityBefore': 'Before', 'SpikeActivityDuring': 'During', 'SpikeActivityAfter': 'After'})\n",
    "                    allSPresult_ActiveOnly = allSPresult.loc[~(allSPresult == 0).all(axis=1)]\n",
    "                    allSPresult_ActiveOnly = allSPresult_ActiveOnly.copy()\n",
    "                    allSPresult_ActiveOnly['Pref']  = allSPresult_ActiveOnly.apply(column_with_max_single_per_row, axis=1)\n",
    "                    allSPresult = allSPresult.copy()\n",
    "                    allSPresult['Pref']  = allSPresult.apply(column_with_max_single_per_row, axis=1)\n",
    "                    CountPref=allSPresult['Pref'].value_counts()\n",
    "                    CountPref_ActiveOnly=allSPresult_ActiveOnly['Pref'].value_counts()            \n",
    "                    allSPresult.to_excel(excel_writer, sheet_name='Sum', index=True, header=True)\n",
    "                    allSPresult_ActiveOnly.to_excel(excel_writer, sheet_name='Sum_ActiveOnly', index=True, header=True)\n",
    "\n",
    "                    SpikeActivityBefore_perUnit = filtered_df.groupby('Unit_ID')['SpikeActivityBefore'].mean()\n",
    "                    SpikeActivityDuring_perUnit = filtered_df.groupby('Unit_ID')['SpikeActivityDuring'].mean()\n",
    "                    SpikeActivityAfter_perUnit = filtered_df.groupby('Unit_ID')['SpikeActivityAfter'].mean()\n",
    "                    \n",
    "                    allSPresult = pd.concat([SpikeActivityBefore_perUnit,SpikeActivityDuring_perUnit,SpikeActivityAfter_perUnit], axis=1, keys=['Before','During', 'After'])\n",
    "                    allSPresult_ActiveOnly = allSPresult.loc[~(allSPresult == 0).all(axis=1)]\n",
    "                    allSPresult_ActiveOnly = allSPresult_ActiveOnly.copy()\n",
    "                    allSPresult_ActiveOnly['Pref']  = allSPresult_ActiveOnly.apply(column_with_max_single_per_row, axis=1)\n",
    "                    allSPresult = allSPresult.copy()\n",
    "                    allSPresult['Pref']  = allSPresult.apply(column_with_max_single_per_row, axis=1)\n",
    "                    CountPref2=allSPresult['Pref'].value_counts()\n",
    "                    CountPref_ActiveOnly2=allSPresult_ActiveOnly['Pref'].value_counts()     \n",
    "                    allSPresult.to_excel(excel_writer, sheet_name='Mean', index=True, header=True)\n",
    "                    allSPresult_ActiveOnly.to_excel(excel_writer, sheet_name='Mean_ActiveOnly', index=True, header=True)\n",
    "\n",
    "                    CountP=pd.concat([CountPref, CountPref_ActiveOnly,CountPref2, CountPref_ActiveOnly2], axis=1, keys=['Sum', 'Sum_ActiveOnly', 'Mean', 'Mean_ActiveOnly'])\n",
    "                    CountP.to_excel(excel_writer, sheet_name='Preference', index=True, header=True)\n",
    "\n",
    "                    excel_writer.close()\n",
    "                    \"\"\"\n",
    "\n",
    "                    ###########################################################################\n",
    "                                                ##### PSTH #####\n",
    "                    ###########################################################################\n",
    "\n",
    "                    filenameOutAVG = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_{Cortex}_AVG&SEM.xlsx'\n",
    "                    excel_writerAVG = pd.ExcelWriter(filenameOutAVG)\n",
    "\n",
    "                    FileNames= ['CalciumAVG', 'SpikeAVG'] # 'SpikeGrandSum',\n",
    "                    FileNamesNormalized= ['Baselined_CalciumAVG', 'Baselined_SpikeAVG'] #, 'Baselined_SpikeGrandSum',\n",
    "                    dfs_per_sheet=[dfs2_per_sheet,dfs3_per_sheet]# dfs4_per_sheet, ]\n",
    "\n",
    "                    for d, df_per_sheet in enumerate(dfs_per_sheet):\n",
    "\n",
    "                        FileName=FileNames[d]\n",
    "                        FileNameNormalized=FileNamesNormalized[d]\n",
    "                        \n",
    "                        filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_{Cortex}_{FileName}.xlsx'\n",
    "                        excel_writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "                        Array=[]\n",
    "                        ArrayUn=[]\n",
    "                        ArrayPre=[]\n",
    "                        ArrayPost=[]\n",
    "                        \n",
    "                        Array=pd.DataFrame(df_per_sheet[f'{Drug}_All_{OscillationList[o]}'])\n",
    "                        ArrayUn=pd.DataFrame(df_per_sheet[f'{Drug}_Uncoupled_{OscillationList[o]}'])\n",
    "                        ArrayPre=pd.DataFrame(df_per_sheet[f'{Drug}_Precoupled_{OscillationList[o]}'])\n",
    "                        ArrayPost=pd.DataFrame(df_per_sheet[f'{Drug}_Postcoupled_{OscillationList[o]}'])\n",
    "                        \n",
    "                        # Only keep the neurons belonging to the list (All units, NREM active, REM active, etc)\n",
    "                        present_indices = [idx for idx in list if idx in Array.index]\n",
    "                        Array = Array.loc[present_indices] \n",
    "                        present_indices = [idx for idx in list if idx in ArrayUn.index]\n",
    "                        ArrayUn = ArrayUn.loc[present_indices] \n",
    "                        present_indices = [idx for idx in list if idx in ArrayPre.index]\n",
    "                        ArrayPre = ArrayPre.loc[present_indices] \n",
    "                        present_indices = [idx for idx in list if idx in ArrayPost.index]\n",
    "                        ArrayPost = ArrayPost.loc[present_indices] \n",
    "\n",
    "                        Array.to_excel(excel_writer, sheet_name=f'{Drug}_All_{OscillationList[o]}', index=True, header=False)\n",
    "                        ArrayUn.to_excel(excel_writer, sheet_name=f'{Drug}_Uncoupled_{OscillationList[o]}', index=True, header=False)\n",
    "                        ArrayPre.to_excel(excel_writer, sheet_name=f'{Drug}_Precoupled_{OscillationList[o]}', index=True, header=False)\n",
    "                        ArrayPost.to_excel(excel_writer, sheet_name=f'{Drug}_Postcoupled_{OscillationList[o]}', index=True, header=False)\n",
    "\n",
    "                        mArray=Array.mean(axis=0)\n",
    "                        semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                        icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                        mArrayUn=ArrayUn.mean(axis=0)\n",
    "                        semArrayUn = stats.sem(ArrayUn, axis=0, ddof=1, nan_policy='omit')\n",
    "                        icArrayUn = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayUn, axis=0) / np.sqrt(ArrayUn.shape[0]))\n",
    "                        mArrayPre=ArrayPre.mean(axis=0)\n",
    "                        semArrayPre = stats.sem(ArrayPre, axis=0, ddof=1, nan_policy='omit')\n",
    "                        icArrayPre = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayPre, axis=0) / np.sqrt(ArrayPre.shape[0]))\n",
    "                        mArrayPost=ArrayPost.mean(axis=0)\n",
    "                        semArrayPost = stats.sem(ArrayPost, axis=0, ddof=1, nan_policy='omit')\n",
    "                        icArrayPost = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayPost, axis=0) / np.sqrt(ArrayPost.shape[0]))\n",
    "                        BigArray=[mArray,semArray,icArray , mArrayUn, semArrayUn, icArrayUn, mArrayPre, semArrayPre, icArrayPre, mArrayPost, semArrayPost, icArrayPost]\n",
    "                        BigArray=pd.DataFrame(np.transpose(BigArray), columns=[f'{Drug}_All {Osc} Mean', f'{Drug}_All {Osc} SEM', f'{Drug}_All {Osc} IC', f'{Drug}_Uncoupled {Osc} Mean', f'{Drug}_Uncoupled {Osc} SEM',f'{Drug}_Uncoupled {Osc} IC', f'{Drug}_Postcoupled {Osc} Mean', f'{Drug}_Postcoupled {Osc} SEM',f'{Drug}_Postcoupled {Osc} IC', f'{Drug}_Precoupled {Osc} Mean', f'{Drug}_Precoupled {Osc} SEM',  f'{Drug}_Precoupled {Osc} IC'])\n",
    "\n",
    "                        if Osc=='Spdl':\n",
    "                            \n",
    "                            ArrayGlobal=[]\n",
    "                            ArrayLocal=[]\n",
    "                            ArrayGlobal=pd.DataFrame(df_per_sheet[f'{Drug}_Global_Spindles'])\n",
    "                            ArrayLocal=pd.DataFrame(df_per_sheet[f'{Drug}_Local_Spindles'])\n",
    "\n",
    "                            present_indices = [idx for idx in list if idx in ArrayGlobal.index]\n",
    "                            ArrayGlobal = ArrayGlobal.loc[present_indices] \n",
    "                            present_indices = [idx for idx in list if idx in ArrayLocal.index]\n",
    "                            ArrayLocal = ArrayLocal.loc[present_indices]\n",
    "\n",
    "                            ArrayGlobal.to_excel(excel_writer, sheet_name=f'{Drug}_Global_Spindles', index=True, header=False)\n",
    "                            ArrayLocal.to_excel(excel_writer, sheet_name=f'{Drug}_Local_Spindles', index=True, header=False)\n",
    "\n",
    "                            mArrayLocal=ArrayLocal.mean(axis=0)\n",
    "                            semArrayLocal = stats.sem(ArrayLocal, axis=0, ddof=1, nan_policy='omit')\n",
    "                            icArrayLocal = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayLocal, axis=0) / np.sqrt(ArrayLocal.shape[0]))\n",
    "                            mArrayGlobal=ArrayGlobal.mean(axis=0)\n",
    "                            semArrayGlobal = stats.sem(ArrayGlobal, axis=0, ddof=1, nan_policy='omit')\n",
    "                            icArrayGlobal = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayGlobal, axis=0) / np.sqrt(ArrayGlobal.shape[0]))\n",
    "                            BigArray=[mArray,semArray,icArray , mArrayUn, semArrayUn, icArrayUn, mArrayPre, semArrayPre, icArrayPre, mArrayPost, semArrayPost, icArrayPost,mArrayLocal, semArrayLocal, icArrayLocal , mArrayGlobal, semArrayGlobal, icArrayGlobal]\n",
    "                            BigArray=pd.DataFrame(np.transpose(BigArray), columns=[f'{Drug}_All {Osc} Mean', f'{Drug}_All {Osc} SEM', f'{Drug}_All {Osc} IC', f'{Drug}_Uncoupled {Osc} Mean', f'{Drug}_Uncoupled {Osc} SEM',f'{Drug}_Uncoupled {Osc} IC', f'{Drug}_Postcoupled {Osc} Mean', f'{Drug}_Postcoupled {Osc} SEM',f'{Drug}_Postcoupled {Osc} IC', f'{Drug}_Precoupled {Osc} Mean', f'{Drug}_Precoupled {Osc} SEM',  f'{Drug}_Precoupled {Osc} IC', f'{Drug}_Local {Osc} Mean', f'{Drug}_Local {Osc} SEM',f'{Drug}_Local {Osc} IC',f'{Drug}_Global {Osc} Mean', f'{Drug}_Global {Osc} SEM', f'{Drug}_Global {Osc} IC'])\n",
    "\n",
    "                        BigArray.to_excel(excel_writerAVG, sheet_name=FileName, index=True, header=True)\n",
    "                        excel_writer.close()\n",
    "\n",
    "                        # CALCIUM traces Normalization dfs2_per_sheet\n",
    "\n",
    "                        filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_{Cortex}_{FileNameNormalized}.xlsx'\n",
    "                        excel_writer = pd.ExcelWriter(filenameOut)\n",
    "                        \n",
    "                        baseline_columns = Array.iloc[:, :Array.shape[1] // 4]\n",
    "                        mean_baseline = baseline_columns.mean(axis=1)\n",
    "                        Array = Array.sub(mean_baseline, axis=0)\n",
    "\n",
    "                        baseline_columns = ArrayUn.iloc[:, :ArrayUn.shape[1] // 4]\n",
    "                        mean_baseline = baseline_columns.mean(axis=1)\n",
    "                        ArrayUn = ArrayUn.sub(mean_baseline, axis=0)\n",
    "\n",
    "                        baseline_columns = ArrayPre.iloc[:, :ArrayPre.shape[1] // 4]\n",
    "                        mean_baseline = baseline_columns.mean(axis=1)\n",
    "                        ArrayPre = ArrayPre.sub(mean_baseline, axis=0)\n",
    "\n",
    "                        baseline_columns = ArrayPost.iloc[:, :ArrayPost.shape[1] // 4]\n",
    "                        mean_baseline = baseline_columns.mean(axis=1)\n",
    "                        ArrayPost = ArrayPost.sub(mean_baseline, axis=0)\n",
    "\n",
    "                        Array.to_excel(excel_writer, sheet_name=f'{Drug}_All_{OscillationList[o]}', index=True, header=False)\n",
    "                        ArrayUn.to_excel(excel_writer, sheet_name=f'{Drug}_Uncoupled_{OscillationList[o]}', index=True, header=False)\n",
    "                        ArrayPre.to_excel(excel_writer, sheet_name=f'{Drug}_Precoupled_{OscillationList[o]}', index=True, header=False)\n",
    "                        ArrayPost.to_excel(excel_writer, sheet_name=f'{Drug}_Postcoupled_{OscillationList[o]}', index=True, header=False)\n",
    "\n",
    "                        mArray=Array.mean(axis=0)\n",
    "                        semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                        icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                        mArrayUn=ArrayUn.mean(axis=0)\n",
    "                        semArrayUn = stats.sem(ArrayUn, axis=0, ddof=1, nan_policy='omit')\n",
    "                        icArrayUn = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayUn, axis=0) / np.sqrt(ArrayUn.shape[0]))\n",
    "                        mArrayPre=ArrayPre.mean(axis=0)\n",
    "                        semArrayPre = stats.sem(ArrayPre, axis=0, ddof=1, nan_policy='omit')\n",
    "                        icArrayPre = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayPre, axis=0) / np.sqrt(ArrayPre.shape[0]))\n",
    "                        mArrayPost=ArrayPost.mean(axis=0)\n",
    "                        semArrayPost = stats.sem(ArrayPost, axis=0, ddof=1, nan_policy='omit')\n",
    "                        icArrayPost = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayPost, axis=0) / np.sqrt(ArrayPost.shape[0]))\n",
    "                        BigArray=[mArray,semArray,icArray , mArrayUn, semArrayUn, icArrayUn, mArrayPre, semArrayPre, icArrayPre, mArrayPost, semArrayPost, icArrayPost]\n",
    "                        BigArray=pd.DataFrame(np.transpose(BigArray), columns=[f'{Drug}_All {Osc} Mean', f'{Drug}_All {Osc} SEM', f'{Drug}_All {Osc} IC', f'{Drug}_Uncoupled {Osc} Mean', f'{Drug}_Uncoupled {Osc} SEM',f'{Drug}_Uncoupled {Osc} IC', f'{Drug}_Postcoupled {Osc} Mean', f'{Drug}_Postcoupled {Osc} SEM',f'{Drug}_Postcoupled {Osc} IC', f'{Drug}_Precoupled {Osc} Mean', f'{Drug}_Precoupled {Osc} SEM',  f'{Drug}_Precoupled {Osc} IC'])\n",
    "\n",
    "                        if Osc=='Spdl':\n",
    "                            \n",
    "                            baseline_columns = ArrayGlobal.iloc[:, :ArrayGlobal.shape[1] // 4]\n",
    "                            mean_baseline = baseline_columns.mean(axis=1)\n",
    "                            ArrayGlobal = ArrayGlobal.sub(mean_baseline, axis=0)\n",
    "                            \n",
    "                            baseline_columns = ArrayLocal.iloc[:, :ArrayLocal.shape[1] // 4]\n",
    "                            mean_baseline = baseline_columns.mean(axis=1)\n",
    "                            ArrayLocal = ArrayLocal.sub(mean_baseline, axis=0)\n",
    "\n",
    "                            ArrayGlobal.to_excel(excel_writer, sheet_name=f'{Drug}_Global_Spindles', index=True, header=False)\n",
    "                            ArrayLocal.to_excel(excel_writer, sheet_name=f'{Drug}_Local_Spindles', index=True, header=False)\n",
    "\n",
    "                            mArrayLocal=ArrayLocal.mean(axis=0)\n",
    "                            semArrayLocal = stats.sem(ArrayLocal, axis=0, ddof=1, nan_policy='omit')\n",
    "                            icArrayLocal = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayLocal, axis=0) / np.sqrt(ArrayLocal.shape[0]))\n",
    "                            mArrayGlobal=ArrayGlobal.mean(axis=0)\n",
    "                            semArrayGlobal = stats.sem(ArrayGlobal, axis=0, ddof=1, nan_policy='omit')\n",
    "                            icArrayGlobal = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayGlobal, axis=0) / np.sqrt(ArrayGlobal.shape[0]))\n",
    "                            BigArray=[mArray,semArray,icArray , mArrayUn, semArrayUn, icArrayUn, mArrayPre, semArrayPre, icArrayPre, mArrayPost, semArrayPost, icArrayPost,mArrayLocal, semArrayLocal, icArrayLocal , mArrayGlobal, semArrayGlobal, icArrayGlobal]\n",
    "                            BigArray=pd.DataFrame(np.transpose(BigArray), columns=[f'{Drug}_All {Osc} Mean', f'{Drug}_All {Osc} SEM', f'{Drug}_All {Osc} IC', f'{Drug}_Uncoupled {Osc} Mean', f'{Drug}_Uncoupled {Osc} SEM',f'{Drug}_Uncoupled {Osc} IC', f'{Drug}_Postcoupled {Osc} Mean', f'{Drug}_Postcoupled {Osc} SEM',f'{Drug}_Postcoupled {Osc} IC', f'{Drug}_Precoupled {Osc} Mean', f'{Drug}_Precoupled {Osc} SEM',  f'{Drug}_Precoupled {Osc} IC', f'{Drug}_Local {Osc} Mean', f'{Drug}_Local {Osc} SEM',f'{Drug}_Local {Osc} IC',f'{Drug}_Global {Osc} Mean', f'{Drug}_Global {Osc} SEM', f'{Drug}_Global {Osc} IC'])\n",
    "\n",
    "                        excel_writer.close() \n",
    "                        BigArray.to_excel(excel_writerAVG, sheet_name=FileNameNormalized, index=True, header=True)\n",
    "\n",
    "                    excel_writerAVG.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian311new2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
