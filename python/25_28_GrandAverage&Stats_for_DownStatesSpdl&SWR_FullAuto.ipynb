{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spdl oscillations analysis...\n",
      "... for L2&3 neurons...\n",
      "Spdl_CaPSTH_Purple.xlsx\n",
      "Spdl_CaPSTH_ThreeColDotsOK.xlsx\n",
      "Spdl_Global_Purple.xlsx\n",
      "Spdl_Global_ThreeColDotsOK.xlsx\n",
      "Spdl_SpPSTH_Purple.xlsx\n",
      "Spdl_SpPSTH_ThreeColDotsOK.xlsx\n",
      "507 L2&3 neurons recorded\n",
      "507 L2&3 neurons in the cross-registration\n",
      "775 Spdl recorded in total\n",
      "... for L1 neurons...\n",
      "Spdl_CaPSTH_BlackLinesOK.xlsx\n",
      "Spdl_CaPSTH_BlueLinesOK.xlsx\n",
      "Spdl_CaPSTH_GreenDotsOK.xlsx\n",
      "Spdl_Global_BlackLinesOK.xlsx\n",
      "Spdl_Global_BlueLinesOK.xlsx\n",
      "Spdl_Global_GreenDotsOK.xlsx\n",
      "Spdl_SpPSTH_BlackLinesOK.xlsx\n",
      "Spdl_SpPSTH_BlueLinesOK.xlsx\n",
      "Spdl_SpPSTH_GreenDotsOK.xlsx\n",
      "63 L1 neurons recorded\n",
      "62 L1 neurons in the cross-registration\n",
      "892 Spdl recorded in total\n",
      "SWR oscillations analysis...\n",
      "... for L2&3 neurons...\n",
      "SWR_CaPSTH_Purple.xlsx\n",
      "SWR_CaPSTH_ThreeColDotsOK.xlsx\n",
      "SWR_Global_Purple.xlsx\n",
      "SWR_Global_ThreeColDotsOK.xlsx\n",
      "SWR_SpPSTH_Purple.xlsx\n",
      "SWR_SpPSTH_ThreeColDotsOK.xlsx\n",
      "507 L2&3 neurons recorded\n",
      "507 L2&3 neurons in the cross-registration\n",
      "2113 SWR recorded in total\n",
      "... for L1 neurons...\n",
      "SWR_CaPSTH_BlackLinesOK.xlsx\n",
      "SWR_CaPSTH_BlueLinesOK.xlsx\n",
      "SWR_CaPSTH_GreenDotsOK.xlsx\n",
      "SWR_Global_BlackLinesOK.xlsx\n",
      "SWR_Global_BlueLinesOK.xlsx\n",
      "SWR_Global_GreenDotsOK.xlsx\n",
      "SWR_SpPSTH_BlackLinesOK.xlsx\n",
      "SWR_SpPSTH_BlueLinesOK.xlsx\n",
      "SWR_SpPSTH_GreenDotsOK.xlsx\n",
      "63 L1 neurons recorded\n",
      "62 L1 neurons in the cross-registration\n",
      "2001 SWR recorded in total\n"
     ]
    }
   ],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Osc\n",
    "\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=1 #if CGP Experiment\n",
    "#DrugExperiment=0 #if Baseline Experiment\n",
    "suffix='_AH_FINAL'\n",
    "\n",
    "choosed_folder='Osc_2024_08_04_10_35_33_AH_FINAL' if DrugExperiment else 'Osc_2024_08_04_09_24_52_AH_FINAL'\n",
    "PrefVigExcel_file = 'AVG_VigSt_2024-08-04_13_06_25_AB_FINAL' if DrugExperiment else 'AVG_VigSt_2024-08-04_10_42_04_AB_FINAL'\n",
    "                \n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import sem\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def column_with_max_single_per_row(row):\n",
    "    max_val = row.max()  # Find the max value in the row\n",
    "    max_columns = row == max_val  # Boolean Series of columns with max value\n",
    "    \n",
    "    if max_columns.sum() > 1:\n",
    "        return 'NoPref'  # More than one column has the max value\n",
    "    else:\n",
    "        return max_columns.idxmax()  # Return the name of the column with max value\n",
    "\n",
    "########################################################################\n",
    "        # SCRIPT 27AB_GrandAverages&Stats_for_Osc\n",
    "########################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\" if DrugExperiment else \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\"\n",
    "directory= f'{InitialDirectory}/{choosed_folder}'\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis/AVG_Osc_{FolderNameSave}{suffix}/\" if DrugExperiment else f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis/AVG_Osc_{FolderNameSave}{suffix}/\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.ipynb\"\n",
    "destination_file_path = f\"{destination_folder}/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "NrSubtypeList=['L2&3', 'L1']\n",
    "CTX=['PFC_', 'S1_', 'S1PFC_']\n",
    "Coupling=['', 'UnCoupled', 'Coupled']\n",
    "OscList=['Spdl', 'SWR']#, 'DS']\n",
    "Drugs= ['Baseline', 'CGP'] if DrugExperiment else ['Baseline']\n",
    "\n",
    "for o, Osc in enumerate(OscList): \n",
    "    \n",
    "    print(Osc, 'oscillations analysis...')\n",
    "\n",
    "    AllOscStatut=pd.DataFrame()\n",
    "    AllOscDuration=pd.DataFrame()\n",
    "    AllOscCoupling=pd.DataFrame()\n",
    "    AllGlobalSpindle=pd.DataFrame()\n",
    "    AllOscStartLocation=pd.DataFrame()\n",
    "    \n",
    "    AllOscStatutS1=pd.DataFrame()\n",
    "    AllOscDurationS1=pd.DataFrame()\n",
    "    AllOscCouplingS1=pd.DataFrame()\n",
    "\n",
    "    AllOscStatutPFC=pd.DataFrame()\n",
    "    AllOscDurationPFC=pd.DataFrame()\n",
    "    AllOscCouplingPFC=pd.DataFrame()\n",
    "\n",
    "    AllOscStatutS1PFC=pd.DataFrame()\n",
    "    AllOscDurationS1PFC=pd.DataFrame()\n",
    "    AllOscCouplingS1PFC=pd.DataFrame()\n",
    "\n",
    "    for NrSubtype in NrSubtypeList: \n",
    "        \n",
    "        print('... for', NrSubtype, 'neurons...')\n",
    "        \n",
    "        # Initialize an empty list to store the dataframes\n",
    "        dfs = []\n",
    "        df=[]\n",
    "        dfs2 = []\n",
    "        df2=[]\n",
    "        dfs2_per_sheet = {}\n",
    "        dfs3 = []\n",
    "        df3=[]\n",
    "        dfs3_per_sheet = {}\n",
    "        dfs4 = []\n",
    "        df4=[]\n",
    "        dfs4_per_sheet = {}\n",
    "        filtered_df=[]\n",
    "\n",
    "        if NrSubtype=='L1':\n",
    "            MiceList=['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK', 'GreenLinesOK', 'RedLinesOK']\n",
    "        else:\n",
    "            MiceList=['Purple', 'ThreeColDotsOK', 'ThreeBlueCrossesOK']\n",
    "\n",
    "        nametofind=f'{Osc}_Global'\n",
    "        nametofind2=f'{Osc}_CaPSTH'\n",
    "        nametofind3=f'{Osc}_SpPSTH'\n",
    "        #nametofind4=f'{OscillationList[o]}_{Cortex}_SpikeSum'\n",
    "\n",
    "        # Recursively traverse the directory structure\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for filename in files:\n",
    "                # Check if the file is an Excel file and contains the specified name\n",
    "                if filename.endswith('.xlsx') and nametofind in filename:\n",
    "                    if any(name in filename for name in MiceList):  \n",
    "                        # Construct the full path to the file\n",
    "                        filepath = os.path.join(root, filename)\n",
    "                        # Read the Excel file into a dataframe and append it to the list\n",
    "                        df = pd.read_excel(filepath, index_col=0)\n",
    "                        dfs.append(df)\n",
    "                        print(filename)\n",
    "                if filename.endswith('.xlsx') and nametofind2 in filename: \n",
    "                    if any(name in filename for name in MiceList): \n",
    "                        # Construct the full path to the file\n",
    "                        filepath = os.path.join(root, filename)\n",
    "                        # Read the Excel file into a dataframe and append it to the list\n",
    "                        excel_data = pd.read_excel(filepath, sheet_name=None, index_col=0, header=None)           \n",
    "                        for sheet_name, df2 in excel_data.items():\n",
    "                            if len(df2)>0:\n",
    "                                if sheet_name in dfs2_per_sheet:                                       \n",
    "                                    updated_matrix = pd.concat([dfs2_per_sheet[sheet_name], df2], ignore_index=False, axis=0)                    \n",
    "                                    dfs2_per_sheet[sheet_name] = updated_matrix    \n",
    "                                else:\n",
    "                                    dfs2_per_sheet[sheet_name] = df2  #one average trace per unique unit, len(df2)==nb unit recorded for that mouse\n",
    "                        print(filename)\n",
    "                if filename.endswith('.xlsx') and nametofind3 in filename: \n",
    "                    if any(name in filename for name in MiceList): \n",
    "                        # Construct the full path to the file\n",
    "                        filepath = os.path.join(root, filename)\n",
    "                        # Read the Excel file into a dataframe and append it to the list\n",
    "                        excel_data = pd.read_excel(filepath, sheet_name=None, index_col=0, header=None)           \n",
    "                        for sheet_name, df3 in excel_data.items():\n",
    "                            if sheet_name in dfs3_per_sheet:   \n",
    "                                updated_matrix = pd.concat((dfs3_per_sheet[sheet_name],df3), ignore_index=False, axis=0)                \n",
    "                                dfs3_per_sheet[sheet_name] = updated_matrix                    \n",
    "                            else:                    \n",
    "                                dfs3_per_sheet[sheet_name] = df3 #one average trace per unique unit, len(df3)==nb unit recorded for that mouse\n",
    "                        print(filename)\n",
    "\n",
    "        ###########################################################################\n",
    "                                    ##### GLOBAL #####\n",
    "        ###########################################################################\n",
    "\n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        try: combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        except: combined_df =pd.DataFrame(dfs)\n",
    "\n",
    "        combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(str)\n",
    "        combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "        combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "\n",
    "        combined_df[f'{Osc}Statut'] = combined_df[f'{Osc}Statut'].astype(str)\n",
    "\n",
    "        combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "        combined_df['Session_ID'] = combined_df['Mice'] + combined_df['Session'].astype(str)\n",
    "\n",
    "        unique_count = combined_df['Unit_ID'].nunique()\n",
    "        print(unique_count, f'{NrSubtype} neurons recorded') \n",
    "\n",
    "        # Remove non defined Unique Units \n",
    "        combined_df = combined_df[combined_df['Unique_Unit'] != '[]']\n",
    "        combined_df = combined_df.dropna(subset=['Unique_Unit'])\n",
    "        unique_count = combined_df['Unit_ID'].nunique()\n",
    "        print(unique_count, f'{NrSubtype} neurons in the cross-registration') \n",
    "        \n",
    "        combined_df[f'{Osc}_ID'] = combined_df['Mice'] + combined_df['Session'] + combined_df[f'{Osc}Number'].astype(str)\n",
    "        \n",
    "        unique_count = combined_df[f'{Osc}_ID'].nunique()\n",
    "        print(unique_count, f'{Osc} recorded in total')\n",
    "\n",
    "        filenameOut = f'{folder_to_save}/{NrSubtype}_{Osc}_Global.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "        combined_df.to_excel(writer)\n",
    "        writer.close()\n",
    "\n",
    "        for drug in Drugs: \n",
    "            \n",
    "            combined_df_Drug = combined_df.copy()\n",
    "            try:\n",
    "                combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == drug]\n",
    "            except: \n",
    "                combined_df_Drug=combined_df_Drug\n",
    "            \n",
    "            folder_to_save2= f'{folder_to_save}/{drug}/'\n",
    "            if NrSubtype=='L2&3' and o==0 :\n",
    "                os.makedirs(folder_to_save2)\n",
    "\n",
    "            #####################\n",
    "            # PREFERENCE #\n",
    "            #####################\n",
    "                        \n",
    "            # Load the Excel file and read each sheet into a separate DataFrame\n",
    "            excel_file = f'{InitialDirectory}/{PrefVigExcel_file}/Baseline/{NrSubtype}_ActivityPreference.xlsx'\n",
    "            sheets = pd.read_excel(excel_file, sheet_name=None, header=None, index_col=0)  # sheet_name=None reads all sheets\n",
    "            AllUnits=combined_df_Drug['Unit_ID'].unique()\n",
    "            sheets['AllUnits']=pd.DataFrame(AllUnits)\n",
    "\n",
    "            # Print the names of the sheets and their corresponding DataFrames\n",
    "            for List_name, listI in sheets.items():\n",
    "                \n",
    "                list=listI[0].tolist() if List_name=='AllUnits' else listI[1].tolist()\n",
    "                filtered_df = combined_df_Drug[combined_df_Drug['Unit_ID'].isin(list)]\n",
    "                List_name=List_name.replace( '\\\\', '/')\n",
    "\n",
    "                if NrSubtype=='L2&3' and o==0:\n",
    "                    new_folder= f\"{folder_to_save2}/{List_name}/\"\n",
    "                    os.makedirs(new_folder)\n",
    "\n",
    "                ###########################################################################\n",
    "                                            ##### PSTH #####\n",
    "                ###########################################################################\n",
    "\n",
    "                filenameOutAVG = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_AVG&SEM.xlsx'\n",
    "                excel_writerAVG = pd.ExcelWriter(filenameOutAVG)\n",
    "                filenameOutAVGBSL = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_BSL_AVG&SEM.xlsx'\n",
    "                excel_writerAVGBSL = pd.ExcelWriter(filenameOutAVGBSL)\n",
    "\n",
    "                filenameOutMean = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_During.xlsx'\n",
    "                excel_writerMean= pd.ExcelWriter(filenameOutMean)\n",
    "                filenameOutMeanBSL = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_BSL_During.xlsx'\n",
    "                excel_writerMeanBSL= pd.ExcelWriter(filenameOutMeanBSL)\n",
    "\n",
    "                FileNames= ['CaPSTH', 'SpPSTH'] # 'SpikeGrandSum',\n",
    "                FileNamesNormalized= ['BSL_CaPSTH', 'BSL_SpPSTH'] #, 'Baselined_SpikeGrandSum',\n",
    "                dfs_per_sheet=[dfs2_per_sheet,dfs3_per_sheet]# dfs4_per_sheet, ] #Ca &Sp\n",
    "\n",
    "                for d, df_per_sheet in enumerate(dfs_per_sheet):\n",
    "\n",
    "                    FileName=FileNames[d]\n",
    "                    FileNameNormalized=FileNamesNormalized[d]\n",
    "                    BigArray=pd.DataFrame()\n",
    "                    BigArrayBSL=pd.DataFrame()\n",
    "                    AVGArray=pd.DataFrame()\n",
    "                    AVGArrayBSL=pd.DataFrame()\n",
    "\n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_{FileName}.xlsx'\n",
    "                    excel_writer = pd.ExcelWriter(filenameOut)\n",
    "                    \n",
    "                    filenameOutBSL = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_{FileNameNormalized}.xlsx'\n",
    "                    excel_writerBSL = pd.ExcelWriter(filenameOutBSL)\n",
    "                        \n",
    "                    for ctx in CTX:\n",
    "                        for coup in Coupling: \n",
    "\n",
    "                            ctx= '' if Osc=='SWR' else ctx\n",
    "\n",
    "                            Array=[]\n",
    "                            Array=pd.DataFrame(df_per_sheet[f'{ctx}{coup}{Osc}_{drug}'])\n",
    "                        \n",
    "                            # Only keep the neurons belonging to the list (All units, NREM active, REM active, etc)\n",
    "                            present_indices = [idx for idx in list if idx in Array.index]\n",
    "                            Array = Array.loc[present_indices] \n",
    "                        \n",
    "                            # Leave a blanck space for units not recorded in that condition\n",
    "                            missing_indexes = set(list) - set(Array.index)\n",
    "                            Array = Array.reindex(Array.index.union(missing_indexes))\n",
    "                            Array = Array.sort_index()\n",
    "                            Array.to_excel(excel_writer, sheet_name=f'{ctx}{coup}{Osc}', index=True, header=False)\n",
    "\n",
    "                            mArray=Array.mean(axis=0)\n",
    "                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                            BigArray=pd.concat([BigArray,SmallArray], axis=1)\n",
    "\n",
    "                            SecondHalf_columns = Array.iloc[:, Array.shape[1]//2:]\n",
    "                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{ctx}{coup}{Osc}'])\n",
    "                            AVGArray=pd.concat([AVGArray,avgarray], axis=1)\n",
    "                            \n",
    "                            # Baseline signals\n",
    "                            baseline_columns = Array.iloc[:, :Array.shape[1] // 4]\n",
    "                            mean_baseline = baseline_columns.mean(axis=1)\n",
    "                            Array = Array.sub(mean_baseline, axis=0)\n",
    "                            Array.to_excel(excel_writerBSL, sheet_name=f'{ctx}{coup}{Osc}', index=True, header=False)\n",
    "\n",
    "                            mArray=Array.mean(axis=0)\n",
    "                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                            BigArrayBSL=pd.concat([BigArrayBSL,SmallArray], axis=1)\n",
    "\n",
    "                            SecondHalf_columns = Array.iloc[:, Array.shape[1]//2:]\n",
    "                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{ctx}{coup}{Osc}'])\n",
    "                            AVGArrayBSL=pd.concat([AVGArrayBSL,avgarray], axis=1)\n",
    "\n",
    "                    excel_writer.close()\n",
    "                    excel_writerBSL.close() \n",
    "                    BigArray.to_excel(excel_writerAVG, sheet_name=FileName, index=True, header=True)\n",
    "                    AVGArray.to_excel(excel_writerMean, sheet_name=FileName, index=True, header=True)\n",
    "                    BigArrayBSL.to_excel(excel_writerAVGBSL, sheet_name=FileNameNormalized, index=True, header=True)\n",
    "                    AVGArrayBSL.to_excel(excel_writerMeanBSL, sheet_name=FileNameNormalized, index=True, header=True)\n",
    "\n",
    "                excel_writerAVG.close()                   \n",
    "                excel_writerAVGBSL.close()    \n",
    "                excel_writerMean.close()                   \n",
    "                excel_writerMeanBSL.close()    \n",
    "\n",
    "        #######################\n",
    "        # Propreties Osc\n",
    "        #######################\n",
    "        filenameOut = f'{folder_to_save}/{Osc}Propreties.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "        combined_dfOsc = combined_df.drop_duplicates(subset=f'{Osc}_ID', keep='first')\n",
    "        #All Spdl\n",
    "        OscStatut = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}Statut']])\n",
    "        AllOscStatut=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "        OscDuration = combined_dfOsc.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "        AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "        OscCoupling = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'SWR_inside_Spdl']])\n",
    "        AllOscCoupling=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "        if Osc== 'Spdl':\n",
    "            GlobalSpindle = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle']])\n",
    "            AllGlobalSpindle=pd.concat([AllGlobalSpindle, GlobalSpindle], axis=0)\n",
    "            OscStartLocation = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}StartLocation']])\n",
    "            AllOscStartLocation=pd.concat([AllOscStartLocation, OscStartLocation], axis=0)\n",
    "\n",
    "            #S1 Spdl\n",
    "            combined_dfOscS1=combined_dfOsc[combined_dfOsc[f'{Osc}StartLocation']=='S1' and combined_dfOscS1[f'GlobalSpindle']=='Local']\n",
    "            OscStatut = pd.crosstab(index=combined_dfOscS1['Session_ID'],columns=[combined_dfOscS1['Drug'], combined_dfOscS1[f'{Osc}Statut']])\n",
    "            AllOscStatutS1=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "            OscDuration = combined_dfOscS1.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDurationS1=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOscS1['Session_ID'],columns=[combined_dfOscS1['Drug'], combined_dfOscS1[f'SWR_inside_Spdl']])\n",
    "            AllOscCouplingS1=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "            #PFC Spdl\n",
    "            combined_dfOscPFC=combined_dfOsc[combined_dfOsc[f'{Osc}StartLocation']=='PFC' and combined_dfOscS1[f'GlobalSpindle']=='Local']\n",
    "            OscStatut = pd.crosstab(index=combined_dfOscPFC['Session_ID'],columns=[combined_dfOscPFC['Drug'], combined_dfOscPFC[f'{Osc}Statut']])\n",
    "            AllOscStatutPFC=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "            OscDuration = combined_dfOscPFC.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDurationPFC=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOscPFC['Session_ID'],columns=[combined_dfOscPFC['Drug'], combined_dfOscPFC[f'SWR_inside_Spdl']])\n",
    "            AllOscCouplingPFC=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "            #S1PFC Spdl\n",
    "            combined_dfOscS1PFC=combined_dfOsc[combined_dfOsc[combined_dfOscS1[f'GlobalSpindle']=='Global']]\n",
    "            OscStatut = pd.crosstab(index=combined_dfOscS1PFC['Session_ID'],columns=[combined_dfOscS1PFC['Drug'], combined_dfOscS1PFC[f'{Osc}Statut']])\n",
    "            AllOscStatutS1PFC=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "            OscDuration = combined_dfOscS1PFC.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDurationS1PFC=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOscS1PFC['Session_ID'],columns=[combined_dfOscS1PFC['Drug'], combined_dfOscS1PFC[f'SWR_inside_Spdl']])\n",
    "            AllOscCouplingS1PFC=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "\n",
    "    AllOscStatut.to_excel(writer, sheet_name=f'CouplingStatut')\n",
    "    AllOscDuration.to_excel(writer, sheet_name=f'MeanDuration')\n",
    "    AllOscCoupling.to_excel(writer, sheet_name=f'SWR_inside_Spdl')    \n",
    "    if Osc== 'Spdl':\n",
    "        AllGlobalSpindle.to_excel(writer, sheet_name=f'GlobalSpindle')\n",
    "        AllOscStartLocation.to_excel(writer, sheet_name=f'StartLocation')\n",
    "\n",
    "        AllOscStatutS1.to_excel(writer, sheet_name=f'S1_CouplingStatut')\n",
    "        AllOscDurationS1.to_excel(writer, sheet_name=f'S1_MeanDuration')\n",
    "        AllOscCouplingS1.to_excel(writer, sheet_name=f'S1_SWR_inside_Spdl') \n",
    "        \n",
    "        AllOscStatutPFC.to_excel(writer, sheet_name=f'PFC_CouplingStatut')\n",
    "        AllOscDurationPFC.to_excel(writer, sheet_name=f'PFC_MeanDuration')\n",
    "        AllOscCouplingPFC.to_excel(writer, sheet_name=f'PFC_SWR_inside_Spdl') \n",
    "        \n",
    "        AllOscStatutS1PFC.to_excel(writer, sheet_name=f'S1PFC_CouplingStatut')\n",
    "        AllOscDurationS1PFC.to_excel(writer, sheet_name=f'S1PFC_MeanDuration')\n",
    "        AllOscCouplingS1PFC.to_excel(writer, sheet_name=f'S1PFC_SWR_inside_Spdl')\n",
    "\n",
    "    writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian311new2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
