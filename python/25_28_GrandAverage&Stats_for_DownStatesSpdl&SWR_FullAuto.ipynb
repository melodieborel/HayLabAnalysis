{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spdl oscillations analysis...\n",
      "... for L2&3 neurons...\n",
      "Spdl_CaPSTH_Purple.pkl\n",
      "Spdl_CaPSTH_ThreeBlueCrossesOK.pkl\n",
      "Spdl_CaPSTH_ThreeColDotsOK.pkl\n",
      "Spdl_Global_Purple.pkl\n",
      "Spdl_Global_ThreeBlueCrossesOK.pkl\n",
      "Spdl_Global_ThreeColDotsOK.pkl\n",
      "Spdl_SpPSTH_Purple.pkl\n",
      "Spdl_SpPSTH_ThreeBlueCrossesOK.pkl\n",
      "Spdl_SpPSTH_ThreeColDotsOK.pkl\n",
      "Spdl_CaPSTH_Purple.pkl\n",
      "Spdl_CaPSTH_ThreeColDotsOK.pkl\n",
      "Spdl_Global_Purple.pkl\n",
      "Spdl_Global_ThreeColDotsOK.pkl\n",
      "Spdl_SpPSTH_Purple.pkl\n",
      "Spdl_SpPSTH_ThreeColDotsOK.pkl\n",
      "805 L2&3 neurons recorded\n",
      "803 L2&3 neurons in the cross-registration\n",
      "1994 Spdl recorded in total\n",
      "... for L1 neurons...\n",
      "Spdl_CaPSTH_BlackLinesOK.pkl\n",
      "Spdl_CaPSTH_BlueLinesOK.pkl\n",
      "Spdl_CaPSTH_GreenDotsOK.pkl\n",
      "Spdl_CaPSTH_GreenLinesOK.pkl\n",
      "Spdl_CaPSTH_RedLinesOK.pkl\n",
      "Spdl_Global_BlackLinesOK.pkl\n",
      "Spdl_Global_BlueLinesOK.pkl\n",
      "Spdl_Global_GreenDotsOK.pkl\n",
      "Spdl_Global_GreenLinesOK.pkl\n",
      "Spdl_Global_RedLinesOK.pkl\n",
      "Spdl_SpPSTH_BlackLinesOK.pkl\n",
      "Spdl_SpPSTH_BlueLinesOK.pkl\n",
      "Spdl_SpPSTH_GreenDotsOK.pkl\n",
      "Spdl_SpPSTH_GreenLinesOK.pkl\n",
      "Spdl_SpPSTH_RedLinesOK.pkl\n",
      "Spdl_CaPSTH_BlackLinesOK.pkl\n",
      "Spdl_CaPSTH_BlueLinesOK.pkl\n",
      "Spdl_CaPSTH_GreenDotsOK.pkl\n",
      "Spdl_Global_BlackLinesOK.pkl\n",
      "Spdl_Global_BlueLinesOK.pkl\n",
      "Spdl_Global_GreenDotsOK.pkl\n",
      "Spdl_SpPSTH_BlackLinesOK.pkl\n",
      "Spdl_SpPSTH_BlueLinesOK.pkl\n",
      "Spdl_SpPSTH_GreenDotsOK.pkl\n",
      "180 L1 neurons recorded\n",
      "179 L1 neurons in the cross-registration\n",
      "2064 Spdl recorded in total\n",
      "SWR oscillations analysis...\n",
      "... for L2&3 neurons...\n",
      "SWR_CaPSTH_Purple.pkl\n",
      "SWR_CaPSTH_ThreeBlueCrossesOK.pkl\n",
      "SWR_CaPSTH_ThreeColDotsOK.pkl\n",
      "SWR_Global_Purple.pkl\n",
      "SWR_Global_ThreeBlueCrossesOK.pkl\n",
      "SWR_Global_ThreeColDotsOK.pkl\n",
      "SWR_SpPSTH_Purple.pkl\n",
      "SWR_SpPSTH_ThreeBlueCrossesOK.pkl\n",
      "SWR_SpPSTH_ThreeColDotsOK.pkl\n",
      "SWR_CaPSTH_Purple.pkl\n",
      "SWR_CaPSTH_ThreeColDotsOK.pkl\n",
      "SWR_Global_Purple.pkl\n",
      "SWR_Global_ThreeColDotsOK.pkl\n",
      "SWR_SpPSTH_Purple.pkl\n",
      "SWR_SpPSTH_ThreeColDotsOK.pkl\n",
      "805 L2&3 neurons recorded\n",
      "803 L2&3 neurons in the cross-registration\n",
      "10733 SWR recorded in total\n",
      "... for L1 neurons...\n",
      "SWR_CaPSTH_BlackLinesOK.pkl\n",
      "SWR_CaPSTH_BlueLinesOK.pkl\n",
      "SWR_CaPSTH_GreenDotsOK.pkl\n",
      "SWR_CaPSTH_GreenLinesOK.pkl\n",
      "SWR_CaPSTH_RedLinesOK.pkl\n",
      "SWR_Global_BlackLinesOK.pkl\n",
      "SWR_Global_BlueLinesOK.pkl\n",
      "SWR_Global_GreenDotsOK.pkl\n",
      "SWR_Global_GreenLinesOK.pkl\n",
      "SWR_Global_RedLinesOK.pkl\n",
      "SWR_SpPSTH_BlackLinesOK.pkl\n",
      "SWR_SpPSTH_BlueLinesOK.pkl\n",
      "SWR_SpPSTH_GreenDotsOK.pkl\n",
      "SWR_SpPSTH_GreenLinesOK.pkl\n",
      "SWR_SpPSTH_RedLinesOK.pkl\n",
      "SWR_CaPSTH_BlackLinesOK.pkl\n",
      "SWR_CaPSTH_BlueLinesOK.pkl\n",
      "SWR_CaPSTH_GreenDotsOK.pkl\n",
      "SWR_Global_BlackLinesOK.pkl\n",
      "SWR_Global_BlueLinesOK.pkl\n",
      "SWR_Global_GreenDotsOK.pkl\n",
      "SWR_SpPSTH_BlackLinesOK.pkl\n",
      "SWR_SpPSTH_BlueLinesOK.pkl\n",
      "SWR_SpPSTH_GreenDotsOK.pkl\n",
      "180 L1 neurons recorded\n",
      "179 L1 neurons in the cross-registration\n",
      "7640 SWR recorded in total\n"
     ]
    }
   ],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Osc\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=1 # 1 if CGP Experiment, 0 if Baseline Experiment\n",
    "\n",
    "suffix='_AH_wRealTS_forCGP'\n",
    "\n",
    "Local=1\n",
    "\n",
    "#choosed_folder='Osc_2024_08_04_10_35_33_AH_FINAL' if DrugExperiment else 'Osc_2024_08_04_09_24_52_AH_FINAL'\n",
    "choosed_folder1='Osc_2024_09_03_17_21_50_AH_wRealTS' # for Baseline Expe\n",
    "choosed_folder2='Osc_2024_09_03_18_31_36_AH_wRealTS' # for CGP Expe\n",
    "\n",
    "PrefVigExcel_file = 'AVG_VigSt_2024-09-03_11_16_02_AB_wRealTS_forCGP' if DrugExperiment else 'AVG_VigSt_2024-09-03_11_00_49_AB_wRealTS'\n",
    "#PrefVigExcel_file = 'AVG_VigSt_2024-08-22_13_50_33_AB_Clustering_forCGP' if DrugExperiment else 'AVG_VigSt_2024-08-22_13_28_19_AB_Clustering'\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import sem\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def column_with_max_single_per_row(row):\n",
    "    max_val = row.max()  # Find the max value in the row\n",
    "    max_columns = row == max_val  # Boolean Series of columns with max value\n",
    "    \n",
    "    if max_columns.sum() > 1:\n",
    "        return 'NoPref'  # More than one column has the max value\n",
    "    else:\n",
    "        return max_columns.idxmax()  # Return the name of the column with max value\n",
    "\n",
    "def divide_keys(data):\n",
    "    it=list(data.keys())[0]\n",
    "    d=data[it]\n",
    "    data[it]=d.replace(0, np.nan)\n",
    "    for sheet in list(data.keys())[1:]: \n",
    "        data[sheet].div(data[it][sheet], axis=0)\n",
    "    del data[it]\n",
    "    return data    \n",
    "\n",
    "########################################################################\n",
    "        # SCRIPT 27AB_GrandAverages&Stats_for_Osc\n",
    "########################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory1 = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\" \n",
    "directory1= f'{InitialDirectory1}/{choosed_folder1}'\n",
    "InitialDirectory2 =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\" if Local else \"/crnldata/waking///L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\"\n",
    "directory2= f'{InitialDirectory2}/{choosed_folder2}'\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/AVG_Osc_{FolderNameSave}{suffix}/\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.ipynb\"\n",
    "destination_file_path = f\"{destination_folder}/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "NrSubtypeList=['L2&3', 'L1']\n",
    "CTX=['PFC_', 'S1_', 'S1PFC_']\n",
    "Coupling=['', 'UnCoupled', 'Coupled']\n",
    "OscList=['Spdl', 'SWR']#, 'DS']\n",
    "Drugs= ['Baseline', 'CGP'] if DrugExperiment else ['Baseline']\n",
    "\n",
    "for o, Osc in enumerate(OscList): \n",
    "    \n",
    "    print(Osc, 'oscillations analysis...')\n",
    "\n",
    "    AllOscStatut=pd.DataFrame()\n",
    "    AllOscDuration=pd.DataFrame()\n",
    "    AllOscCoupling=pd.DataFrame()\n",
    "    AllGlobalSpindle=pd.DataFrame()\n",
    "    AllOscStartLocation=pd.DataFrame()\n",
    "    \n",
    "    AllOscStatutS1=pd.DataFrame()\n",
    "    AllOscDurationS1=pd.DataFrame()\n",
    "    AllOscCouplingS1=pd.DataFrame()\n",
    "\n",
    "    AllOscStatutPFC=pd.DataFrame()\n",
    "    AllOscDurationPFC=pd.DataFrame()\n",
    "    AllOscCouplingPFC=pd.DataFrame()\n",
    "\n",
    "    AllOscStatutS1PFC=pd.DataFrame()\n",
    "    AllOscDurationS1PFC=pd.DataFrame()\n",
    "    AllOscCouplingS1PFC=pd.DataFrame()\n",
    "\n",
    "    for NrSubtype in NrSubtypeList: \n",
    "        \n",
    "        print('... for', NrSubtype, 'neurons...')\n",
    "        \n",
    "        # Initialize an empty list to store the dataframes\n",
    "        dfs = []\n",
    "        dfs2_per_sheet = {}\n",
    "        dfs3_per_sheet = {}\n",
    "        filtered_df=[]\n",
    "\n",
    "        if NrSubtype=='L1':\n",
    "            MiceList=['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK', 'GreenLinesOK', 'RedLinesOK']\n",
    "        else:\n",
    "            MiceList=['Purple', 'ThreeColDotsOK', 'ThreeBlueCrossesOK']\n",
    "\n",
    "        nametofind=f'{Osc}_Global'\n",
    "        nametofind2=f'{Osc}_CaPSTH'\n",
    "        nametofind3=f'{Osc}_SpPSTH'\n",
    "        #nametofind4=f'{OscillationList[o]}_{Cortex}_SpikeSum'\n",
    "\n",
    "        # Recursively traverse the directory structure\n",
    "        for directory in [directory1, directory2]:\n",
    "            for root, _, files in os.walk(directory):\n",
    "                for filename in files:\n",
    "                    # Check if the file is an Excel file and contains the specified name\n",
    "                    if filename.endswith('.pkl') and nametofind in filename:\n",
    "                        if any(name in filename for name in MiceList):  \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the file and append it to the list\n",
    "                            with open(filepath, 'rb') as pickle_file:\n",
    "                                df = pickle.load(pickle_file)\n",
    "                            dfs.append(df)\n",
    "                            print(filename)\n",
    "                    if filename.endswith('.pkl') and nametofind2 in filename: \n",
    "                        if any(name in filename for name in MiceList): \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            with open(filepath, 'rb') as pickle_file:\n",
    "                                df = pickle.load(pickle_file)\n",
    "                            for key, value in df.items():\n",
    "                                if key in dfs2_per_sheet:\n",
    "                                    dfs2_per_sheet[key]=pd.concat([dfs2_per_sheet[key],value], ignore_index=False, axis=0)\n",
    "                                else:\n",
    "                                    dfs2_per_sheet[key]=value\n",
    "                            print(filename)\n",
    "                    if filename.endswith('.pkl') and nametofind3 in filename: \n",
    "                        if any(name in filename for name in MiceList): \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            with open(filepath, 'rb') as pickle_file:\n",
    "                                df = pickle.load(pickle_file)\n",
    "                            for key, value in df.items():\n",
    "                                if key in dfs3_per_sheet:\n",
    "                                    dfs3_per_sheet[key]=pd.concat([dfs3_per_sheet[key],value], ignore_index=False,axis=0)\n",
    "                                else:\n",
    "                                    dfs3_per_sheet[key]=value\n",
    "                            print(filename)\n",
    "\n",
    "        ###########################################################################\n",
    "                                    ##### GLOBAL #####\n",
    "        ###########################################################################\n",
    "\n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(str)\n",
    "        combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "        combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "\n",
    "        combined_df[f'{Osc}Statut'] = combined_df[f'{Osc}Statut'].astype(str)\n",
    "\n",
    "        combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "        combined_df['Session_ID'] = combined_df['Mice'] + combined_df['Session'].astype(str)\n",
    "\n",
    "        unique_count = combined_df['Unit_ID'].nunique()\n",
    "        print(unique_count, f'{NrSubtype} neurons recorded') \n",
    "\n",
    "        # Remove non defined Unique Units \n",
    "        combined_df = combined_df[combined_df['Unique_Unit'] != '[]']\n",
    "        combined_df = combined_df.dropna(subset=['Unique_Unit'])\n",
    "        unique_count = combined_df['Unit_ID'].nunique()\n",
    "        print(unique_count, f'{NrSubtype} neurons in the cross-registration') \n",
    "        \n",
    "        combined_df[f'{Osc}_ID'] = combined_df['Mice'] + combined_df['Session'] + combined_df[f'{Osc}Number'].astype(str)\n",
    "        \n",
    "        unique_count = combined_df[f'{Osc}_ID'].nunique()\n",
    "        print(unique_count, f'{Osc} recorded in total')\n",
    "\n",
    "        filenameOut = f'{folder_to_save}/{NrSubtype}_{Osc}_Global.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "        combined_df.to_excel(writer)\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "        # Merge PSTH and do the average\n",
    "\n",
    "        dfs2_per_sheet2 = {sheet_name: df.groupby(df.index).sum() for sheet_name, df in dfs2_per_sheet.items()} #cause was concatenated in the 0 axis\n",
    "        dfs2_per_sheet=divide_keys(dfs2_per_sheet2)\n",
    "        for sheet_name, df in dfs2_per_sheet.items():\n",
    "            df = df.sort_index(axis=1)\n",
    "            df = df.sort_index(axis=0)\n",
    "            dfs2_per_sheet[sheet_name]=df\n",
    "\n",
    "        dfs3_per_sheet3 = {sheet_name: df.groupby(df.index).sum() for sheet_name, df in dfs3_per_sheet.items()} #cause was concatenated in the 0 axis\n",
    "        dfs3_per_sheet=divide_keys(dfs3_per_sheet3)\n",
    "        for sheet_name, df in dfs3_per_sheet.items():\n",
    "            df = df.sort_index(axis=1)\n",
    "            df = df.sort_index(axis=0)\n",
    "            dfs3_per_sheet[sheet_name]=df\n",
    "\n",
    "        for drug in Drugs: \n",
    "            \n",
    "            combined_df_Drug = combined_df.copy()\n",
    "            try:\n",
    "                combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == drug]\n",
    "            except: \n",
    "                combined_df_Drug=combined_df_Drug\n",
    "            \n",
    "            folder_to_save2= f'{folder_to_save}/{drug}/'\n",
    "            if NrSubtype=='L2&3' and o==0 :\n",
    "                os.makedirs(folder_to_save2)\n",
    "\n",
    "            #####################\n",
    "            # PREFERENCE #\n",
    "            #####################\n",
    "                        \n",
    "            # Load the Excel file and read each sheet into a separate DataFrame\n",
    "            excel_file = f'//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/{PrefVigExcel_file}/Baseline/{NrSubtype}_ActivityPreference.xlsx'\n",
    "            sheets = pd.read_excel(excel_file, sheet_name=None, header=None, index_col=0)  # sheet_name=None reads all sheets\n",
    "            AllUnits=combined_df_Drug['Unit_ID'].unique()\n",
    "            sheets['AllUnits']=pd.DataFrame(AllUnits)\n",
    "\n",
    "            # Print the names of the sheets and their corresponding DataFrames\n",
    "            for List_name, listI in sheets.items():\n",
    "                \n",
    "                thelist=listI[0].tolist() if List_name=='AllUnits' else listI[1].tolist()\n",
    "                filtered_df = combined_df_Drug[combined_df_Drug['Unit_ID'].isin(thelist)]\n",
    "                List_name=List_name.replace( '\\\\', '/')\n",
    "\n",
    "                if NrSubtype=='L2&3' and o==0:\n",
    "                    new_folder= f\"{folder_to_save2}/{List_name}/\"\n",
    "                    os.makedirs(new_folder)\n",
    "\n",
    "                ###########################################################################\n",
    "                                            ##### PSTH #####\n",
    "                ###########################################################################\n",
    "\n",
    "                filenameOutAVG = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_AVG&SEM.xlsx'\n",
    "                excel_writerAVG = pd.ExcelWriter(filenameOutAVG)\n",
    "                filenameOutAVGBSL = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_BSL_AVG&SEM.xlsx'\n",
    "                excel_writerAVGBSL = pd.ExcelWriter(filenameOutAVGBSL)\n",
    "\n",
    "                filenameOutMean = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_During.xlsx'\n",
    "                excel_writerMean= pd.ExcelWriter(filenameOutMean)\n",
    "                filenameOutMeanBSL = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_BSL_During.xlsx'\n",
    "                excel_writerMeanBSL= pd.ExcelWriter(filenameOutMeanBSL)\n",
    "\n",
    "                FileNames= ['CaPSTH', 'SpPSTH'] # 'SpikeGrandSum',\n",
    "                FileNamesNormalized= ['BSL_CaPSTH', 'BSL_SpPSTH'] #, 'Baselined_SpikeGrandSum',\n",
    "                dfs_per_sheet=[dfs2_per_sheet,dfs3_per_sheet]# dfs4_per_sheet, ] #Ca &Sp\n",
    "\n",
    "                for d, df_per_sheet in enumerate(dfs_per_sheet):\n",
    "\n",
    "                    FileName=FileNames[d]\n",
    "                    FileNameNormalized=FileNamesNormalized[d]\n",
    "                    BigArray=pd.DataFrame()\n",
    "                    BigArrayBSL=pd.DataFrame()\n",
    "                    AVGArray=pd.DataFrame()\n",
    "                    AVGArrayBSL=pd.DataFrame()\n",
    "\n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_{FileName}.xlsx'\n",
    "                    excel_writer = pd.ExcelWriter(filenameOut)\n",
    "                    \n",
    "                    filenameOutBSL = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_{FileNameNormalized}.xlsx'\n",
    "                    excel_writerBSL = pd.ExcelWriter(filenameOutBSL)\n",
    "                        \n",
    "                    for ctx in CTX:\n",
    "                        for coup in Coupling: \n",
    "\n",
    "                            ctx= '' if Osc=='SWR' else ctx\n",
    "                            \n",
    "                            Array=[]\n",
    "                            Array=pd.DataFrame(df_per_sheet[f'{ctx}{coup}{Osc}_{drug}'])\n",
    "                        \n",
    "                            # Only keep the neurons belonging to the list (All units, NREM active, REM active, etc)\n",
    "                            present_indices = [idx for idx in thelist if idx in Array.index]\n",
    "                            Array = Array.loc[present_indices] \n",
    "                        \n",
    "                            # Leave a blanck space for units not recorded in that condition\n",
    "                            missing_indexes = set(thelist) - set(Array.index)\n",
    "                            Array = Array.reindex(Array.index.union(missing_indexes))\n",
    "                            Array = Array.sort_index()\n",
    "\n",
    "                            # Reduce the array by half\n",
    "                            #Array=Array.iloc[:, Array.shape[1] // 4 : Array.shape[1] // 4 * 3] # -2.5 to 2.5 sec\n",
    "                            Array=Array.iloc[:, Array.shape[1] // 10 *4  : Array.shape[1] // 10 * 6] # -1 to 1 sec\n",
    "\n",
    "                            Array.to_excel(excel_writer, sheet_name=f'{ctx}{coup}{Osc}', index=True, header=False)\n",
    "\n",
    "                            mArray=Array.mean(axis=0)\n",
    "                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                            BigArray=pd.concat([BigArray,SmallArray], axis=1)\n",
    "\n",
    "                            SecondHalf_columns = Array.iloc[:, Array.shape[1] //2:]\n",
    "                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{ctx}{coup}{Osc}'])\n",
    "                            AVGArray=pd.concat([AVGArray,avgarray], axis=1)\n",
    "                            \n",
    "                            # Baseline signals\n",
    "                            baseline_columns = Array.iloc[:, :Array.shape[1] // 4]\n",
    "                            mean_baseline = baseline_columns.mean(axis=1)\n",
    "                            Array = Array.sub(mean_baseline, axis=0)\n",
    "                            Array.to_excel(excel_writerBSL, sheet_name=f'{ctx}{coup}{Osc}', index=True, header=False)\n",
    "\n",
    "                            mArray=Array.mean(axis=0)\n",
    "                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                            BigArrayBSL=pd.concat([BigArrayBSL,SmallArray], axis=1)\n",
    "\n",
    "                            SecondHalf_columns = Array.iloc[:, Array.shape[1]//2:]\n",
    "                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{ctx}{coup}{Osc}'])\n",
    "                            AVGArrayBSL=pd.concat([AVGArrayBSL,avgarray], axis=1)\n",
    "\n",
    "                    excel_writer.close()\n",
    "                    excel_writerBSL.close() \n",
    "                    BigArray.to_excel(excel_writerAVG, sheet_name=FileName, index=True, header=True)\n",
    "                    AVGArray.to_excel(excel_writerMean, sheet_name=FileName, index=True, header=True)\n",
    "                    BigArrayBSL.to_excel(excel_writerAVGBSL, sheet_name=FileNameNormalized, index=True, header=True)\n",
    "                    AVGArrayBSL.to_excel(excel_writerMeanBSL, sheet_name=FileNameNormalized, index=True, header=True)\n",
    "\n",
    "                excel_writerAVG.close()                   \n",
    "                excel_writerAVGBSL.close()    \n",
    "                excel_writerMean.close()                   \n",
    "                excel_writerMeanBSL.close()    \n",
    "\n",
    "        #######################\n",
    "        # Propreties Osc\n",
    "        #######################\n",
    "        filenameOut = f'{folder_to_save}/{Osc}Propreties.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "        combined_dfOsc = combined_df.drop_duplicates(subset=f'{Osc}_ID', keep='first')\n",
    "        #All Spdl\n",
    "        OscStatut = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}Statut']])\n",
    "        AllOscStatut=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "        OscDuration = combined_dfOsc.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "        AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "        OscCoupling = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'SWR_inside_Spdl']])\n",
    "        AllOscCoupling=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "        if Osc== 'Spdl':\n",
    "            GlobalSpindle = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle']])\n",
    "            AllGlobalSpindle=pd.concat([AllGlobalSpindle, GlobalSpindle], axis=0)\n",
    "            OscStartLocation = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}StartLocation']])\n",
    "            AllOscStartLocation=pd.concat([AllOscStartLocation, OscStartLocation], axis=0)\n",
    "            \"\"\"\n",
    "            #S1 Spdl\n",
    "            combined_dfOscS1=combined_dfOsc[combined_dfOsc[f'{Osc}StartLocation']=='S1' and combined_dfOscS1[f'GlobalSpindle']=='Local']\n",
    "            OscStatut = pd.crosstab(index=combined_dfOscS1['Session_ID'],columns=[combined_dfOscS1['Drug'], combined_dfOscS1[f'{Osc}Statut']])\n",
    "            AllOscStatutS1=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "            OscDuration = combined_dfOscS1.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDurationS1=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOscS1['Session_ID'],columns=[combined_dfOscS1['Drug'], combined_dfOscS1[f'SWR_inside_Spdl']])\n",
    "            AllOscCouplingS1=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "            #PFC Spdl\n",
    "            combined_dfOscPFC=combined_dfOsc[combined_dfOsc[f'{Osc}StartLocation']=='PFC' and combined_dfOscS1[f'GlobalSpindle']=='Local']\n",
    "            OscStatut = pd.crosstab(index=combined_dfOscPFC['Session_ID'],columns=[combined_dfOscPFC['Drug'], combined_dfOscPFC[f'{Osc}Statut']])\n",
    "            AllOscStatutPFC=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "            OscDuration = combined_dfOscPFC.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDurationPFC=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOscPFC['Session_ID'],columns=[combined_dfOscPFC['Drug'], combined_dfOscPFC[f'SWR_inside_Spdl']])\n",
    "            AllOscCouplingPFC=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "            #S1PFC Spdl\n",
    "            combined_dfOscS1PFC=combined_dfOsc[combined_dfOsc[combined_dfOscS1[f'GlobalSpindle']=='Global']]\n",
    "            OscStatut = pd.crosstab(index=combined_dfOscS1PFC['Session_ID'],columns=[combined_dfOscS1PFC['Drug'], combined_dfOscS1PFC[f'{Osc}Statut']])\n",
    "            AllOscStatutS1PFC=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "            OscDuration = combined_dfOscS1PFC.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDurationS1PFC=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOscS1PFC['Session_ID'],columns=[combined_dfOscS1PFC['Drug'], combined_dfOscS1PFC[f'SWR_inside_Spdl']])\n",
    "            AllOscCouplingS1PFC=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "            \"\"\"    \n",
    "\n",
    "    AllOscStatut.to_excel(writer, sheet_name=f'CouplingStatut')\n",
    "    AllOscDuration.to_excel(writer, sheet_name=f'MeanDuration')\n",
    "    AllOscCoupling.to_excel(writer, sheet_name=f'SWR_inside_Spdl')    \n",
    "    if Osc== 'Spdl':\n",
    "        AllGlobalSpindle.to_excel(writer, sheet_name=f'GlobalSpindle')\n",
    "        AllOscStartLocation.to_excel(writer, sheet_name=f'StartLocation')\n",
    "        \"\"\"\n",
    "        AllOscStatutS1.to_excel(writer, sheet_name=f'S1_CouplingStatut')\n",
    "        AllOscDurationS1.to_excel(writer, sheet_name=f'S1_MeanDuration')\n",
    "        AllOscCouplingS1.to_excel(writer, sheet_name=f'S1_SWR_inside_Spdl') \n",
    "        \n",
    "        AllOscStatutPFC.to_excel(writer, sheet_name=f'PFC_CouplingStatut')\n",
    "        AllOscDurationPFC.to_excel(writer, sheet_name=f'PFC_MeanDuration')\n",
    "        AllOscCouplingPFC.to_excel(writer, sheet_name=f'PFC_SWR_inside_Spdl') \n",
    "        \n",
    "        AllOscStatutS1PFC.to_excel(writer, sheet_name=f'S1PFC_CouplingStatut')\n",
    "        AllOscDurationS1PFC.to_excel(writer, sheet_name=f'S1PFC_MeanDuration')\n",
    "        AllOscCouplingS1PFC.to_excel(writer, sheet_name=f'S1PFC_SWR_inside_Spdl')\n",
    "        \"\"\"\n",
    "\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian311new2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
