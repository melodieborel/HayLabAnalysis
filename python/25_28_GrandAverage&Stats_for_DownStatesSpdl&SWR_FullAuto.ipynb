{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWR oscillations analysis...\n",
      "... for L2&3 neurons...\n",
      "SWR_Global_Purple.pkl\n",
      "SWR_Global_ThreeBlueCrossesOK.pkl\n",
      "SWR_Global_ThreeColDotsOK.pkl\n",
      "333 L2&3 neurons recorded\n",
      "332 L2&3 neurons in the cross-registration\n",
      "8554 SWR recorded in total\n",
      "CaPSTHSWR_Baseline\n",
      "CaPSTHSWR_UnCoupledBaseline\n",
      "CaPSTHSWR_CoupledBaseline\n",
      "CaPSTHSWR_Baseline\n",
      "CaPSTHSWR_UnCoupledBaseline\n",
      "CaPSTHSWR_CoupledBaseline\n",
      "CaPSTHSWR_Baseline\n",
      "CaPSTHSWR_UnCoupledBaseline\n",
      "CaPSTHSWR_CoupledBaseline\n",
      "SpPSTHSWR_Baseline\n",
      "SpPSTHSWR_UnCoupledBaseline\n",
      "SpPSTHSWR_CoupledBaseline\n",
      "SpPSTHSWR_Baseline\n",
      "SpPSTHSWR_UnCoupledBaseline\n",
      "SpPSTHSWR_CoupledBaseline\n",
      "SpPSTHSWR_Baseline\n",
      "SpPSTHSWR_UnCoupledBaseline\n",
      "SpPSTHSWR_CoupledBaseline\n",
      "... for L1 neurons...\n",
      "SWR_Global_BlackLinesOK.pkl\n",
      "SWR_Global_BlueLinesOK.pkl\n",
      "SWR_Global_GreenDotsOK.pkl\n",
      "SWR_Global_GreenLinesOK.pkl\n",
      "SWR_Global_RedLinesOK.pkl\n",
      "SWR_Global_BlackLinesOK.pkl\n",
      "129 L1 neurons recorded\n",
      "129 L1 neurons in the cross-registration\n",
      "6681 SWR recorded in total\n",
      "CaPSTHSWR_Baseline\n",
      "CaPSTHSWR_UnCoupledBaseline\n",
      "CaPSTHSWR_CoupledBaseline\n",
      "CaPSTHSWR_Baseline\n",
      "CaPSTHSWR_UnCoupledBaseline\n",
      "CaPSTHSWR_CoupledBaseline\n",
      "CaPSTHSWR_Baseline\n",
      "CaPSTHSWR_UnCoupledBaseline\n",
      "CaPSTHSWR_CoupledBaseline\n",
      "SpPSTHSWR_Baseline\n",
      "SpPSTHSWR_UnCoupledBaseline\n",
      "SpPSTHSWR_CoupledBaseline\n",
      "SpPSTHSWR_Baseline\n",
      "SpPSTHSWR_UnCoupledBaseline\n",
      "SpPSTHSWR_CoupledBaseline\n",
      "SpPSTHSWR_Baseline\n",
      "SpPSTHSWR_UnCoupledBaseline\n",
      "SpPSTHSWR_CoupledBaseline\n"
     ]
    }
   ],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Osc\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=0 # 1 if CGP Experiment, 0 if Baseline Experiment\n",
    "\n",
    "suffix='_AH_DS'\n",
    "\n",
    "Local=1\n",
    "\n",
    "#choosed_folder='Osc_2024_08_04_10_35_33_AH_FINAL' if DrugExperiment else 'Osc_2024_08_04_09_24_52_AH_FINAL'\n",
    "choosed_folder1='Osc_2024_09_04_14_58_48_AH_DS' # for Baseline Expe\n",
    "choosed_folder2='Osc_2024_09_04_17_05_19_AH_DS' # for CGP Expe\n",
    "\n",
    "PrefVigExcel_file = 'AVG_VigSt_2024-09-03_11_16_02_AB_wRealTS_forCGP' if DrugExperiment else 'AVG_VigSt_2024-09-03_11_00_49_AB_wRealTS'\n",
    "#PrefVigExcel_file = 'AVG_VigSt_2024-08-22_13_50_33_AB_Clustering_forCGP' if DrugExperiment else 'AVG_VigSt_2024-08-22_13_28_19_AB_Clustering'\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import sem\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def column_with_max_single_per_row(row):\n",
    "    max_val = row.max()  # Find the max value in the row\n",
    "    max_columns = row == max_val  # Boolean Series of columns with max value\n",
    "    \n",
    "    if max_columns.sum() > 1:\n",
    "        return 'NoPref'  # More than one column has the max value\n",
    "    else:\n",
    "        return max_columns.idxmax()  # Return the name of the column with max value\n",
    "\n",
    "def divide_keys(data):\n",
    "    it=list(data.keys())[0]\n",
    "    d=data[it]\n",
    "    data[it]=d.replace(0, np.nan)\n",
    "    for sheet in list(data.keys())[1:]: \n",
    "        data[sheet].div(data[it][sheet], axis=0)\n",
    "    del data[it]\n",
    "    return data    \n",
    "\n",
    "########################################################################\n",
    "        # SCRIPT 27AB_GrandAverages&Stats_for_Osc\n",
    "########################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory1 = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis\" \n",
    "directory1= f'{InitialDirectory1}/{choosed_folder1}'\n",
    "InitialDirectory2 =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\" if Local else \"/crnldata/waking///L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis\"\n",
    "directory2= f'{InitialDirectory2}/{choosed_folder2}'\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/AVG_Osc_{FolderNameSave}{suffix}/\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.ipynb\"\n",
    "destination_file_path = f\"{destination_folder}/25_28_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "NrSubtypeList=['L2&3', 'L1']\n",
    "CTX=['PFC_', 'S1_', 'S1PFC_']\n",
    "CTX2=['PFC', 'S1', 'S1PFC']\n",
    "Coupling=['', 'UnCoupled', 'Coupled']\n",
    "OscList=['Spdl', 'SWR', 'DS']\n",
    "Drugs= ['Baseline', 'CGP'] if DrugExperiment else ['Baseline']\n",
    "\n",
    "for o, Osc in enumerate(OscList): \n",
    "    \n",
    "    print(Osc, 'oscillations analysis...')\n",
    "\n",
    "    AllOscStatut=pd.DataFrame()\n",
    "    AllOscDuration=pd.DataFrame()\n",
    "    AllOscCoupling=pd.DataFrame()\n",
    "    AllGlobalSpindle=pd.DataFrame()\n",
    "    AllOscStartLocation=pd.DataFrame()\n",
    "    \n",
    "    AllOscStatutS1=pd.DataFrame()\n",
    "    AllOscDurationS1=pd.DataFrame()\n",
    "    AllOscCouplingS1=pd.DataFrame()\n",
    "\n",
    "    AllOscStatutPFC=pd.DataFrame()\n",
    "    AllOscDurationPFC=pd.DataFrame()\n",
    "    AllOscCouplingPFC=pd.DataFrame()\n",
    "\n",
    "    AllOscStatutS1PFC=pd.DataFrame()\n",
    "    AllOscDurationS1PFC=pd.DataFrame()\n",
    "    AllOscCouplingS1PFC=pd.DataFrame()\n",
    "\n",
    "    for NrSubtype in NrSubtypeList: \n",
    "        \n",
    "        print('... for', NrSubtype, 'neurons...')\n",
    "        \n",
    "        # Initialize an empty list to store the dataframes\n",
    "        dfs = []\n",
    "        filtered_df=[]\n",
    "\n",
    "        if NrSubtype=='L1':\n",
    "            MiceList=['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK', 'GreenLinesOK', 'RedLinesOK']\n",
    "        else:\n",
    "            MiceList=['Purple', 'ThreeColDotsOK', 'ThreeBlueCrossesOK']\n",
    "\n",
    "        nametofind=f'{Osc}_Global'\n",
    "\n",
    "        ###########################################################################\n",
    "                                    ##### GLOBAL #####\n",
    "        ###########################################################################\n",
    "\n",
    "        # Recursively traverse the directory structure\n",
    "        for directory in [directory1, directory2]: #both Baseline & CGP experiments \n",
    "            for root, _, files in os.walk(directory):\n",
    "                for filename in files:\n",
    "                    # Check if the file is an Excel file and contains the specified name\n",
    "                    if filename.endswith('.pkl') and nametofind in filename:\n",
    "                        if any(name in filename for name in MiceList):  \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the file and append it to the list\n",
    "                            with open(filepath, 'rb') as pickle_file:\n",
    "                                df = pickle.load(pickle_file)\n",
    "                            dfs.append(df)\n",
    "                            print(filename)\n",
    "\n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(str)\n",
    "        combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "        combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "\n",
    "        combined_df[f'{Osc}Statut'] = combined_df[f'{Osc}Statut'].astype(str)\n",
    "\n",
    "        combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "        combined_df['Session_ID'] = combined_df['Mice'] + combined_df['Session'].astype(str)\n",
    "\n",
    "        unique_count = combined_df['Unit_ID'].nunique()\n",
    "        print(unique_count, f'{NrSubtype} neurons recorded') \n",
    "\n",
    "        # Remove non defined Unique Units \n",
    "        combined_df = combined_df[combined_df['Unique_Unit'] != '[]']\n",
    "        combined_df = combined_df.dropna(subset=['Unique_Unit'])\n",
    "        unique_count = combined_df['Unit_ID'].nunique()\n",
    "        print(unique_count, f'{NrSubtype} neurons in the cross-registration') \n",
    "        \n",
    "        combined_df[f'{Osc}_ID'] = combined_df['Mice'] + combined_df['Session'] + combined_df[f'{Osc}Number'].astype(str)\n",
    "        \n",
    "        unique_count = combined_df[f'{Osc}_ID'].nunique()\n",
    "        print(unique_count, f'{Osc} recorded in total')\n",
    "\n",
    "        filenameOut = f'{folder_to_save}/{NrSubtype}_{Osc}_Global.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "        combined_df.to_excel(writer)\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "        ###########################################################################\n",
    "                                    ##### PSTH #####\n",
    "        ###########################################################################\n",
    "\n",
    "        Data=['Ca', 'Sp']\n",
    "        for data in Data:\n",
    "            for drug in Drugs: \n",
    "                for ctx in CTX2:\n",
    "                    for coup in Coupling:  \n",
    "\n",
    "                        ctx= '' if Osc=='SWR' else ctx  \n",
    "                        \n",
    "                        locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']={}\n",
    "                        dfsPSTH_per_sheet = locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']\n",
    "                        nametofind2=f'{Osc}_{data}PSTH_{coup}{ctx}{drug}'\n",
    "        \n",
    "                        # Recursively traverse the directory structure\n",
    "                        for directory in [directory1]:\n",
    "                            for root, _, files in os.walk(directory):\n",
    "                                for filename in files:\n",
    "                                    if filename.endswith('.pkl') and nametofind2 in filename: \n",
    "                                        if any(name in filename for name in MiceList): \n",
    "                                            # Construct the full path to the file\n",
    "                                            filepath = os.path.join(root, filename)\n",
    "                                            with open(filepath, 'rb') as pickle_file:\n",
    "                                                df = pickle.load(pickle_file)\n",
    "                                            for key, value in df.items():\n",
    "                                                if key in dfsPSTH_per_sheet:\n",
    "                                                    dfsPSTH_per_sheet[key]=pd.concat([dfsPSTH_per_sheet[key],value], ignore_index=False, axis=0)\n",
    "                                                else:\n",
    "                                                    dfsPSTH_per_sheet[key]=value\n",
    "\n",
    "\n",
    "        ###########################################################################\n",
    "                                ##### PREFERENCE #####\n",
    "        ########################################################################### \n",
    "\n",
    "        for drug in Drugs: \n",
    "            \n",
    "            combined_df_Drug = combined_df.copy()\n",
    "            try:\n",
    "                combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == drug]\n",
    "            except: \n",
    "                combined_df_Drug=combined_df_Drug\n",
    "            \n",
    "            folder_to_save2= f'{folder_to_save}/{drug}/'\n",
    "            if NrSubtype=='L2&3' and o==0 :\n",
    "                os.makedirs(folder_to_save2)\n",
    "                        \n",
    "            # Load the Excel file and read each sheet into a separate DataFrame\n",
    "            excel_file = f'//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/AB_GlobalAnalysis/{PrefVigExcel_file}/Baseline/{NrSubtype}_ActivityPreference.xlsx'\n",
    "            sheets = pd.read_excel(excel_file, sheet_name=None, header=None, index_col=0)  # sheet_name=None reads all sheets\n",
    "            AllUnits=combined_df_Drug['Unit_ID'].unique()\n",
    "            sheets['AllUnits']=pd.DataFrame(AllUnits)\n",
    "\n",
    "            # Print the names of the sheets and their corresponding DataFrames\n",
    "            for List_name, listI in sheets.items():\n",
    "                \n",
    "                thelist=listI[0].tolist() if List_name=='AllUnits' else listI[1].tolist()\n",
    "                filtered_df = combined_df_Drug[combined_df_Drug['Unit_ID'].isin(thelist)]\n",
    "                List_name=List_name.replace( '\\\\', '/')\n",
    "\n",
    "                if NrSubtype=='L2&3' and o==0:\n",
    "                    new_folder= f\"{folder_to_save2}/{List_name}/\"\n",
    "                    os.makedirs(new_folder)\n",
    "\n",
    "                ###########################################################################\n",
    "                                        ##### AVERAGE PSTH #####\n",
    "                ###########################################################################\n",
    "\n",
    "                filenameOutAVG = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_AVG&SEM.xlsx'\n",
    "                excel_writerAVG = pd.ExcelWriter(filenameOutAVG)\n",
    "\n",
    "                filenameOutMean = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_During.xlsx'\n",
    "                excel_writerMean= pd.ExcelWriter(filenameOutMean)\n",
    "                \n",
    "                for data in Data:\n",
    "\n",
    "                    BigArray=pd.DataFrame()\n",
    "                    BigArrayBSL=pd.DataFrame()\n",
    "                    AVGArray=pd.DataFrame()\n",
    "                    AVGArrayBSL=pd.DataFrame()\n",
    "\n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_{Osc}_{data}PSTH.xlsx'\n",
    "                    excel_writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "                    for ctx in CTX2:\n",
    "                        for coup in Coupling:    \n",
    "                            \n",
    "                            ctx= '' if Osc=='SWR' else ctx\n",
    "                            df_per_sheet=locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']\n",
    "\n",
    "                            activatedNr=0\n",
    "                            inhibitedNr=0\n",
    "                            modulatedNr=0\n",
    "\n",
    "                            if len(df_per_sheet.keys()): # not empty\n",
    "\n",
    "                                arrayLen = 0\n",
    "                                for key, value in df_per_sheet.items():\n",
    "                                    if value.size > 0:\n",
    "                                        arrayLen = np.shape(value)[1]\n",
    "                                        break  \n",
    "\n",
    "                                Array=pd.DataFrame(columns=np.arange(0,arrayLen,1))\n",
    "\n",
    "                                for nr in df_per_sheet.keys():\n",
    "                                    \n",
    "                                    if df_per_sheet[nr].shape[0] > 10 : # at least 10 oscillations recorded\n",
    "\n",
    "                                        AVGtrace=np.nanmean((df_per_sheet[nr]), axis=0)\n",
    "                                        BaselineSTD=np.std(AVGtrace[:df_per_sheet[nr].shape[1]//4], axis=0)\n",
    "\n",
    "                                        upperThrs=np.nanmean(AVGtrace[:df_per_sheet[nr].shape[1]//4], axis=0) + BaselineSTD*2\n",
    "                                        lowerThrs=np.nanmean(AVGtrace[:df_per_sheet[nr].shape[1]//4], axis=0) - BaselineSTD*2\n",
    "\n",
    "                                        AVGbefore=np.nanmean(AVGtrace[df_per_sheet[nr].shape[1]//4:df_per_sheet[nr].shape[1]//4*2], axis=0)\n",
    "                                        AVGearly=np.nanmean(AVGtrace[df_per_sheet[nr].shape[1]//4*2:df_per_sheet[nr].shape[1]//4*3], axis=0)\n",
    "                                        AVGlate=np.nanmean(AVGtrace[df_per_sheet[nr].shape[1]//4*3:df_per_sheet[nr].shape[1]//4*4], axis=0)\n",
    "\n",
    "                                        if AVGbefore > upperThrs or AVGearly > upperThrs or AVGlate > upperThrs :\n",
    "                                            activatedNr +=1\n",
    "                                            modulatedNr=1\n",
    "                                        if AVGbefore < lowerThrs or AVGearly < lowerThrs or AVGlate < lowerThrs :\n",
    "                                            inhibitedNr +=1\n",
    "                                            modulatedNr=1\n",
    "\n",
    "                                        Array.loc[nr]=AVGtrace\n",
    "                                \n",
    "                                # Only keep the neurons belonging to the list (All units, NREM active, REM active, etc)\n",
    "                                present_indices = [idx for idx in thelist if idx in Array.index]\n",
    "                                Array = Array.loc[present_indices] \n",
    "\n",
    "                                # Leave a blanck space for units not recorded in that condition\n",
    "                                missing_indexes = set(thelist) - set(Array.index)\n",
    "                                Array = Array.reindex(Array.index.union(missing_indexes))\n",
    "                                Array = Array.sort_index()\n",
    "\n",
    "                                # Reduce the array by half\n",
    "                                #Array=Array.iloc[:, Array.shape[1] // 4 : Array.shape[1] // 4 * 3] # -2.5 to 2.5 sec\n",
    "                                Array=Array.iloc[:, Array.shape[1] // 10 *4  : Array.shape[1] // 10 * 6] # -1 to 1 sec\n",
    "\n",
    "                                Array.to_excel(excel_writer, sheet_name=f'{ctx}{coup}{Osc}', index=True, header=False)\n",
    "\n",
    "                                mArray=Array.mean(axis=0)\n",
    "                                semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                                icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                                SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                                BigArray=pd.concat([BigArray,SmallArray], axis=1)\n",
    "\n",
    "                                SecondHalf_columns = Array.iloc[:, Array.shape[1] //2:]\n",
    "                                mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                                avgarray=pd.DataFrame(mean_baseline, columns=[f'{ctx}{coup}{Osc}'])\n",
    "                                AVGArray=pd.concat([AVGArray,avgarray], axis=1)\n",
    "                                \n",
    "                                # Baseline signals\n",
    "                                baseline_columns = Array.iloc[:, :Array.shape[1] // 4]\n",
    "                                mean_baseline = baseline_columns.mean(axis=1)\n",
    "                                Array = Array.sub(mean_baseline, axis=0)\n",
    "                                Array.to_excel(excel_writer, sheet_name=f'BSL_{ctx}{coup}{Osc}', index=True, header=False)\n",
    "\n",
    "                                mArray=Array.mean(axis=0)\n",
    "                                semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                                icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                                SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                                BigArrayBSL=pd.concat([BigArrayBSL,SmallArray], axis=1)\n",
    "\n",
    "                                SecondHalf_columns = Array.iloc[:, Array.shape[1]//2:]\n",
    "                                mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                                avgarray=pd.DataFrame(mean_baseline, columns=[f'{ctx}{coup}{Osc}'])\n",
    "                                AVGArrayBSL=pd.concat([AVGArrayBSL,avgarray], axis=1)\n",
    "\n",
    "                    excel_writer.close()\n",
    "\n",
    "                    BigArrayBSL.to_excel(excel_writerAVG, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                    AVGArrayBSL.to_excel(excel_writerMean, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "\n",
    "                    BigArray.to_excel(excel_writerAVG, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                    AVGArray.to_excel(excel_writerMean, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "\n",
    "                excel_writerAVG.close()                   \n",
    "                excel_writerMean.close()                   \n",
    "\n",
    "        #######################\n",
    "        # Propreties Osc\n",
    "        #######################\n",
    "        filenameOut = f'{folder_to_save}/{Osc}Propreties.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "        combined_dfOsc = combined_df.drop_duplicates(subset=f'{Osc}_ID', keep='first')\n",
    "        #All Spdl\n",
    "        OscStatut = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}Statut']])\n",
    "        AllOscStatut=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "        OscDuration = combined_dfOsc.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "        AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "        if Osc== 'Spdl' or Osc== 'SWR':\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'SWR_inside_Spdl']])\n",
    "            AllOscCoupling=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "        if Osc== 'Spdl':\n",
    "            GlobalSpindle = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle']])\n",
    "            AllGlobalSpindle=pd.concat([AllGlobalSpindle, GlobalSpindle], axis=0)\n",
    "            OscStartLocation = pd.crosstab(index=combined_dfOsc['Session_ID'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}StartLocation']])\n",
    "            AllOscStartLocation=pd.concat([AllOscStartLocation, OscStartLocation], axis=0)\n",
    "            \"\"\"\n",
    "            #S1 Spdl\n",
    "            combined_dfOscS1=combined_dfOsc[combined_dfOsc[f'{Osc}StartLocation']=='S1' and combined_dfOscS1[f'GlobalSpindle']=='Local']\n",
    "            OscStatut = pd.crosstab(index=combined_dfOscS1['Session_ID'],columns=[combined_dfOscS1['Drug'], combined_dfOscS1[f'{Osc}Statut']])\n",
    "            AllOscStatutS1=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "            OscDuration = combined_dfOscS1.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDurationS1=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOscS1['Session_ID'],columns=[combined_dfOscS1['Drug'], combined_dfOscS1[f'SWR_inside_Spdl']])\n",
    "            AllOscCouplingS1=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "            #PFC Spdl\n",
    "            combined_dfOscPFC=combined_dfOsc[combined_dfOsc[f'{Osc}StartLocation']=='PFC' and combined_dfOscS1[f'GlobalSpindle']=='Local']\n",
    "            OscStatut = pd.crosstab(index=combined_dfOscPFC['Session_ID'],columns=[combined_dfOscPFC['Drug'], combined_dfOscPFC[f'{Osc}Statut']])\n",
    "            AllOscStatutPFC=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "            OscDuration = combined_dfOscPFC.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDurationPFC=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOscPFC['Session_ID'],columns=[combined_dfOscPFC['Drug'], combined_dfOscPFC[f'SWR_inside_Spdl']])\n",
    "            AllOscCouplingPFC=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "\n",
    "            #S1PFC Spdl\n",
    "            combined_dfOscS1PFC=combined_dfOsc[combined_dfOsc[combined_dfOscS1[f'GlobalSpindle']=='Global']]\n",
    "            OscStatut = pd.crosstab(index=combined_dfOscS1PFC['Session_ID'],columns=[combined_dfOscS1PFC['Drug'], combined_dfOscS1PFC[f'{Osc}Statut']])\n",
    "            AllOscStatutS1PFC=pd.concat([AllOscStatut, OscStatut], axis=0)\n",
    "            OscDuration = combined_dfOscS1PFC.pivot_table(index='Session_ID', columns='Drug', values=f'{Osc}Duration', aggfunc='mean')\n",
    "            AllOscDurationS1PFC=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "            OscCoupling = pd.crosstab(index=combined_dfOscS1PFC['Session_ID'],columns=[combined_dfOscS1PFC['Drug'], combined_dfOscS1PFC[f'SWR_inside_Spdl']])\n",
    "            AllOscCouplingS1PFC=pd.concat([AllOscCoupling, OscCoupling], axis=0)\n",
    "            \"\"\"    \n",
    "\n",
    "    AllOscStatut.to_excel(writer, sheet_name=f'CouplingStatut')\n",
    "    AllOscDuration.to_excel(writer, sheet_name=f'MeanDuration')\n",
    "    if Osc== 'Spdl' or Osc== 'SWR':\n",
    "        AllOscCoupling.to_excel(writer, sheet_name=f'SWR_inside_Spdl')    \n",
    "    if Osc== 'Spdl':\n",
    "        AllGlobalSpindle.to_excel(writer, sheet_name=f'GlobalSpindle')\n",
    "        AllOscStartLocation.to_excel(writer, sheet_name=f'StartLocation')\n",
    "        \"\"\"\n",
    "        AllOscStatutS1.to_excel(writer, sheet_name=f'S1_CouplingStatut')\n",
    "        AllOscDurationS1.to_excel(writer, sheet_name=f'S1_MeanDuration')\n",
    "        AllOscCouplingS1.to_excel(writer, sheet_name=f'S1_SWR_inside_Spdl') \n",
    "        \n",
    "        AllOscStatutPFC.to_excel(writer, sheet_name=f'PFC_CouplingStatut')\n",
    "        AllOscDurationPFC.to_excel(writer, sheet_name=f'PFC_MeanDuration')\n",
    "        AllOscCouplingPFC.to_excel(writer, sheet_name=f'PFC_SWR_inside_Spdl') \n",
    "        \n",
    "        AllOscStatutS1PFC.to_excel(writer, sheet_name=f'S1PFC_CouplingStatut')\n",
    "        AllOscDurationS1PFC.to_excel(writer, sheet_name=f'S1PFC_MeanDuration')\n",
    "        AllOscCouplingS1PFC.to_excel(writer, sheet_name=f'S1PFC_SWR_inside_Spdl')\n",
    "        \"\"\"\n",
    "\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian311new2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
