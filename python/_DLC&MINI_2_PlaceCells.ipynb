{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect place cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import bisect\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "import warnings\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.signal import resample\n",
    "from scipy.stats import sem\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "%matplotlib widget\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#%reset\n",
    "from scipy.interpolate import interp1d\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def remove_outliers_avg_filter(data):\n",
    "    data = np.array(data, dtype=float)  # Ensure NumPy array with float type\n",
    "    filtered_data = np.copy(data)  # Copy to avoid modifying original data\n",
    "    for i in range(len(data)):\n",
    "        if not np.isnan(data[i]):  # Skip valid values\n",
    "            continue\n",
    "        # Find the closest previous non-NaN value\n",
    "        prev_idx = i - 1\n",
    "        while prev_idx >= 0 and np.isnan(data[prev_idx]):\n",
    "            prev_idx -= 1        \n",
    "        # Find the closest next non-NaN value\n",
    "        next_idx = i + 1\n",
    "        while next_idx < len(data) and np.isnan(data[next_idx]):\n",
    "            next_idx += 1\n",
    "        # Compute average if both values exist\n",
    "        if prev_idx >= 0 and next_idx < len(data):\n",
    "            filtered_data[i] = (data[prev_idx] + data[next_idx]) / 2\n",
    "        # If neither exists, NaN remains\n",
    "    return filtered_data\n",
    "\n",
    "def find_closest_index_sorted(arr, target):\n",
    "    idx = bisect.bisect_left(arr, target)  # Find the insertion point\n",
    "    if idx == 0:\n",
    "        return 0\n",
    "    if idx == len(arr):\n",
    "        return len(arr) - 1\n",
    "    before = idx - 1\n",
    "    after = idx\n",
    "    return before if abs(arr[before] - target) <= abs(arr[after] - target) else after\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "def detect_longest_lowest_sequence(arr, margin=0):\n",
    "    min_val = np.nanmin(arr)  # Find minimum value\n",
    "    threshold = min_val + margin  # Define threshold based on margin    \n",
    "    # Get indices where values are within the threshold\n",
    "    min_indices = np.where(arr <= threshold)[0]\n",
    "    # Identify consecutive sequences\n",
    "    longest_sequence = None\n",
    "    if len(min_indices) > 0:\n",
    "        start = min_indices[0]\n",
    "        max_duration = 0  # Track longest duration        \n",
    "        for i in range(1, len(min_indices)):\n",
    "            if min_indices[i] != min_indices[i - 1] + 1:  # Not consecutive\n",
    "                duration = min_indices[i - 1] - start + 1\n",
    "                if duration > max_duration:\n",
    "                    max_duration = duration\n",
    "                    longest_sequence = (start, min_indices[i - 1], duration)\n",
    "                start = min_indices[i]  # Reset start index        \n",
    "        # Check last detected sequence\n",
    "        duration = min_indices[-1] - start + 1\n",
    "        if duration > max_duration:\n",
    "            longest_sequence = (start, min_indices[-1], duration)\n",
    "    return min_val, threshold, longest_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"C:/Users/Manip2/SCRIPTS/minian/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian_path = os.path.join(os.path.abspath('..'),'minian')\n",
    "print(\"The folder used for minian procedures is : {}\".format(minian_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(minian_path)\n",
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the minian folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dpath either from a previous run or from a previous notebook\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "    dpath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Folder with videos</b>\", layout=widgets.Layout(width='100%'))\n",
    "display(fc1)\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import spatial map, Ca2+ traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice=Path(dpath).parent.parent.parent.parent.parent.name\n",
    "date=Path(dpath).parent.parent.parent.name\n",
    "sessiontype=Path(dpath).parent.parent.name\n",
    "hour=Path(dpath).parent.name\n",
    "print(mice, '-',date, '-', sessiontype ,'-', hour)\n",
    "\n",
    "\n",
    "minianversion = 'minian'\n",
    "try: # tries to retrieve minianversion either from a previous run or from a previous notebook\n",
    "    %store -r minianversion\n",
    "except:\n",
    "    print(\"the minian folder to use was not defined in store\")\n",
    "    minianversion = 'minian' #'minianAB' # or 'minian_intermediate'\n",
    "    %store minianversion\n",
    "\n",
    "folderMouse = Path(os.path.join(dpath,minianversion))\n",
    "print(folderMouse)\n",
    "minian_ds = open_minian(folderMouse)\n",
    "\n",
    "StampsMiniscopeFile = Path(os.path.join(dpath, f'timeStamps.csv'))\n",
    "tsmini=pd.read_csv(StampsMiniscopeFile)['Time Stamp (ms)']\n",
    "minian_freq=round(1/np.mean(np.diff(np.array(tsmini)/1000)))\n",
    "print('Miniscope sample rate =', minian_freq, 'Hz')\n",
    "\n",
    "Ao = minian_ds['A']\n",
    "Co = minian_ds['C']\n",
    "\n",
    "try: \n",
    "    TodropFile = folderMouse / f'TodropFileAB.json'\n",
    "    with open(TodropFile, 'r') as f:\n",
    "        unit_to_drop = json.load(f)\n",
    "except:\n",
    "    TodropFile = folderMouse.parent / f'TodropFileAB.json'\n",
    "    with open(TodropFile, 'r') as f:\n",
    "        unit_to_drop = json.load(f)\n",
    "    \n",
    "C=Co.drop_sel(unit_id=unit_to_drop)\n",
    "A=Ao.drop_sel(unit_id=unit_to_drop)\n",
    "\n",
    "idloc = A.idxmax(\"unit_id\")\n",
    "Hmax = A.idxmax(\"height\")\n",
    "Hmax2 = Hmax.max(\"width\")\n",
    "\n",
    "Wmax = A.idxmax(\"width\")\n",
    "Wmax2 = Wmax.max(\"height\")\n",
    "coord1 = Wmax2.to_series()\n",
    "coord2 = Hmax2.to_series()\n",
    "\n",
    "a = pd.concat([coord1,coord2], axis=1)\n",
    "unit = len(a)\n",
    "print(\"{} units have been found\".format(unit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import DeepLabCut data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "pixel_to_cm = 2.25  \n",
    "table_center_x, table_center_y = 313, 283  # Center of the cheeseboard table on the video\n",
    "table_center_x, table_center_y = 300, 270  # Center of the cheeseboard table on the video\n",
    "table_radius = 290 / 2\n",
    "\n",
    "# Define functions\n",
    "def calculate_relative_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "def calculate_distance_run(x_coords, y_coords):\n",
    "    distances = np.sqrt(np.diff(x_coords) ** 2 + np.diff(y_coords) ** 2)\n",
    "    for i in range(1, len(distances) - 1):\n",
    "        if np.isnan(distances[i]):\n",
    "            neighbors = [distances[i-1], distances[i+1]]\n",
    "            distances[i] = np.mean([x for x in neighbors if not np.isnan(x)])\n",
    "    total_distance_cm = np.nansum(distances) / pixel_to_cm  # Convert to cm\n",
    "    return total_distance_cm, distances\n",
    "\n",
    "def find_long_non_nan_sequences(arr, min_length=100):\n",
    "    mask = ~np.isnan(arr)  # True for non-NaN values\n",
    "    diff = np.diff(np.concatenate(([0], mask.astype(int), [0])))  # Add padding to detect edges\n",
    "    starts = np.where(diff == 1)[0]  # Where a sequence starts\n",
    "    ends = np.where(diff == -1)[0]   # Where a sequence ends\n",
    "    sequences = [arr[start:end] for start, end in zip(starts, ends) if (end - start) > min_length]\n",
    "    return sequences\n",
    "\n",
    "def remove_outliers_median_filter(data, window=1):\n",
    "    data = np.array(data, dtype=float)  # Ensure NumPy array with float type\n",
    "    filtered_data = np.copy(data)  # Copy to avoid modifying original data\n",
    "    half_window = window // 2\n",
    "    for i in range(len(data)):\n",
    "        # Define window range, ensuring it doesn't exceed bounds\n",
    "        start = max(0, i - half_window)\n",
    "        end = min(len(data), i + half_window + 1)\n",
    "        # Extract local values in window\n",
    "        local_values = data[start:end]\n",
    "        # Check if the window contains at least one non-NaN value\n",
    "        if np.all(np.isnan(local_values)):\n",
    "            median_value = np.nan  # Keep NaN if no valid numbers\n",
    "        else:\n",
    "            median_value = np.nanmedian(local_values)  # Compute median ignoring NaNs\n",
    "        # Replace only if the current value is not NaN\n",
    "        if not np.isnan(data[i]):\n",
    "            filtered_data[i] = median_value\n",
    "    return filtered_data\n",
    "\n",
    "def replace_high_speed_points_with_nan(x, y, speed_threshold):\n",
    "    x = np.array(x, dtype='float')\n",
    "    y = np.array(y, dtype='float')\n",
    "    # Compute speed between consecutive points\n",
    "    dx = np.diff(x)\n",
    "    dy = np.diff(y)\n",
    "    speeds = np.sqrt(dx**2 + dy**2)\n",
    "    # Create mask for speed exceeding threshold\n",
    "    high_speed_mask = speeds > speed_threshold\n",
    "    # We mark i+1 as NaN if speed between them is too high\n",
    "    x_out = x.copy()\n",
    "    y_out = y.copy()\n",
    "    for i in range(len(high_speed_mask)):\n",
    "        if high_speed_mask[i]:\n",
    "            # Only mark the faster of the two points\n",
    "            if i > 0 and i < len(x) - 1:\n",
    "                if speeds[i] > speeds[i - 1]:\n",
    "                    x_out[i + 1] = np.nan\n",
    "                    y_out[i + 1] = np.nan\n",
    "                else:\n",
    "                    x_out[i] = np.nan\n",
    "                    y_out[i] = np.nan\n",
    "    return x_out, y_out\n",
    "\n",
    "def interpolate_2d_path(x, y, kind='linear', fill='extrapolate'):\n",
    "    x = np.array(x, dtype='float')\n",
    "    y = np.array(y, dtype='float')\n",
    "    indices = np.arange(len(x))\n",
    "    valid_mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    if np.sum(valid_mask) < 2:\n",
    "        raise ValueError(\"Not enough valid points to interpolate/extrapolate.\")\n",
    "    interp_x = interp1d(indices[valid_mask], x[valid_mask], kind=kind, fill_value=fill, bounds_error=False)\n",
    "    interp_y = interp1d(indices[valid_mask], y[valid_mask], kind=kind, fill_value=fill, bounds_error=False)\n",
    "    x_filled = x.copy()\n",
    "    y_filled = y.copy()\n",
    "    nan_mask = np.isnan(x) | np.isnan(y)\n",
    "    x_filled[nan_mask] = interp_x(indices[nan_mask])\n",
    "    y_filled[nan_mask] = interp_y(indices[nan_mask])\n",
    "    return x_filled, y_filled\n",
    "\n",
    "def limit_speed(x, y, max_speed):\n",
    "    dx = np.diff(x.copy())\n",
    "    dy = np.diff(y.copy())\n",
    "    speeds = np.sqrt(dx**2 + dy**2)\n",
    "    for i,t in enumerate(speeds):\n",
    "        if t > max_speed:        \n",
    "            x[i+1] = x[i] \n",
    "            y[i+1] = y[i] \n",
    "            x[i+2] = x[i] \n",
    "            y[i+2] = y[i] \n",
    "    return x, y\n",
    "\n",
    "def remove_short_sequences(arr, max_len=10):\n",
    "    arr = np.array(arr, dtype='float')\n",
    "    result = arr.copy()\n",
    "    is_value = ~np.isnan(arr)\n",
    "    i = 0\n",
    "    while i < len(arr):\n",
    "        if is_value[i]:\n",
    "            start = i\n",
    "            while i < len(arr) and is_value[i]:\n",
    "                i += 1\n",
    "            end = i\n",
    "            seq_len = end - start\n",
    "            # Check if surrounded by NaNs and short enough\n",
    "            if seq_len <= max_len:\n",
    "                left_nan = (start == 0) or np.isnan(arr[start - 1])\n",
    "                right_nan = (end == len(arr)) or np.isnan(arr[end])  # safe for edge\n",
    "                if left_nan and right_nan:\n",
    "                    result[start:end] = np.nan\n",
    "        else:\n",
    "            i += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlcpath=Path(f'{Path(dpath).parent}/My_First_WebCam/')\n",
    "for file in os.listdir(dlcpath):\n",
    "    if file.endswith(('.h5')):\n",
    "        dlcfile=file\n",
    "        break\n",
    "dlc_path = os.path.join(dlcpath, dlcfile)\n",
    "print(dlcfile)\n",
    "\n",
    "# Load HDF5 file\n",
    "df = pd.read_hdf(dlc_path)\n",
    "directory = os.path.dirname(dlc_path)\n",
    "timestamps_path = Path(directory,'timeStamps.csv')\n",
    "if timestamps_path.exists():\n",
    "    timestamps = pd.read_csv(timestamps_path)\n",
    "    tswebcam = timestamps['Time Stamp (ms)']\n",
    "    frame_rate = round(1/(np.mean(np.diff(timestamps.iloc[:,1]))/1000))  # fps\n",
    "    print(f'Acquisition with DAQ, frame rate = {frame_rate} fps')\n",
    "else:\n",
    "    frame_rate = 16  # fps /!\\ CHANGE ACCORDING TO YOUR DATA\n",
    "    print(f'Acquisition with Webcam, frame rate = {frame_rate} fps')\n",
    "\n",
    "X0 = df.iloc[:, 0]\n",
    "Y0 = df.iloc[:, 1]\n",
    "\n",
    "# Remove uncertain location predictions (likelihood < 0.9)\n",
    "df.iloc[:, 0] = df.apply(lambda row: row.iloc[0] if row.iloc[2] > 0.5 else np.nan, axis=1)\n",
    "df.iloc[:, 1] = df.apply(lambda row: row.iloc[1] if row.iloc[2] > 0.5 else np.nan, axis=1)\n",
    "\n",
    "X = df.iloc[:, 0]\n",
    "Y = df.iloc[:, 1]\n",
    "\n",
    "# Separate the individual's positions into x and y coordinates\n",
    "individual_xO= np.array(X.values)\n",
    "individual_yO = np.array(Y.values)\n",
    "\n",
    "# Define when the mouse is on the cheeseboard (start)\n",
    "for i, x in enumerate(individual_xO):\n",
    "    y = individual_yO[i]\n",
    "    if calculate_relative_distance(x, y, table_center_x, table_center_y) >= table_radius:\n",
    "        individual_xO[i] = np.nan\n",
    "        individual_yO[i] = np.nan\n",
    "\n",
    "individual_xOO = remove_short_sequences(individual_xO, max_len=3)\n",
    "individual_yOO = remove_short_sequences(individual_yO, max_len=3)\n",
    "\n",
    "x_start = find_long_non_nan_sequences(individual_xOO)[0][0] # first value of the first long non nan sequence\n",
    "y_start = find_long_non_nan_sequences(individual_yOO)[0][0] # first value of the first long non nan sequence\n",
    "\n",
    "start_frame = np.where(individual_xOO == x_start)[0][0].item()\n",
    "\n",
    "individual_xOO[:start_frame]=np.nan # remove any path before the real start\n",
    "individual_yOO[:start_frame]=np.nan # remove any path before the real start\n",
    "\n",
    "individual_x1, individual_y1 = replace_high_speed_points_with_nan(individual_xOO, individual_yOO, speed_threshold=10)\n",
    "\n",
    "#for i in range(len(individual_x1)-1, 0, -1): # Find the last non-NaN value which is not isolated\n",
    "#    if not np.isnan(individual_x1[i]) and not np.isnan(individual_x1[i-1]):\n",
    "#        last_frame = i\n",
    "#        break\n",
    "\n",
    "last_frame = len(individual_x1)\n",
    "\n",
    "individual_x2, individual_y2 = interpolate_2d_path(individual_x1[start_frame:last_frame], individual_y1[start_frame:last_frame], kind='nearest')\n",
    "individual_x3, individual_y3 = limit_speed(individual_x2, individual_y2, max_speed=20)\n",
    "\n",
    "individual_x = np.concatenate((individual_x1[:start_frame], individual_x3))\n",
    "individual_y = np.concatenate((individual_y1[:start_frame], individual_y3))\n",
    "\n",
    "if len(individual_x) == len(tswebcam):\n",
    "    if timestamps_path.exists():\n",
    "        start_time = timestamps.iloc[start_frame,1].item() / 1000\n",
    "        end_time = timestamps.iloc[-1,1].item() / 1000\n",
    "        duration_trial = end_time - start_time\n",
    "    else:\n",
    "        duration_trial = (last_frame - start_frame) / frame_rate\n",
    "    print(f'Total trial duration: {round(duration_trial)} sec')\n",
    "\n",
    "    total_distance, speed = calculate_distance_run(individual_x[start_frame:last_frame], individual_y[start_frame:last_frame])\n",
    "    print(f\"Total distance run: {round(total_distance)} cm\")\n",
    "    print(f\"Average speed: {round(np.nanmean(speed)/pixel_to_cm*frame_rate,2)} cm/s\")\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(3, 3)) \n",
    "\n",
    "    # Plot individual positions over time\n",
    "    cmap = plt.get_cmap('gnuplot2')\n",
    "    norm = plt.Normalize(vmin=0, vmax=len(individual_x))\n",
    "\n",
    "    for i in range(1, len(individual_x)):\n",
    "        ax.plot(individual_x[i-1:i+1], individual_y[i-1:i+1], color=cmap(norm(i)), linewidth=1)\n",
    "\n",
    "    #plt.plot(individual_x, individual_y, label=\"Individual's Path\", color='b')\n",
    "\n",
    "    plt.scatter(x_start, y_start, color='black', s=100, label='Start')\n",
    "    # Draw cheeseboard circle\n",
    "    table_circle = plt.Circle((table_center_x, table_center_y), table_radius, color='k', fill=False)\n",
    "    plt.gca().add_patch(table_circle) \n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    plt.title(f'Mouse Path On Cheeseboard Maze')\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "else: \n",
    "    print(f'Error: Length of DLC data ({len(individual_x)}) does not match length of timestamps ({len(tswebcam)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "table_center_x, table_center_y = 313, 283  # Center of the cheeseboard table on the video\n",
    "table_center_x, table_center_y = 300, 270  # Center of the cheeseboard table on the video\n",
    "table_radius = 290 / 2\n",
    "square_size = pixel_to_cm * 6\n",
    "\n",
    "# Filter out NaNs\n",
    "valid_mask = ~np.isnan(individual_x) & ~np.isnan(individual_y)\n",
    "path_x = individual_x[valid_mask]\n",
    "path_y = individual_y[valid_mask]\n",
    "\n",
    "# Generate symmetric grid of square centers\n",
    "n = int(np.floor(2 * table_radius / square_size))\n",
    "offsets = (np.arange(n) - (n - 1) / 2.0) * square_size\n",
    "centers_x = table_center_x + offsets\n",
    "centers_y = table_center_y + offsets\n",
    "\n",
    "# Count visits per square\n",
    "counts = defaultdict(int)\n",
    "for px, py in zip(path_x, path_y):\n",
    "    if np.sqrt((px - table_center_x)**2 + (py - table_center_y)**2) > table_radius:\n",
    "        continue  # skip points outside circle\n",
    "    ix = int(np.floor((px - (table_center_x - n/2 * square_size)) / square_size))\n",
    "    iy = int(np.floor((py - (table_center_y - n/2 * square_size)) / square_size))\n",
    "    counts[(ix, iy)] += 1\n",
    "\n",
    "max_count = max(counts.values())/3 if counts else 1\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "# Draw circle outline\n",
    "theta = np.linspace(0, 2*np.pi, 500)\n",
    "ax.plot(table_center_x + table_radius*np.cos(theta),\n",
    "        table_center_y + table_radius*np.sin(theta),\n",
    "        'k', lw=1)\n",
    "\n",
    "# Draw squares\n",
    "for i, cx in enumerate(centers_x):\n",
    "    for j, cy in enumerate(centers_y):\n",
    "        if np.sqrt((cx - table_center_x)**2 + (cy - table_center_y)**2) + square_size/np.sqrt(2) <= table_radius:\n",
    "            count = counts.get((i, j), 0)\n",
    "            if count > 0:                \n",
    "                intensity = count / max_count # Map count to viridis colormap\n",
    "                color = plt.cm.viridis(intensity)\n",
    "            else:\n",
    "                color = 'lightgrey'  # no visits\n",
    "            rect = plt.Rectangle((cx - square_size/2, cy - square_size/2), \n",
    "                                 square_size, square_size, \n",
    "                                 facecolor=color, edgecolor=None, lw=0.5)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the spatial map for all cells + interactive Ca2+ trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up selector object\n",
    "discrete_slider = pn.widgets.DiscreteSlider(\n",
    "    name= f\"Unit n°\", \n",
    "    options=[i for i in a.index],\n",
    "    value=a.index[0]\n",
    ")\n",
    "\n",
    "next_unit_button = pn.widgets.Button(name='Next unit > ', button_type='primary')\n",
    "previous_unit_button = pn.widgets.Button(name='< Previous unit')\n",
    "\n",
    "# Define a callback function for the button\n",
    "def nextunit_callback(event):\n",
    "    position = np.where(a.index == discrete_slider.value)[0]\n",
    "    position = position[0]\n",
    "    nextunitvalue=a.index[position + 1] if position+2<=len(a) else a.index[0]\n",
    "    discrete_slider.value = nextunitvalue\n",
    "    \n",
    "# Define a callback function for the button\n",
    "def previousunit_callback(event):\n",
    "    position = np.where(a.index == discrete_slider.value)[0]\n",
    "    position = position[0]\n",
    "    previousunitvalue=a.index [position - 1]\n",
    "    discrete_slider.value = previousunitvalue\n",
    "\n",
    "next_unit_button.on_click(nextunit_callback)\n",
    "previous_unit_button.on_click(previousunit_callback)\n",
    "\n",
    "# Define interactivity\n",
    "@pn.depends(indexes=discrete_slider)\n",
    "def calciumtrace(indexes):\n",
    "    index = indexes\n",
    "    position = np.where(a.index == index)[0]\n",
    "    position = position[0]\n",
    "    return hv.Curve((tsmini/1000, C[position, :]), label=f'Unit n°{index} \\nNr #{position}').opts(ylim=(0, 10), xlim=(0, tsmini.values[-1]/1000),frame_height=200, color='red')\n",
    "\n",
    "@pn.depends(indexes=discrete_slider)\n",
    "def unitshadow(indexes):\n",
    "    index = indexes \n",
    "    data=A.sel(unit_id=index)\n",
    "    x = np.linspace(0, 600, 600)\n",
    "    y = np.linspace(0, 600, 600)\n",
    "    masked_data = np.where(data < 0.01, np.nan, data) \n",
    "    return hv.Image((x, y, masked_data)).opts(cmap='hot', clim=(0, 1))\n",
    "\n",
    "@pn.depends(indexes=discrete_slider)\n",
    "def circlepath(indexes):\n",
    "    index = indexes\n",
    "    radius = 15\n",
    "    num_points=100\n",
    "    theta = np.linspace(0, 2*np.pi, num_points)\n",
    "    position = np.where(a.index == index)[0]\n",
    "    position = position[0]\n",
    "    return hv.Path((a.iloc[position, 0] + radius * np.cos(theta), a.iloc[position, 1] + radius * np.sin(theta)), group='keep').opts(ylim=(0, 600), xlim=(0, 600), line_color='red', line_width=3) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 120\n",
    "hv.output(size=int(output_size))\n",
    "\n",
    "image = hv.Image(\n",
    "    A.max(\"unit_id\").compute().astype(np.float32).rename(\"A\"),\n",
    "    kdims=[\"width\", \"height\"],\n",
    ").opts(colorbar=False, invert_yaxis=False,cmap=\"Viridis\")\n",
    "\n",
    "alltraces=hv.NdOverlay({idx: hv.Curve((tsmini/1000, C[idx,:])).opts(frame_height=200, show_legend=False, color='black', alpha=0.2, xlabel='time (s)')\n",
    "                       for idx in np.arange(len(C))})\n",
    "\n",
    "start =  hv.VLine(start_time).opts(color='blue', line_width=2)\n",
    "starttxt = hv.Text(start_time + 5, 9.5, 'Start').opts(text_color='blue')\n",
    "\n",
    "layout = pn.Column(pn.Row(image * hv.DynamicMap(unitshadow), \n",
    "            pn.Column(starttxt * start * hv.DynamicMap(calciumtrace), discrete_slider, pn.Row(previous_unit_button, next_unit_button),       \n",
    "                    ),\n",
    "                    ))   \n",
    "\n",
    "display(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a neuron to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr=34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot neuron's activity during the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=[10,2])\n",
    "plt.plot(tswebcam[start_frame+1:last_frame]/1000, (speed)/max(speed), 'c', label='Mouse speed')\n",
    "\n",
    "closest_start= find_closest_index_sorted(tsmini, start_time*1000)\n",
    "closest_end= find_closest_index_sorted(tsmini, end_time*1000)\n",
    "\n",
    "Cnr=C[nr,:]\n",
    "\n",
    "normalized_C = (Cnr - np.min(Cnr)) / (np.max(Cnr.values) - np.min(Cnr.values)) if np.sum(Cnr)!=0 else Cnr\n",
    "plt.plot(tsmini[:]/1000, normalized_C, 'k', label= f'Neuron #{nr}')\n",
    "\n",
    "Call=C[:,:]\n",
    "normalized_Cmean = (np.mean(Call, axis=0) - np.min(np.mean(Call, axis=0))) / (np.max(np.mean(Call, axis=0)) - np.min(np.mean(Call, axis=0))) \n",
    "plt.plot(tsmini[:]/1000, normalized_Cmean , 'k', alpha=0.2, label= f'Mean neuron activity')\n",
    "\n",
    "plt.axvline(x=start_time, color='b', linewidth=2)\n",
    "plt.text(start_time, plt.gca().get_ylim()[1], 'Start', fontsize=8, color='blue')\n",
    "plt.xlabel('time (s)')\n",
    "plt.legend(frameon=False, bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot neuron on the cheeseboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= individual_x[start_frame:last_frame]\n",
    "y= individual_y[start_frame:last_frame]\n",
    "Cnr_ = Cnr[closest_start:closest_end+1].to_numpy()\n",
    "\n",
    "# Plot circular environment\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "table_circle = plt.Circle((table_center_x, table_center_y), table_radius, color='k', fill=False)\n",
    "plt.gca().add_patch(table_circle) \n",
    "\n",
    "# Normalize Cnr_ for colormap\n",
    "norm = mcolors.Normalize(vmin=Cnr_.min(), vmax=Cnr_.max())\n",
    "cmap = cm.jet\n",
    "\n",
    "# Plot path with colormap\n",
    "for i in range(len(x) - 1):\n",
    "    closest_point= find_closest_index_sorted(tsmini, tswebcam[start_frame+i])\n",
    "    color = cmap(norm(Cnr_[closest_point]))\n",
    "    ax.plot([x[i], x[i+1]], [y[i], y[i+1]], color=color, linewidth=3)\n",
    "\n",
    "# Add colorbar\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "#plt.scatter(x_start, y_start, color='black', s=100, label='Start')\n",
    "ax.invert_yaxis()\n",
    "ax.set_aspect('equal')\n",
    "plt.title(f'Neuron #{nr}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out NaNs\n",
    "valid_mask = ~np.isnan(individual_x) & ~np.isnan(individual_y)\n",
    "path_x = individual_x[valid_mask]\n",
    "path_y = individual_y[valid_mask]\n",
    "\n",
    "x= individual_x[start_frame:last_frame]\n",
    "y= individual_y[start_frame:last_frame]\n",
    "Cnr_ = Cnr[closest_start:closest_end+1].to_numpy()\n",
    "\n",
    "# Generate symmetric grid of square centers\n",
    "n = int(np.floor(2 * table_radius / square_size))\n",
    "offsets = (np.arange(n) - (n - 1) / 2.0) * square_size\n",
    "centers_x = table_center_x + offsets\n",
    "centers_y = table_center_y + offsets\n",
    "\n",
    "nr_tot_act_biaised = defaultdict(int) # Neuron activity per square\n",
    "counts = defaultdict(int) # Count visits per square\n",
    "for idx, (px, py) in enumerate(zip(x, y)):\n",
    "    if np.sqrt((px - table_center_x)**2 + (py - table_center_y)**2) > table_radius:\n",
    "        continue  # skip points outside circle\n",
    "    ix = int(np.floor((px - (table_center_x - n/2 * square_size)) / square_size))\n",
    "    iy = int(np.floor((py - (table_center_y - n/2 * square_size)) / square_size))\n",
    "    closest_point= find_closest_index_sorted(tsmini, tswebcam[start_frame+idx])\n",
    "    nr_tot_act_biaised[(ix, iy)] += Cnr_[closest_point]\n",
    "    counts[(ix, iy)] += 1\n",
    "\n",
    "nr_tot_act = defaultdict(float)\n",
    "for key in counts.keys():\n",
    "    if counts[key] != 0:   # avoid division by zero\n",
    "        nr_tot_act[key] = nr_tot_act_biaised[key] / counts[key]\n",
    "    else:\n",
    "        nr_tot_act[key] = np.nan  \n",
    "max_nr_tot_act = max(nr_tot_act.values())\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "# Draw circle outline\n",
    "theta = np.linspace(0, 2*np.pi, 500)\n",
    "ax.plot(table_center_x + table_radius*np.cos(theta),\n",
    "        table_center_y + table_radius*np.sin(theta),\n",
    "        'k', lw=1)\n",
    "# Draw squares\n",
    "for i, cx in enumerate(centers_x):\n",
    "    for j, cy in enumerate(centers_y):\n",
    "        if np.sqrt((cx - table_center_x)**2 + (cy - table_center_y)**2) + square_size/np.sqrt(2) <= table_radius:\n",
    "            nr_act = nr_tot_act.get((i, j), np.nan)\n",
    "            if ~ np.isnan(nr_act):                \n",
    "                intensity = nr_act / max_nr_tot_act # Map count to viridis colormap\n",
    "                color = plt.cm.viridis(intensity)\n",
    "            else:\n",
    "                color = 'lightgrey'  # no visits\n",
    "            rect = plt.Rectangle((cx - square_size/2, cy - square_size/2), \n",
    "                                 square_size, square_size, \n",
    "                                 facecolor=color, edgecolor='None', lw=0.5)\n",
    "            ax.add_patch(rect)\n",
    "ax.invert_yaxis()\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot activity of each neuron on the cheeseboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_subplot=min(C.shape[0], 100)\n",
    "rows = int(np.ceil(np.sqrt(nb_subplot)))  # Rows: ceil(sqrt(X))\n",
    "cols = int(np.ceil(np.sqrt(nb_subplot)))  # Columns: floor(sqrt(X))\n",
    "\n",
    "# Create the figure with a 2x2 grid\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "plt.tight_layout()\n",
    "\n",
    "for nr in range(nb_subplot):\n",
    "\n",
    "    Cds_nr = Cds_all[nr,start_frame:last_frame]\n",
    "    x= individual_x_nonan[start_frame:last_frame]\n",
    "    y= individual_y_nonan[start_frame:last_frame]\n",
    "\n",
    "    # Plot circular environment\n",
    "    table_circle = plt.Circle((table_center_x, table_center_y), table_radius, color='k', fill=False)\n",
    "    axs[nr].add_patch(table_circle) \n",
    "\n",
    "    # Normalize Cds_nr for colormap\n",
    "    if Cds_nr.min() != Cds_nr.max():\n",
    "        norm = mcolors.Normalize(vmin=Cds_nr.min(), vmax=Cds_nr.max())\n",
    "    else:\n",
    "        norm = mcolors.Normalize(vmin=0, vmax=1)\n",
    "    cmap = cm.jet\n",
    "\n",
    "    # Plot path with colormap\n",
    "    for i in range(len(x) - 1):\n",
    "        color = cmap(norm(Cds_nr[i]))\n",
    "        axs[nr].plot([x[i], x[i+1]], [y[i], y[i+1]], color=color, linewidth=3)\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    # Scatter start and reward points\n",
    "    axs[nr].scatter(x_start, y_start,  marker='+', color='black', s=100, label='Start')\n",
    "\n",
    "    # Customize plot\n",
    "    axs[nr].invert_yaxis()\n",
    "    axs[nr].set_aspect('equal')\n",
    "    axs[nr].set_title(f'#{nr}', pad=0, loc='left')\n",
    "    \n",
    "    # Remove box (spines)\n",
    "    for spine in axs[nr].spines.values():\n",
    "        spine.set_visible(False)\n",
    "    axs[nr].set_xticks([])  # No x-axis ticks\n",
    "    axs[nr].set_yticks([])  # No y-axis ticks\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average neuron activity on the cheeseboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cds_all_mean=np.mean(Cds_all[:,start_frame:last_frame], axis=0)\n",
    "x= individual_x_nonan[start_frame:last_frame]\n",
    "y= individual_y_nonan[start_frame:last_frame]\n",
    "\n",
    "# Plot circular environment\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "table_circle = plt.Circle((table_center_x, table_center_y), table_radius, color='k', fill=False)\n",
    "plt.gca().add_patch(table_circle) \n",
    "\n",
    "# Normalize Cds_all_mean for colormap\n",
    "norm = mcolors.Normalize(vmin=Cds_all_mean.min(), vmax=Cds_all_mean.max())\n",
    "cmap = cm.jet\n",
    "\n",
    "# Plot path with colormap\n",
    "for i in range(len(x) - 1):\n",
    "    color = cmap(norm(Cds_all_mean[i]))\n",
    "    ax.plot([x[i], x[i+1]], [y[i], y[i+1]], color=color, linewidth=3)\n",
    "\n",
    "# Add colorbar\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "plt.scatter(x_start, y_start, color='black', s=100, label='Start')\n",
    "ax.invert_yaxis()\n",
    "ax.set_aspect('equal')\n",
    "plt.title(f'Average activity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head direction cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head orientation cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import xarray as xr\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from mpl_toolkits.mplot3d import Axes3D  # nécessaire pour 3D même si pas utilisé explicitement\n",
    "\n",
    "# ======================== Paramètres ========================\n",
    "nr = 5  # Numéro du neurone à visualiser (1-based)\n",
    "dpath = Path(r\"S:\\forgetting\\Clementine\\CheeseboardExperiment\\Juin\\YL\\Cheeseboard\\2025_06_05\\11_19_07\\My_V4_Miniscope\")\n",
    "minianversion = \"minian\"\n",
    "\n",
    "# ======================== Définition des chemins ========================\n",
    "folderMouse = dpath / minianversion\n",
    "StampsMiniscopeFile = dpath / \"timeStamps.csv\"\n",
    "A_zarr_path = folderMouse / \"A.zarr\"\n",
    "C_zarr_path = folderMouse / \"C.zarr\"\n",
    "todrop_path = dpath / \"TodropFileAB.json\"\n",
    "head_orientation_file = dpath / \"headOrientation.csv\"\n",
    "\n",
    "# ======================== Vérification des fichiers ========================\n",
    "for path in [dpath, folderMouse, A_zarr_path, C_zarr_path, StampsMiniscopeFile, todrop_path, head_orientation_file]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Fichier manquant : {path}\")\n",
    "\n",
    "# ======================== Chargement des données calcium ========================\n",
    "A_ds = xr.open_zarr(A_zarr_path)\n",
    "C_ds = xr.open_zarr(C_zarr_path)\n",
    "\n",
    "# ======================== Chargement des timestamps ========================\n",
    "tsmini = pd.read_csv(StampsMiniscopeFile)['Time Stamp (ms)']\n",
    "minian_freq = round(1 / np.mean(np.diff(np.array(tsmini) / 1000)))\n",
    "print('🎞️  Fréquence d\\'échantillonnage miniscope =', minian_freq, 'Hz')\n",
    "\n",
    "# ======================== Application du filtre Todrop ========================\n",
    "with open(todrop_path, 'r') as f:\n",
    "    todrop_data = json.load(f)\n",
    "to_drop = todrop_data\n",
    "print(f\"🧹 Unités à exclure : {len(to_drop)}\")\n",
    "\n",
    "all_units = np.arange(C_ds['C'].shape[0])\n",
    "kept_units = np.setdiff1d(all_units, to_drop)\n",
    "print(f\"✅ Unités conservées : {len(kept_units)}\")\n",
    "\n",
    "if nr < 1 or nr > len(kept_units):\n",
    "    raise ValueError(f\"nr doit être entre 1 et {len(kept_units)} après filtrage\")\n",
    "\n",
    "C_filtered = C_ds['C'].values[kept_units]\n",
    "A_filtered = A_ds['A'].values[:, kept_units]\n",
    "Cds_all = C_filtered\n",
    "\n",
    "# ======================== Chargement et conversion des données d'orientation ========================\n",
    "head_df = pd.read_csv(head_orientation_file)\n",
    "\n",
    "# Extraction des quaternions\n",
    "qw = head_df['qw'].to_numpy()\n",
    "qx = head_df['qx'].to_numpy()\n",
    "qy = head_df['qy'].to_numpy()\n",
    "qz = head_df['qz'].to_numpy()\n",
    "\n",
    "# ======================== Conversion des quaternions en angles d'Euler ========================\n",
    "def quaternion_to_euler(qw, qx, qy, qz):\n",
    "    sinr_cosp = 2 * (qw * qx + qy * qz)\n",
    "    cosr_cosp = 1 - 2 * (qx * qx + qy * qy)\n",
    "    roll = np.arctan2(sinr_cosp, cosr_cosp)\n",
    "\n",
    "    sinp = 2 * (qw * qy - qz * qx)\n",
    "    sinp = np.clip(sinp, -1.0, 1.0)\n",
    "    pitch = np.arcsin(sinp)\n",
    "\n",
    "    siny_cosp = 2 * (qw * qz + qx * qy)\n",
    "    cosy_cosp = 1 - 2 * (qy * qy + qz * qz)\n",
    "    yaw = np.arctan2(siny_cosp, cosy_cosp)\n",
    "\n",
    "    return roll, pitch, yaw\n",
    "\n",
    "roll, pitch, yaw = quaternion_to_euler(qw, qx, qy, qz)\n",
    "roll_deg = np.degrees(roll)\n",
    "pitch_deg = np.degrees(pitch)\n",
    "yaw_deg = np.degrees(yaw)\n",
    "\n",
    "# ======================== Filtrage des outliers ========================\n",
    "def remove_outliers_iqr(data, factor=1.5):\n",
    "    q1 = np.nanpercentile(data, 25)\n",
    "    q3 = np.nanpercentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - factor * iqr\n",
    "    upper_bound = q3 + factor * iqr\n",
    "\n",
    "    data_filtered = data.copy()\n",
    "    data_filtered[(data < lower_bound) | (data > upper_bound)] = np.nan\n",
    "    return data_filtered\n",
    "\n",
    "roll_deg = remove_outliers_iqr(roll_deg)\n",
    "pitch_deg = remove_outliers_iqr(pitch_deg)\n",
    "yaw_deg = remove_outliers_iqr(yaw_deg)\n",
    "\n",
    "valid_mask = ~(np.isnan(roll_deg) | np.isnan(pitch_deg) | np.isnan(yaw_deg))\n",
    "valid_indices = np.where(valid_mask)[0]\n",
    "\n",
    "if len(valid_indices) == 0:\n",
    "    raise ValueError(\"Aucune donnée d'orientation valide trouvée\")\n",
    "\n",
    "start_frame = valid_indices[0]\n",
    "last_frame = valid_indices[-1] + 1\n",
    "\n",
    "\n",
    "# Extraction des données valides\n",
    "individual_roll = roll_deg[start_frame:last_frame]\n",
    "individual_pitch = pitch_deg[start_frame:last_frame]\n",
    "individual_yaw = yaw_deg[start_frame:last_frame]\n",
    "\n",
    "# Alignement avec données calcium\n",
    "if start_frame >= Cds_all.shape[1] or last_frame > Cds_all.shape[1]:\n",
    "    last_frame = min(last_frame, Cds_all.shape[1])\n",
    "    individual_roll = roll_deg[start_frame:last_frame]\n",
    "    individual_pitch = pitch_deg[start_frame:last_frame]\n",
    "    individual_yaw = yaw_deg[start_frame:last_frame]\n",
    "\n",
    "Cds_nr = Cds_all[nr - 1, start_frame:last_frame]\n",
    "\n",
    "# ======================== Visualisation 3D interactive ========================\n",
    "\n",
    "def plot_head_orientation_neuron_3D(nr):\n",
    "    if nr < 1 or nr > len(kept_units):\n",
    "        print(f\"nr doit être entre 1 et {len(kept_units)}\")\n",
    "        return\n",
    "\n",
    "    Cds_nr = Cds_all[nr - 1, start_frame:last_frame]\n",
    "    valid = ~(np.isnan(individual_roll) | np.isnan(individual_pitch) | np.isnan(individual_yaw))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    norm = mcolors.Normalize(vmin=Cds_nr.min(), vmax=Cds_nr.max())\n",
    "    cmap = cm.jet\n",
    "\n",
    "    sc = ax.scatter(individual_roll[valid], individual_pitch[valid], individual_yaw[valid],\n",
    "                    c=Cds_nr[valid], cmap=cmap, norm=norm, s=10, alpha=0.8)\n",
    "    ax.set_xlabel(\"Roll (°)\")\n",
    "    ax.set_ylabel(\"Pitch (°)\")\n",
    "    ax.set_zlabel(\"Yaw (°)\")\n",
    "    ax.set_title(f\"3D Head Orientation - Neuron #{nr}\")\n",
    "\n",
    "    cbar = fig.colorbar(sc, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Calcium activity\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Widget interactif pour choisir le neurone\n",
    "print(\"🎮 Visualisation interactive 3D : Choisissez un neurone\")\n",
    "slider_neuron = widgets.IntSlider(value=nr, min=1, max=len(kept_units), step=1, description='Neuron:')\n",
    "widgets.interact(plot_head_orientation_neuron_3D, nr=slider_neuron)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neurones Choisis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import json\n",
    "from mpl_toolkits.mplot3d import Axes3D  # required for 3D plots\n",
    "\n",
    "# === Step 1: Load kept_units from JSON file if available ===\n",
    "try:\n",
    "    with open(\"TodropFileAB.json\", \"r\") as f:\n",
    "        todrop = json.load(f)\n",
    "    kept_units = [i for i in range(Cds_all.shape[0]) if i not in todrop[\"to_drop\"]]\n",
    "    print(f\"✅ {len(kept_units)} units kept after filtering.\")\n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        kept_units = list(range(Cds_all.shape[0]))\n",
    "        print(f\"✅ {len(kept_units)} units used without filtering.\")\n",
    "    except NameError:\n",
    "        kept_units = []\n",
    "\n",
    "# === Step 2: Visualization function ===\n",
    "def plot_head_orientation_neurons_grid_selected(point_size=3, alpha=0.7):\n",
    "    if not kept_units:\n",
    "        print(\"❌ No available units to plot. Make sure 'Cds_all' is loaded.\")\n",
    "        return\n",
    "\n",
    "    neuron_indices = [101, 107, 110, 114]  # 1-based indices in kept_units\n",
    "    neuron_indices = [nr for nr in neuron_indices if 1 <= nr <= len(kept_units)]\n",
    "\n",
    "    if not neuron_indices:\n",
    "        print(\"❌ No valid neurons to display.\")\n",
    "        return\n",
    "\n",
    "    n_neurons = len(neuron_indices)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_neurons + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols,\n",
    "                            figsize=(6 * n_cols, 5 * n_rows),\n",
    "                            subplot_kw={'projection': '3d'})\n",
    "    \n",
    "    axs = np.array(axs).flatten() if n_neurons > 1 else np.array([axs])\n",
    "    all_colors = []\n",
    "\n",
    "    for i, nr in enumerate(neuron_indices):\n",
    "        index_data = kept_units[nr - 1]\n",
    "        Cds_nr = Cds_all[index_data, start_frame:last_frame]\n",
    "\n",
    "        valid_mask = ~np.isnan(individual_roll) & ~np.isnan(individual_pitch) & ~np.isnan(individual_yaw)\n",
    "        if np.sum(valid_mask) == 0:\n",
    "            print(f\"❌ Neuron #{nr}: no valid data.\")\n",
    "            continue\n",
    "\n",
    "        x_data = individual_yaw[valid_mask]\n",
    "        y_data = individual_roll[valid_mask]\n",
    "        z_data = individual_pitch[valid_mask]\n",
    "        colors = Cds_nr[valid_mask]\n",
    "        all_colors.append(colors)\n",
    "\n",
    "        ax = axs[i]\n",
    "        ax.scatter(x_data, y_data, z_data,\n",
    "                   c=colors, cmap=cm.jet,\n",
    "                   s=point_size, alpha=alpha,\n",
    "                   edgecolors='none')\n",
    "\n",
    "        ax.set_title(f\"Neuron #{nr}\", fontsize=11)\n",
    "        ax.set_xlabel(\"Yaw (left ↔ right)\", fontsize=10)\n",
    "        ax.set_ylabel(\"Roll (side tilt)\", fontsize=10)\n",
    "        ax.set_zlabel(\"Pitch (up ↕ down)\", fontsize=10)\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_zticks([])\n",
    "\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        fig.delaxes(axs[j])\n",
    "\n",
    "    if all_colors:\n",
    "        all_colors_concat = np.concatenate(all_colors)\n",
    "        norm = mcolors.Normalize(vmin=all_colors_concat.min(), vmax=all_colors_concat.max())\n",
    "        sm = cm.ScalarMappable(cmap=cm.jet, norm=norm)\n",
    "        sm.set_array([])\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.07, 0.5, 0.02])\n",
    "        cbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\n",
    "        cbar.set_label('Calcium activity (a.u.)', fontsize=12)\n",
    "\n",
    "    fig.suptitle(\"🧠 3D Head Orientation – Neurons #101, 107, 110, 114\", fontsize=16, fontweight='bold')\n",
    "    plt.subplots_adjust(top=0.88, bottom=0.15)\n",
    "    plt.show()\n",
    "\n",
    "# === Call the function ===\n",
    "plot_head_orientation_neurons_grid_selected()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STATS\n",
    "#The three statistical tests used here—permutation, Kolmogorov-Smirnov, and Fisher tests—are\n",
    "#designed to identify place cells and head direction cells by comparing the observed spatial firing\n",
    "#patterns of neurons against null distributions that assume no spatial selectivity. These tests suppose\n",
    "#that true place or head direction cells will show significantly non-random spatial firing patterns that\n",
    "#cannot be explained by chance alone, with the permutation test shuffling temporal relationships to\n",
    "#test spatial specificity, the Kolmogorov-Smirnov test comparing the distribution of firing rates\n",
    "#across spatial bins to a uniform distribution, and the Fisher test evaluating the statistical significance\n",
    "#of the spatial information content of each neuron's firing pattern.\n",
    "#Here we used alpha = 10%\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import json\n",
    "from scipy.stats import ks_2samp, fisher_exact\n",
    "from IPython.display import display\n",
    "\n",
    "# ======== PARAMÈTRES ========\n",
    "dpath = Path(r\"S:\\forgetting\\Clementine\\CheeseboardExperiment\\Juin\\YL\\Cheeseboard\\2025_06_05\\11_19_07\\My_V4_Miniscope\")\n",
    "minianversion = \"minian\"\n",
    "\n",
    "folderMouse = dpath / minianversion\n",
    "A_zarr_path = folderMouse / \"A.zarr\"\n",
    "C_zarr_path = folderMouse / \"C.zarr\"\n",
    "todrop_path = dpath / \"TodropFileAB.json\"\n",
    "head_orientation_file = dpath / \"headOrientation.csv\"\n",
    "\n",
    "# ======== Vérification des fichiers ========\n",
    "for path in [dpath, folderMouse, A_zarr_path, C_zarr_path, todrop_path, head_orientation_file]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Fichier manquant : {path}\")\n",
    "\n",
    "print(\"✅ Tous les fichiers requis existent\")\n",
    "\n",
    "# ======== Chargement données calcium ========\n",
    "A_ds = xr.open_zarr(A_zarr_path)\n",
    "C_ds = xr.open_zarr(C_zarr_path)\n",
    "\n",
    "with open(todrop_path, 'r') as f:\n",
    "    to_drop = json.load(f)\n",
    "\n",
    "all_units = np.arange(C_ds['C'].shape[0])\n",
    "kept_units = np.setdiff1d(all_units, to_drop)\n",
    "C_filtered = C_ds['C'].values[kept_units]\n",
    "\n",
    "# ======== Chargement et conversion orientation tête (quaternion → angles) ========\n",
    "head_df = pd.read_csv(head_orientation_file)\n",
    "\n",
    "qw = head_df['qw'].to_numpy()\n",
    "qx = head_df['qx'].to_numpy()\n",
    "qy = head_df['qy'].to_numpy()\n",
    "qz = head_df['qz'].to_numpy()\n",
    "\n",
    "def quaternion_to_euler(qw, qx, qy, qz):\n",
    "    sinr_cosp = 2 * (qw * qx + qy * qz)\n",
    "    cosr_cosp = 1 - 2 * (qx * qx + qy * qy)\n",
    "    roll = np.arctan2(sinr_cosp, cosr_cosp)\n",
    "\n",
    "    sinp = 2 * (qw * qy - qz * qx)\n",
    "    sinp = np.clip(sinp, -1.0, 1.0)\n",
    "    pitch = np.arcsin(sinp)\n",
    "\n",
    "    siny_cosp = 2 * (qw * qz + qx * qy)\n",
    "    cosy_cosp = 1 - 2 * (qy * qy + qz * qz)\n",
    "    yaw = np.arctan2(siny_cosp, cosy_cosp)\n",
    "\n",
    "    return roll, pitch, yaw\n",
    "\n",
    "roll, pitch, yaw = quaternion_to_euler(qw, qx, qy, qz)\n",
    "roll_deg = np.degrees(roll)\n",
    "pitch_deg = np.degrees(pitch)\n",
    "yaw_deg = np.degrees(yaw)\n",
    "\n",
    "def remove_outliers_iqr(data, factor=1.5):\n",
    "    q1 = np.nanpercentile(data, 25)\n",
    "    q3 = np.nanpercentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - factor * iqr\n",
    "    upper_bound = q3 + factor * iqr\n",
    "    filtered = data.copy()\n",
    "    filtered[(data < lower_bound) | (data > upper_bound)] = np.nan\n",
    "    return filtered\n",
    "\n",
    "roll_deg = remove_outliers_iqr(roll_deg)\n",
    "pitch_deg = remove_outliers_iqr(pitch_deg)\n",
    "yaw_deg = remove_outliers_iqr(yaw_deg)\n",
    "\n",
    "valid_mask = ~(np.isnan(roll_deg) | np.isnan(pitch_deg) | np.isnan(yaw_deg))\n",
    "valid_indices = np.where(valid_mask)[0]\n",
    "\n",
    "if len(valid_indices) == 0:\n",
    "    raise ValueError(\"Aucune donnée d'orientation valide\")\n",
    "\n",
    "start_frame = valid_indices[0]\n",
    "last_frame = valid_indices[-1] + 1\n",
    "\n",
    "roll_deg = roll_deg[start_frame:last_frame]\n",
    "pitch_deg = pitch_deg[start_frame:last_frame]\n",
    "yaw_deg = yaw_deg[start_frame:last_frame]\n",
    "\n",
    "if last_frame > C_filtered.shape[1]:\n",
    "    last_frame = C_filtered.shape[1]\n",
    "\n",
    "C_filtered = C_filtered[:, start_frame:last_frame]\n",
    "\n",
    "# ======== Fonctions de test de modulation activité vs angle tête ========\n",
    "\n",
    "def compute_spatial_info(activity, angle, nbins=10):\n",
    "    bins = np.linspace(np.nanmin(angle), np.nanmax(angle), nbins + 1)\n",
    "    inds = np.digitize(angle, bins) - 1\n",
    "    inds[inds == nbins] = nbins - 1\n",
    "\n",
    "    p_i = np.array([np.sum(inds == i) for i in range(nbins)]) / len(angle)\n",
    "    r_i = np.array([np.nanmean(activity[inds == i]) for i in range(nbins)])\n",
    "    r_i = np.nan_to_num(r_i)\n",
    "    r = np.nanmean(activity)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        info_per_bin = p_i * (r_i / r) * np.log2((r_i / r) + 1e-12)\n",
    "    info_per_bin[np.isnan(info_per_bin)] = 0\n",
    "\n",
    "    return np.nansum(info_per_bin)\n",
    "\n",
    "def permutation_test(activity, angle, n_perm=1000, nbins=10):\n",
    "    info_real = compute_spatial_info(activity, angle, nbins=nbins)\n",
    "    info_perm = np.zeros(n_perm)\n",
    "    n = len(angle)\n",
    "    for i in range(n_perm):\n",
    "        shift = np.random.randint(n)\n",
    "        activity_perm = np.roll(activity, shift)\n",
    "        info_perm[i] = compute_spatial_info(activity_perm, angle, nbins=nbins)\n",
    "    p_val = np.sum(info_perm >= info_real) / n_perm\n",
    "    return info_real, info_perm, p_val\n",
    "\n",
    "# ======== Analyse ========\n",
    "\n",
    "angle_to_use = yaw_deg  # Choisir ici roll_deg ou pitch_deg si souhaité\n",
    "nbins = 10\n",
    "percentile_threshold = 90\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, neuron in enumerate(kept_units):\n",
    "    activity = C_filtered[idx, :]\n",
    "    valid_idx = ~np.isnan(angle_to_use)\n",
    "    angle_vals = angle_to_use[valid_idx]\n",
    "    activity_vals = activity[valid_idx]\n",
    "\n",
    "    if len(activity_vals) < 10:\n",
    "        continue\n",
    "\n",
    "    # Test permutation\n",
    "    info_real, info_perm, p_perm = permutation_test(activity_vals, angle_vals, n_perm=1000, nbins=nbins)\n",
    "    threshold = np.percentile(info_perm, percentile_threshold)\n",
    "    is_modulated_perm = info_real > threshold\n",
    "\n",
    "    # Test KS (différence distribution activité / bins angle)\n",
    "    bins = np.digitize(angle_vals, bins=np.linspace(np.nanmin(angle_vals), np.nanmax(angle_vals), nbins + 1)) - 1\n",
    "    binned_means = np.array([np.nanmean(activity_vals[bins == i]) for i in range(nbins)])\n",
    "    binned_means = np.nan_to_num(binned_means)\n",
    "    ks_stat, ks_p = ks_2samp(activity_vals, binned_means)\n",
    "    is_modulated_ks = ks_p < 0.05\n",
    "\n",
    "    # Test Fisher (association activité forte vs bins)\n",
    "    threshold_act = np.nanpercentile(activity_vals, 80)\n",
    "    active = activity_vals > threshold_act\n",
    "    spatial_bin = bins < (len(bins) // 2)\n",
    "    contingency = pd.crosstab(active, spatial_bin)\n",
    "    if contingency.shape == (2, 2):\n",
    "        _, fisher_p = fisher_exact(contingency)\n",
    "    else:\n",
    "        fisher_p = np.nan\n",
    "    is_modulated_fisher = fisher_p < 0.05 if not np.isnan(fisher_p) else False\n",
    "\n",
    "    # Consensus (au moins 2 tests positifs)\n",
    "    test_flags = [is_modulated_perm, is_modulated_ks, is_modulated_fisher]\n",
    "    consensus = sum(test_flags) >= 2\n",
    "\n",
    "    results.append({\n",
    "        \"Neuron\": neuron,\n",
    "        \"Info_Spatial (Permutation)\": info_real,\n",
    "        f\"Permutation_Threshold_{percentile_threshold}%\": threshold,\n",
    "        \"P_Value_Permutation\": p_perm,\n",
    "        \"Modulated_Permutation\": is_modulated_perm,\n",
    "        \"KS_Stat\": ks_stat,\n",
    "        \"P_Value_KS\": ks_p,\n",
    "        \"Modulated_KS\": is_modulated_ks,\n",
    "        \"P_Value_Fisher\": fisher_p,\n",
    "        \"Modulated_Fisher\": is_modulated_fisher,\n",
    "        \"Consensus_Modulated\": consensus\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(dpath / \"head_orientation_cells_results.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Analyse terminée, résultats sauvegardés dans {dpath / 'head_orientation_cells_results.csv'}\")\n",
    "\n",
    "display(\n",
    "    df_results[df_results[\"Consensus_Modulated\"] == True]\n",
    "    .style\n",
    "    .format(precision=4)\n",
    "    .set_caption(\"Résultats détection head orientation cells - Consensus = True\")\n",
    "    .background_gradient(cmap=\"YlGnBu\", subset=[\n",
    "        \"Info_Spatial (Permutation)\", \"P_Value_Permutation\", \"P_Value_KS\", \"P_Value_Fisher\"\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
