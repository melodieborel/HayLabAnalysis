{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder used for minian procedures is : c:\\Users\\Manip2\\SCRIPTS\\CodePythonAudrey\\CodePythonAurelie\\HayLabAnalysis\\minian\n",
      "####################################################################################\n",
      "################################### ThreeBlueCrossesOK ####################################\n",
      "####################################################################################\n",
      "Path to the folder : //10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/ThreeBlueCrossesOK\n",
      "session1 : starts at 5.2 s & ends at 670.0 s ( 664.8 s duration,  0 dropped frames, minian frequency = 30 Hz, drug =  Baseline )...\n",
      "... kept values = ['[3]', '[12]', '[14]', '[15]', '[5]', '[16]', '[17]', '[18]', '[19]', '[20]', '[8]', '[22]', '[23]', '[24]', '[25]', '[26]', '[2]', '[27]', '[6]', '[9]', '[28]', '[29]', '[30]', '[31]', '[7]', '[32]', '[34]', '[35]']\n",
      "session21 : starts at 2.3 s & ends at 1002.4 s ( 1000.0 s duration,  1 dropped frames, minian frequency = 30 Hz, drug =  Baseline )...\n",
      "... kept values = ['[3]', '[11]', '[10]', '[5]', '[0]', '[2]']\n",
      "session22 : starts at 1002.4 s & ends at 2002.4 s ( 1000.0 s duration,  0 dropped frames, minian frequency = 30 Hz, drug =  Baseline )...\n",
      "... kept values = ['[3]', '[10]', '[11]', '[5]', '[8]', '[49]', '[50]', '[2]', '[6]', '[51]', '[37]', '[7]', '[4]', '[39]']\n",
      "session23 : starts at 2002.4 s & ends at 3331.6 s ( 1329.2 s duration,  3 dropped frames, minian frequency = 30 Hz, drug =  Baseline )...\n",
      "... kept values = ['[3]', '[10]', '[5]', '[0]', '[2]']\n",
      "session32 : starts at 3331.7 s & ends at 4359.0 s ( 1027.3 s duration,  0 dropped frames, minian frequency = 30 Hz, drug =  Baseline )...\n",
      "... kept values = ['[0]', '[9]', '[59]']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The length of the input vector x must be greater than padlen, which is 15.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 515\u001b[0m\n\u001b[0;32m    512\u001b[0m S1  \u001b[38;5;241m=\u001b[39m  Allcut[:, S1ch1]\u001b[38;5;241m-\u001b[39mAllcut[:, S1ch2] \n\u001b[0;32m    513\u001b[0m EMG  \u001b[38;5;241m=\u001b[39m  Allcut[:, EMGch1]\n\u001b[1;32m--> 515\u001b[0m SigmaPFC\u001b[38;5;241m=\u001b[39m\u001b[43mget_filt_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPFC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m SigmaS1\u001b[38;5;241m=\u001b[39mget_filt_env(S1, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m    517\u001b[0m ThetaCA1\u001b[38;5;241m=\u001b[39mget_filt_env(CA1, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\n",
      "Cell \u001b[1;32mIn[101], line 129\u001b[0m, in \u001b[0;36mget_filt_env\u001b[1;34m(lfp_signal, lowcut, highcut, fs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_filt_env\u001b[39m(lfp_signal, lowcut, highcut, fs):\n\u001b[1;32m--> 129\u001b[0m     filtered_signal \u001b[38;5;241m=\u001b[39m \u001b[43mbandpass_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlfp_signal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowcut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhighcut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     analytic_signal \u001b[38;5;241m=\u001b[39m hilbert(filtered_signal)\n\u001b[0;32m    131\u001b[0m     envelope \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(analytic_signal)\n",
      "Cell \u001b[1;32mIn[101], line 122\u001b[0m, in \u001b[0;36mbandpass_filter\u001b[1;34m(data, lowcut, highcut, fs, order)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbandpass_filter\u001b[39m(data, lowcut, highcut, fs, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    121\u001b[0m     b, a \u001b[38;5;241m=\u001b[39m butter_bandpass(lowcut, highcut, fs, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m--> 122\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mfiltfilt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:4159\u001b[0m, in \u001b[0;36mfiltfilt\u001b[1;34m(b, a, x, axis, padtype, padlen, method, irlen)\u001b[0m\n\u001b[0;32m   4156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[0;32m   4158\u001b[0m \u001b[38;5;66;03m# method == \"pad\"\u001b[39;00m\n\u001b[1;32m-> 4159\u001b[0m edge, ext \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4160\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mntaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4162\u001b[0m \u001b[38;5;66;03m# Get the steady state of the filter's step response.\u001b[39;00m\n\u001b[0;32m   4163\u001b[0m zi \u001b[38;5;241m=\u001b[39m lfilter_zi(b, a)\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:4209\u001b[0m, in \u001b[0;36m_validate_pad\u001b[1;34m(padtype, padlen, x, axis, ntaps)\u001b[0m\n\u001b[0;32m   4207\u001b[0m \u001b[38;5;66;03m# x's 'axis' dimension must be bigger than edge.\u001b[39;00m\n\u001b[0;32m   4208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[axis] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m edge:\n\u001b[1;32m-> 4209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of the input vector x must be greater \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4210\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan padlen, which is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m edge)\n\u001b[0;32m   4212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m edge \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   4213\u001b[0m     \u001b[38;5;66;03m# Make an extension of length `edge` at each\u001b[39;00m\n\u001b[0;32m   4214\u001b[0m     \u001b[38;5;66;03m# end of the input array.\u001b[39;00m\n\u001b[0;32m   4215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m padtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meven\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: The length of the input vector x must be greater than padlen, which is 15."
     ]
    }
   ],
   "source": [
    "# # Associate Ca2+ signal with sleep stages for each session & subsessions using crossregistration\n",
    "\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "#DrugExperiment=1 if CGP Experiment // DrugExperiment=0 if Baseline Experiment\n",
    "\n",
    "DrugExperimentList=[0,1]\n",
    "\n",
    "#Sleep scoring from '_AB' '_AH' or initial ''\n",
    "suffix='_AB' \n",
    "AnalysisID='_wRealTimeStamps' \n",
    "\n",
    "saveexcel=0\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import quantities as pq\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import sys \n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from ast import literal_eval\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import zscore\n",
    "from scipy import stats\n",
    "from itertools import groupby\n",
    "from IPython.display import display\n",
    "from scipy.interpolate import griddata\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "minian_path = os.path.join(os.path.abspath('.'),'minian')\n",
    "print(\"The folder used for minian procedures is : {}\".format(minian_path))\n",
    "sys.path.append(minian_path)\n",
    "\n",
    "\n",
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")\n",
    "#######################################################################################\n",
    "                                # Define functions #\n",
    "#######################################################################################\n",
    "\n",
    "def Convert(string):\n",
    "            li = list(string.split(\", \"))\n",
    "            li2 = len(li)\n",
    "            return li2\n",
    "\n",
    "def find_session_folders(root_path):\n",
    "    sessions = []\n",
    "    sessions_path=[]\n",
    "    # Iterate through items in the root_path\n",
    "    for item in os.listdir(root_path):\n",
    "        item_path = os.path.join(root_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            # Check if the directory name contains \"session\"\n",
    "            if \"session\" in item:\n",
    "                sessions.append(item)\n",
    "                sessions_path.append(item_path)\n",
    "            else:\n",
    "                # Check the subdirectories of the current directory\n",
    "                for sub_item in os.listdir(item_path):\n",
    "                    sub_item_path = os.path.join(item_path, sub_item)\n",
    "                    if os.path.isdir(sub_item_path) and \"session\" in sub_item:\n",
    "                        sessions.append(sub_item)\n",
    "                        sessions_path.append(sub_item_path)\n",
    "                        \n",
    "    return sessions, sessions_path\n",
    "\n",
    "def filterLFP(lfp, f_lowcut, f_hicut):\n",
    "    range=int(f_hicut-f_lowcut)\n",
    "    fs = 1000\n",
    "    nyq = 0.5 * fs\n",
    "    N = 3 # Filtre order\n",
    "    Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "    b, a = signal.butter(N, Wn, 'band')\n",
    "    filt= signal.filtfilt(b, a, lfp)\n",
    "    # Parameter and computation of CWT\n",
    "    w = 100. #window size\n",
    "    freq = np.linspace(f_lowcut, f_hicut, range)\n",
    "    widths = w*fs / (2*freq*np.pi)\n",
    "    CWT = signal.cwt(filt, signal.morlet2, widths, w=w)\n",
    "    # Projection calculation\n",
    "    absCWT = np.absolute(CWT)\n",
    "    zabsCWT = stats.zscore(absCWT, axis=None)\n",
    "    proj_CWT = np.max(zabsCWT, axis = 0)/range\n",
    "    return proj_CWT\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs  # Nyquist Frequency\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "def get_filt_env(lfp_signal, lowcut, highcut, fs):\n",
    "    filtered_signal = bandpass_filter(lfp_signal, lowcut, highcut, fs)\n",
    "    analytic_signal = hilbert(filtered_signal)\n",
    "    envelope = np.abs(analytic_signal)\n",
    "    window_size = fs*5 #5 sec\n",
    "    smoothed_envelope = moving_average(envelope, window_size)\n",
    "    return smoothed_envelope\n",
    "\n",
    "#######################################################################################\n",
    "                # Load sleep score and Ca2+ time series numpy arrays #\n",
    "#######################################################################################\n",
    "\n",
    "for DrugExperiment in DrugExperimentList: \n",
    "    \n",
    "    MiceList=['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK','Purple' ,'ThreeColDotsOK'] if DrugExperiment else ['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK', 'GreenLinesOK', 'Purple', 'RedLinesOK','ThreeColDotsOK', 'ThreeBlueCrossesOK']\n",
    "    MiceList=['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK','Purple' ,'ThreeColDotsOK'] if DrugExperiment else ['ThreeBlueCrossesOK']\n",
    "\n",
    "    # Get the current date and time\n",
    "    FolderNameSave=str(datetime.now())[:19]\n",
    "    FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "    destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/AB_Analysis/VigSt_{FolderNameSave}{suffix}{AnalysisID}\" if DrugExperiment else f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis/VigSt_{FolderNameSave}{suffix}{AnalysisID}\"\n",
    "    os.makedirs(destination_folder)\n",
    "    folder_to_save=Path(destination_folder)\n",
    "\n",
    "    # Copy the script file to the destination folder\n",
    "    source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/12_13_AssociateMinianSleepScore_FullAuto.py\"\n",
    "    destination_file_path = f\"{destination_folder}/12_13_AssociateMinianSleepScore_FullAuto.txt\"\n",
    "    shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "    Channels = '//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/LFPChannels_perMice.xlsx' \n",
    "    allchannels = pd.read_excel(Channels)\n",
    "\n",
    "    for mice in MiceList:\n",
    "        # Load sleep score and Ca2+ time series numpy arrays\n",
    "        dpath0 = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/CGP/\" if DrugExperiment else \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/\"\n",
    "        dpath=dpath0 + mice\n",
    "        print(f\"####################################################################################\")\n",
    "        print(f\"################################### {mice} ####################################\")\n",
    "        print(f\"####################################################################################\")\n",
    "        print(f\"Path to the folder : {dpath}\")\n",
    "        folder_base = Path(dpath)\n",
    "\n",
    "        mfile = open(folder_base / f'mappingsAB_ALL.pkl', 'rb')\n",
    "        mapping = pickle.load(mfile)\n",
    "\n",
    "        sessions = []\n",
    "        subsessions = []\n",
    "        nb_minian_total=0\n",
    "        dict_Calcium = {}\n",
    "        dict_Spike = {}\n",
    "        dict_Scoring = {}\n",
    "        dict_Stamps = {}\n",
    "        dict_TodropFile = {}\n",
    "        dict_StampsMiniscope = {}\n",
    "        dict_Path={}\n",
    "        dict_LFP={}\n",
    "\n",
    "        sessions, sessions_path = find_session_folders(folder_base)\n",
    "        nb_sessions=len(sessions)\n",
    "\n",
    "        for sess,session in enumerate(sessions):  \n",
    "            session_path=Path(sessions_path[sess])\n",
    "            folder_mini = session_path / f'V4_Miniscope'\n",
    "            nb_subsessions = sum(1 for p in folder_mini.iterdir() if p.is_dir() and p.name.startswith(\"session\"))\n",
    "            ScoringFile = session_path/ f'OpenEphys/ScoredSleep{suffix}.npy'\n",
    "            LFPFile = session_path/ f'OpenEphys/RawDataChannelExtractedDS.npy'\n",
    "            StampsFile = session_path/ f'SynchroFile.xlsx'\n",
    "            StampsMiniscopeFile = folder_mini / f'timeStamps.csv'\n",
    "\n",
    "            if nb_subsessions!=0:\n",
    "                for x in range(1, nb_subsessions+1):            \n",
    "                    subsession= session + str(x)\n",
    "                    subsessions.append(subsession)    \n",
    "                    minian_ds = open_minian(folder_mini / subsession / f'minian')      # OR minianAB\n",
    "                    dict_Path[subsession] = session_path\n",
    "                    dict_Calcium[subsession] = minian_ds['C'] # calcium traces \n",
    "                    dict_Spike[subsession] = minian_ds['S'] # estimated spikes\n",
    "                    dict_Scoring[subsession]  = np.load(ScoringFile)\n",
    "                    dict_LFP[subsession] = np.load(LFPFile, mmap_mode= 'r')\n",
    "                    dict_Stamps[subsession]  = pd.read_excel(StampsFile)\n",
    "                    dict_StampsMiniscope[subsession]  = pd.read_csv(StampsMiniscopeFile)\n",
    "                    try:\n",
    "                        TodropFile = folder_mini / subsession / f'minian/TodropFileAB.json'\n",
    "                        with open(TodropFile, 'r') as f:\n",
    "                            unit_to_drop = json.load(f)\n",
    "                            dict_TodropFile[subsession]  = unit_to_drop\n",
    "                    except:\n",
    "                        TodropFile = folder_mini / subsession / f'minian/TodropFile.json'\n",
    "                        with open(TodropFile, 'r') as f:\n",
    "                            unit_to_drop = json.load(f)\n",
    "                            dict_TodropFile[subsession]  = unit_to_drop\n",
    "                    nb_minian_total+=1\n",
    "            else:\n",
    "                minian_ds = open_minian(folder_mini / f'minian')            # OR minianAB\n",
    "                dict_Path[session] = session_path\n",
    "                dict_Calcium[session] = minian_ds['C'] # calcium traces \n",
    "                dict_Spike[session] = minian_ds['S'] # estimated spikes\n",
    "                dict_Scoring[session]  = np.load(ScoringFile) \n",
    "                dict_LFP[session]  = np.load(LFPFile, mmap_mode= 'r')\n",
    "                dict_Stamps[session]  = pd.read_excel(StampsFile)\n",
    "                dict_StampsMiniscope[session]  = pd.read_csv(StampsMiniscopeFile)\n",
    "                try:\n",
    "                    TodropFile = folder_mini / f'minian/TodropFileAB.json'\n",
    "                    with open(TodropFile, 'r') as f:\n",
    "                        unit_to_drop = json.load(f)\n",
    "                        dict_TodropFile[session]  = unit_to_drop\n",
    "                except:\n",
    "                    TodropFile = folder_mini / f'minian/TodropFile.json'\n",
    "                    with open(TodropFile, 'r') as f:\n",
    "                        unit_to_drop = json.load(f)\n",
    "                        dict_TodropFile[session]  = unit_to_drop\n",
    "                nb_minian_total+=1  \n",
    "\n",
    "        #######################################################################################\n",
    "                                # Cross registration results #\n",
    "        #######################################################################################\n",
    "        \n",
    "        B = mapping['session']    \n",
    "        if mice == 'Purple' and DrugExperiment==0:\n",
    "            index = B.columns\n",
    "            B.columns = index.str.replace('part', 'session2')\n",
    "\n",
    "        #######################################################################################\n",
    "        # Distribute Ca2+ intensity & spikes to vigilance states for each sessions/subsessions #\n",
    "        #######################################################################################\n",
    "        \n",
    "        data = {}\n",
    "        counter=0\n",
    "        VigilanceState_GlobalResults= pd.DataFrame(data, columns=['Mice','Session', 'Session_Time', 'Unique_Unit','UnitNumber','UnitValue', \n",
    "                                                                'Drug', 'Substate','SubstateNumber','DurationSubstate', 'CalciumActivity', \n",
    "                                                                'Avg_CalciumActivity', 'AUC_calcium','Avg_AUC_calcium', 'DeconvSpikeMeanActivity', \n",
    "                                                                'Avg_DeconvSpikeActivity', 'SpikeActivityHz', 'Avg_SpikeActivityHz', 'TotCaPopCoupling', \n",
    "                                                                'TotZ_CaPopCoupling', 'TotSpPopCoupling', 'TotZ_SpPopCoupling', 'SigmaPFC_corr',\n",
    "                                                                'SigmaS1_corr', 'ThetaCA1_corr', 'DeltaS1_corr', 'DeltaPFC_corr','SOS1_corr', \n",
    "                                                                'SOPFC_corr','BetaPFC_corr', 'BetaS1_corr', 'Z_SigmaPFC_corr', 'Z_SigmaS1_corr', \n",
    "                                                                'Z_ThetaCA1_corr', 'Z_DeltaS1_corr','Z_DeltaPFC_corr','Z_SOS1_corr','Z_SOPFC_corr',\n",
    "                                                                'Z_BetaPFC_corr', 'Z_BetaS1_corr'])\n",
    "        \n",
    "        previousEndTime=0\n",
    "        InitialStartTime=0\n",
    "\n",
    "        TotCaCorr=[]\n",
    "        TotSpCorr=[]\n",
    "\n",
    "        StatesCaCorrWakeMatrixBaseline= pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        StatesCaCorrNREMMatrixBaseline=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        StatesCaCorrN2MatrixBaseline=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        StatesCaCorrREMMatrixBaseline=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        StatesCaCorrWakeMatrixCGP=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        StatesCaCorrNREMMatrixCGP=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        StatesCaCorrN2MatrixCGP=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        StatesCaCorrREMMatrixCGP=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "\n",
    "        ITStatesCaCorrWakeMatrixBaseline=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        ITStatesCaCorrNREMMatrixBaseline=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        ITStatesCaCorrREMMatrixBaseline=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        ITStatesCaCorrN2MatrixBaseline=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        ITStatesCaCorrWakeMatrixCGP=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        ITStatesCaCorrNREMMatrixCGP=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        ITStatesCaCorrN2MatrixCGP=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "        ITStatesCaCorrREMMatrixCGP=pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "\n",
    "        CaCorrWakeMatrixBaseline=[]\n",
    "        CaCorrNREMMatrixBaseline=[]\n",
    "        CaCorrN2MatrixBaseline=[]\n",
    "        CaCorrREMMatrixBaseline=[]\n",
    "\n",
    "        SpCorrWakeMatrixBaseline=[]\n",
    "        SpCorrNREMMatrixBaseline=[]\n",
    "        SpCorrN2MatrixBaseline=[]\n",
    "        SpCorrREMMatrixBaseline=[]\n",
    "\n",
    "        RawCaTracesWake_Baseline=[]\n",
    "        RawCaTracesNREM_Baseline=[]\n",
    "        RawCaTracesN2_Baseline=[]\n",
    "        RawCaTracesREM_Baseline=[]\n",
    "\n",
    "        RawSpTracesWake_Baseline=[]\n",
    "        RawSpTracesNREM_Baseline=[]\n",
    "        RawSpTracesN2_Baseline=[]\n",
    "        RawSpTracesREM_Baseline=[]\n",
    "\n",
    "        TotCaCorrBaseline=[]\n",
    "        TotCaCorrCGP=[]\n",
    "        TotSpCorrBaseline=[]\n",
    "        TotSpCorrCGP=[]\n",
    "\n",
    "        CaCorrWakeMatrixCGP=[]\n",
    "        CaCorrNREMMatrixCGP=[]\n",
    "        CaCorrN2MatrixCGP=[]\n",
    "        CaCorrREMMatrixCGP=[]\n",
    "\n",
    "        SpCorrWakeMatrixCGP=[]\n",
    "        SpCorrNREMMatrixCGP=[]\n",
    "        SpCorrN2MatrixCGP=[]\n",
    "        SpCorrREMMatrixCGP=[]\n",
    "\n",
    "        RawCaTracesWake_CGP=[]\n",
    "        RawCaTracesNREM_CGP=[]\n",
    "        RawCaTracesN2_CGP=[]\n",
    "        RawCaTracesREM_CGP=[]\n",
    "\n",
    "        RawSpTracesWake_CGP=[]\n",
    "        RawSpTracesNREM_CGP=[]\n",
    "        RawSpTracesN2_CGP=[]\n",
    "        RawSpTracesREM_CGP=[]\n",
    "\n",
    "        Drugs=['Baseline', 'CGP'] if DrugExperiment else ['Baseline']\n",
    "        if saveexcel: \n",
    "            filenameOut = folder_to_save / f'VigSt_CaCorr_{mice}.xlsx'\n",
    "            excel_writerCa = pd.ExcelWriter(filenameOut)        \n",
    "            filenameOut = folder_to_save / f'VigSt_SpCorr_{mice}.xlsx'\n",
    "            excel_writerSp = pd.ExcelWriter(filenameOut)\n",
    "            filenameOut = folder_to_save / f'VigSt_RawCaTraces_{mice}.xlsx'\n",
    "            excel_writerRawCa = pd.ExcelWriter(filenameOut)        \n",
    "            filenameOut = folder_to_save / f'VigSt_RawSpTraces_{mice}.xlsx'\n",
    "            excel_writerRawSp = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "        for session in list(dict_Stamps.keys()):\n",
    "\n",
    "            drug=os.path.basename(os.path.dirname(dict_Path[session])) if DrugExperiment else 'Baseline'\n",
    "\n",
    "\n",
    "            # Start time & freq miniscope\n",
    "\n",
    "            StartTime = list(dict_Stamps[session][0])[0]\n",
    "            tsmini=dict_StampsMiniscope[session]['Time Stamp (ms)']\n",
    "            minian_freq=round(1/np.mean(np.diff(np.array(tsmini)/1000)))\n",
    "\n",
    "            freqLFP=1000\n",
    "            \n",
    "\n",
    "            # Adjust the StartTime if subsessions\n",
    "\n",
    "            if InitialStartTime==0:\n",
    "                InitialStartTime=StartTime    \n",
    "                firstframe=0\n",
    "                StartTimeMiniscope=0 # start time of miniscope rec of that subsesssions relative to the start of the mniscope recording\n",
    "            else:\n",
    "                if StartTime == InitialStartTime: # just a subsession\n",
    "                    StartTime = previousEndTime + 1/minian_freq #  +1 frame in seconds\n",
    "                    StartTimeMiniscope= StartTime-InitialStartTime\n",
    "                else:  \n",
    "                    InitialStartTime=StartTime # this is a new session\n",
    "                    firstframe=0\n",
    "                    StartTimeMiniscope=0   \n",
    "            \n",
    "\n",
    "            # Remove bad units from recordings\n",
    "\n",
    "            C=dict_Calcium[session]\n",
    "            rec_dur = C.shape[1]\n",
    "            S=dict_Spike[session] \n",
    "\n",
    "            CalciumSub = pd.DataFrame(C, index=C['unit_id'])\n",
    "            recdur = CalciumSub.dropna(axis=1, how='all').shape[1] # probably useless cause not multiple openminian \n",
    "            CalciumSub = CalciumSub.dropna(axis=1, how='all') #cause Nans were added to match the different number of units detected per subsessions \n",
    "            CalciumSub = CalciumSub.dropna(axis=0, how='all') #cause Nans were added to match the different number of units detected per subsessions \n",
    "            SpikeSub = pd.DataFrame(S, index=S['unit_id'])\n",
    "            SpikeSub = SpikeSub.dropna(axis=0, how='all') #cause Nans were added to match the different number of units detected per subsessions \n",
    "            SpikeSub = SpikeSub.dropna(axis=1, how='all') #cause Nans were added to match the different subsessions video sizes\n",
    "\n",
    "            unit_to_drop=dict_TodropFile[session]    \n",
    "            for u in unit_to_drop: \n",
    "                CalciumSub=CalciumSub.drop(index=u)\n",
    "                SpikeSub=SpikeSub.drop(index=u)\n",
    "\n",
    "            indexMappList=B[session]\n",
    "            kept_uniq_unit_List=[]\n",
    "            for unit in CalciumSub.index:\n",
    "                indexMapp = np.where(indexMappList == unit)[0]\n",
    "                kept_uniq_unit_List.append(str(indexMapp))\n",
    "\n",
    "                \n",
    "            # Realigned to the traces to the recorded timestamps \n",
    "\n",
    "            timestamps =  np.array(tsmini[firstframe:firstframe+len(CalciumSub.T)])/freqLFP\n",
    "            x_values = CalciumSub  # Each row is a feature, each column corresponds to a timestamp\n",
    "            sample_rate = minian_freq  # Hz\n",
    "            new_timestamps= np.arange(timestamps[0], timestamps[-1], 1/sample_rate)\n",
    "            Calcium = pd.DataFrame(index=x_values.index, columns=new_timestamps)\n",
    "            for feature in x_values.index:\n",
    "                interpolator = interpolate.interp1d(timestamps, x_values.loc[feature], kind='linear')\n",
    "                Calcium.loc[feature] = interpolator(new_timestamps)\n",
    "\n",
    "            x_values = SpikeSub  # Each row is a feature, each column corresponds to a timestamp\n",
    "            sample_rate = minian_freq  # Hz\n",
    "            new_timestamps= np.arange(timestamps[0], timestamps[-1], 1/sample_rate)\n",
    "            Spike = pd.DataFrame(index=x_values.index, columns=new_timestamps)\n",
    "            for feature in x_values.index:\n",
    "                interpolator = interpolate.interp1d(timestamps, x_values.loc[feature], kind='linear')\n",
    "                Spike.loc[feature] = interpolator(new_timestamps)\n",
    "\n",
    "            Carray=Calcium.values.T.astype(float)\n",
    "            Sarray=Spike.values.T.astype(float)\n",
    "\n",
    "            firstframe=firstframe+len(CalciumSub.T)\n",
    "\n",
    "\n",
    "            # Normalize traces\n",
    "            \n",
    "            #Carray=zscore(Carray, axis=0)\n",
    "            #min=np.min(Carray,axis=0) \n",
    "            #Carray=Carray-min\n",
    "            #Sarray=zscore(Sarray, axis=0)\n",
    "            #min=np.min(Sarray,axis=0) \n",
    "            #Sarray=Sarray-min\n",
    "            \n",
    "            \n",
    "            # Deal with dropped frames (failure to acquire miniscope images)\n",
    "\n",
    "            list_droppedframes = literal_eval(dict_Stamps[session][0][3])    \n",
    "\n",
    "            numbdropfr= 0   \n",
    "            upd_rec_dur=rec_dur\n",
    "            droppedframes_inrec=[]\n",
    "            for item in list_droppedframes: \n",
    "                if item < (round(StartTimeMiniscope*minian_freq) + upd_rec_dur) and item > round(StartTimeMiniscope*minian_freq):\n",
    "                    droppedframes_inrec.append(item-round(StartTimeMiniscope*minian_freq))\n",
    "                    upd_rec_dur+=1 #add the dropped frame to the recording length\n",
    "                    numbdropfr+=1                        \n",
    "\n",
    "            EndTime = StartTime + (upd_rec_dur/minian_freq) # in seconds\n",
    "            previousEndTime=EndTime \n",
    "\n",
    "            print(session, ': starts at', round(StartTime,1), 's & ends at', round(EndTime,1), 's (', round(upd_rec_dur/minian_freq,1), 's duration, ', numbdropfr, 'dropped frames, minian frequency =', minian_freq, 'Hz, drug = ', drug, ')...') \n",
    "            sentence1= f\"... kept values = {kept_uniq_unit_List}\"\n",
    "            print(sentence1)\n",
    "\n",
    "            nb_unit=len(CalciumSub)\n",
    "            if nb_unit==0:\n",
    "                continue  # next iteration\n",
    "\n",
    "            # Replace dropped frame in calcium and spike traces with the previous value\n",
    "\n",
    "            for droppedframe in droppedframes_inrec: \n",
    "                row_to_repeat = Carray[droppedframe]  \n",
    "                Carray = np.vstack((Carray[:droppedframe], row_to_repeat, Carray[droppedframe:]))\n",
    "                row_to_repeat = Sarray[droppedframe]  \n",
    "                Sarray = np.vstack((Sarray[:droppedframe], row_to_repeat, Sarray[droppedframe:]))\n",
    "\n",
    "\n",
    "            # Upscale scoring to miniscope frequency\n",
    "\n",
    "            scale_factor=minian_freq/0.2  #cause scoring was done in 5 seconds bin, ie 0.2 Hz\n",
    "            SleepScoredTS=dict_Scoring[session]\n",
    "            SleepScoredTS_upscaled = np.repeat(SleepScoredTS, scale_factor, axis=0)\n",
    "            StartTime_frame=round(StartTime*minian_freq)\n",
    "            SleepScoredTS_upscaled_ministart=SleepScoredTS_upscaled[StartTime_frame:StartTime_frame+upd_rec_dur]\n",
    "\n",
    "\n",
    "            # Remove N2 stage\n",
    "\n",
    "            SleepScoredTS_upscaled_ministart[SleepScoredTS_upscaled_ministart == 0.5] = 0\n",
    "            mapp = {1.5: 'Wake', 0: 'NREM',  1: 'REM'}\n",
    "            #mapp = {1.5: 'Wake', 0.5: 'N2', 0: 'NREM',  1: 'REM'}\n",
    "\n",
    "            # Determine each substate identity and duration\n",
    "            array=SleepScoredTS_upscaled_ministart\n",
    "            substates_duration = [len(list(group)) for key, group in groupby(array)]\n",
    "            substates_identity = [key for key, _ in groupby(array)]\n",
    "            substates_end = np.array(substates_duration).cumsum()        \n",
    "            substates_start =np.append([0],substates_end[:-1]) #substates_start =np.append([1],substates_end+1) create 1 second gap\n",
    "            substates_identity = [mapp[num] for num in substates_identity]\n",
    "            substates = pd.DataFrame(list(zip(substates_identity, substates_duration, substates_start, substates_end)), columns=['Identity', 'Duration', 'Start','End'])\n",
    "\n",
    "            # Aligned LFP to Calcium traces\n",
    "            PFCch1=int(allchannels[mice][0].split(',')[0])\n",
    "            PFCch2=int(allchannels[mice][0].split(',')[1])\n",
    "            CA1ch1=int(allchannels[mice][2].split(',')[0])\n",
    "            CA1ch2=int(allchannels[mice][2].split(',')[1])\n",
    "            S1ch1=int(allchannels[mice][1].split(',')[0])\n",
    "            S1ch2=int(allchannels[mice][1].split(',')[1])\n",
    "            EMGch1=int(allchannels[mice][3])\n",
    "            \n",
    "            All=dict_LFP[session]\n",
    "            Allcut=All[round(StartTime*1000): round(EndTime*1000),:]\n",
    "\n",
    "            PFC  =  Allcut[:, PFCch1]-Allcut[:, PFCch2] \n",
    "            CA1  =  Allcut[:, CA1ch1]-Allcut[:, CA1ch2] \n",
    "            S1  =  Allcut[:, S1ch1]-Allcut[:, S1ch2] \n",
    "            EMG  =  Allcut[:, EMGch1]\n",
    "\n",
    "            SigmaPFC=get_filt_env(PFC, 10, 18, 1000)\n",
    "            SigmaS1=get_filt_env(S1, 10, 18, 1000)\n",
    "            ThetaCA1=get_filt_env(CA1, 5, 9, 1000)\n",
    "            DeltaS1=get_filt_env(S1, 1, 4, 1000)       \n",
    "            DeltaPFC=get_filt_env(PFC, 1, 4, 1000)          \n",
    "            SOS1=get_filt_env(S1, .1, 1, 1000)       \n",
    "            SOPFC=get_filt_env(PFC, .1, 1, 1000)       \n",
    "            BetaPFC=get_filt_env(PFC, 16, 35, 1000)\n",
    "            BetaS1=get_filt_env(S1, 16, 35, 1000)\n",
    "\n",
    "            # Downscale to Calcium traces\n",
    "            SigmaPFCds = griddata(np.linspace(0, 1, len(SigmaPFC)), SigmaPFC, np.linspace(0, 1, len(Carray)), method='linear')\n",
    "            SigmaS1ds = griddata(np.linspace(0, 1, len(SigmaS1)), SigmaS1, np.linspace(0, 1, len(Carray)), method='linear')\n",
    "            ThetaCA1ds = griddata(np.linspace(0, 1, len(ThetaCA1)), ThetaCA1, np.linspace(0, 1, len(Carray)), method='linear')\n",
    "            DeltaS1ds = griddata(np.linspace(0, 1, len(DeltaS1)), DeltaS1, np.linspace(0, 1, len(Carray)), method='linear')\n",
    "            DeltaPFCds = griddata(np.linspace(0, 1, len(DeltaPFC)), DeltaPFC, np.linspace(0, 1, len(Carray)), method='linear')\n",
    "            BetaPFCds = griddata(np.linspace(0, 1, len(BetaPFC)), BetaPFC, np.linspace(0, 1, len(Carray)), method='linear')\n",
    "            BetaS1ds = griddata(np.linspace(0, 1, len(BetaS1)), BetaS1, np.linspace(0, 1, len(Carray)), method='linear')\n",
    "            SOS1ds = griddata(np.linspace(0, 1, len(SOS1)), SOS1, np.linspace(0, 1, len(Carray)), method='linear')\n",
    "            SOPFCds = griddata(np.linspace(0, 1, len(SOPFC)), SOPFC, np.linspace(0, 1, len(Carray)), method='linear')\n",
    "\n",
    "            for m in mapp:\n",
    "\n",
    "                # Correlation between each neurons according to vigilance states \n",
    "\n",
    "                Bool = (SleepScoredTS_upscaled_ministart == m)\n",
    "                Carray_VigSpe = Carray.copy()\n",
    "                Carray_VigSpe = Carray_VigSpe[0:np.shape(SleepScoredTS_upscaled_ministart)[0],:] # if Calcium imaging longer than LFP rec\n",
    "                Carray_VigSpe = Carray_VigSpe[Bool, :]\n",
    "                \n",
    "                CaCorrVigStateMatrixName=f'CaCorr{mapp[m]}Matrix{drug}'\n",
    "                CaCorrVigStateMatrix = locals()[CaCorrVigStateMatrixName]\n",
    "                CaCorrMatrix=[]\n",
    "                CaCorrMatrix = pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "                \n",
    "                Sarray_VigSpe = Sarray.copy()\n",
    "                Sarray_VigSpe = Sarray_VigSpe[0:np.shape(SleepScoredTS_upscaled_ministart)[0],:] # if Calcium imaging longer than LFP rec\n",
    "                Sarray_VigSpe = Sarray_VigSpe[Bool, :]    \n",
    "\n",
    "                SpCorrVigStateMatrixName=f'SpCorr{mapp[m]}Matrix{drug}'\n",
    "                SpCorrVigStateMatrix = locals()[SpCorrVigStateMatrixName]\n",
    "                SpCorrMatrix=[]\n",
    "                SpCorrMatrix = pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "\n",
    "                if saveexcel:\n",
    "                    RawCaTracesVigStateMatrixName=f'RawCaTraces{mapp[m]}_{drug}'\n",
    "                    RawCaTracesVigStateMatrix = locals()[RawCaTracesVigStateMatrixName]\n",
    "                    RawCaTraces=[]\n",
    "                    RawCaTraces=pd.DataFrame(Carray_VigSpe, columns=[f\"{mice}{str(i).replace('[','').replace(']','')}\" for i in kept_uniq_unit_List])\n",
    "                    unique_columns = RawCaTraces.columns[RawCaTraces.columns.to_series().duplicated()] # remove units that has an empty unique index '[]'\n",
    "                    RawCaTraces = RawCaTraces.drop(columns=unique_columns)\n",
    "                    RawCaTracesVigStateMatrix.append(RawCaTraces)                \n",
    "\n",
    "                    RawSpTracesVigStateMatrixName=f'RawSpTraces{mapp[m]}_{drug}'\n",
    "                    RawSpTracesVigStateMatrix = locals()[RawSpTracesVigStateMatrixName]\n",
    "                    RawSpTraces=[]\n",
    "                    RawSpTraces=pd.DataFrame(Sarray_VigSpe, columns=[f\"{mice}{str(i).replace('[','').replace(']','')}\" for i in kept_uniq_unit_List])\n",
    "                    unique_columns = RawSpTraces.columns[RawSpTraces.columns.to_series().duplicated()] # remove units that has an empty unique index '[]'\n",
    "                    RawSpTraces = RawSpTraces.drop(columns=unique_columns)\n",
    "                    RawSpTracesVigStateMatrix.append(RawSpTraces) \n",
    "                \n",
    "                for unit in range(nb_unit): \n",
    "\n",
    "                    Carray_unit =Carray_VigSpe[:,unit]\n",
    "                    Darray_unit =Sarray_VigSpe[:,unit] # on deconv spike not on spike rate \n",
    "                    otherunit_range = [x for x in range(nb_unit) if x != unit]\n",
    "\n",
    "                    for unit2 in range(nb_unit):\n",
    "\n",
    "                        Carray_unit2 =Carray_VigSpe[:,unit2]\n",
    "                        Darray_unit2 =Sarray_VigSpe[:,unit2]         \n",
    "\n",
    "                        indexMapp = str(np.where(B[session] == Calcium.index[unit])[0]).replace('[','').replace(']','')\n",
    "                        indexMapp2 = np.where(B[session] == Calcium.index[unit2])[0]\n",
    "\n",
    "                        if any(indexMapp) and len(indexMapp2)>0:      \n",
    "                                            \n",
    "                            corr_matrix = np.corrcoef(Carray_unit, Carray_unit2)\n",
    "                            CaCorrMatrix[f'{mice}{indexMapp}'][indexMapp2]={1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                            \n",
    "                            corr_matrix = np.corrcoef(Darray_unit, Darray_unit2)\n",
    "                            SpCorrMatrix[f'{mice}{indexMapp}'][indexMapp2]={1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                            \n",
    "                CaCorrVigStateMatrix.append(CaCorrMatrix)\n",
    "                SpCorrVigStateMatrix.append(SpCorrMatrix) \n",
    "\n",
    "            TotCaCorrName=f'TotCaCorr{drug}'\n",
    "            TotCaCorr = locals()[TotCaCorrName]\n",
    "            TotSpCorrName=f'TotSpCorr{drug}'\n",
    "            TotSpCorr = locals()[TotSpCorrName]\n",
    "            \n",
    "            TotCaCorrMatrix=[]\n",
    "            TotCaCorrMatrix = pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "            TotSpCorrMatrix=[]\n",
    "            TotSpCorrMatrix = pd.DataFrame(columns=[f'{mice}{str(i)}' for i in range(len(B))], index=[i for i in range(len(B))])\n",
    "\n",
    "            for unit in range(nb_unit): \n",
    "\n",
    "                Carray_unit =Carray[:,unit]\n",
    "                Darray_unit =Sarray[:,unit]\n",
    "                peaks, _ = find_peaks(Darray_unit)\n",
    "                Sarray_unit=np.zeros(len(Darray_unit))\n",
    "                Sarray_unit[peaks]=1    \n",
    "\n",
    "                # Correlation with LFP power density\n",
    "        \n",
    "                corr_matrix = np.corrcoef(Carray_unit, SigmaPFCds)\n",
    "                CorrSigmaPFC= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                Z_CorrSigmaPFC = np.arctanh(corCorrected)\n",
    "                corr_matrix = np.corrcoef(Carray_unit, SigmaS1ds)\n",
    "                CorrSigmaS1= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                Z_CorrSigmaS1 = np.arctanh(corCorrected)\n",
    "                corr_matrix = np.corrcoef(Carray_unit, ThetaCA1ds)\n",
    "                CorrThetaCA1= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                Z_CorrThetaCA1 = np.arctanh(corCorrected)\n",
    "                corr_matrix = np.corrcoef(Carray_unit, DeltaS1ds)\n",
    "                CorrDeltaS1= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                Z_CorrDeltaS1 = np.arctanh(corCorrected)            \n",
    "                corr_matrix = np.corrcoef(Carray_unit, DeltaPFCds)\n",
    "                CorrDeltaPFC= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                Z_CorrDeltaPFC = np.arctanh(corCorrected)\n",
    "                corr_matrix = np.corrcoef(Carray_unit, BetaPFCds)\n",
    "                CorrBetaPFC= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                Z_CorrBetaPFC = np.arctanh(corCorrected)\n",
    "                corr_matrix = np.corrcoef(Carray_unit, BetaS1ds)\n",
    "                CorrBetaS1= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                Z_CorrBetaS1 = np.arctanh(corCorrected)\n",
    "                corr_matrix = np.corrcoef(Carray_unit, SOS1ds)\n",
    "                CorrSOS1= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                Z_CorrSOS1 = np.arctanh(corCorrected)            \n",
    "                corr_matrix = np.corrcoef(Carray_unit, SOPFCds)\n",
    "                CorrSOPFC= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                Z_CorrSOPFC = np.arctanh(corCorrected)\n",
    "                \n",
    "                # Population Coupling independent of vigilance states \n",
    "\n",
    "                Carray_Population =np.mean(Carray[:,otherunit_range], axis=1)\n",
    "                corr_matrix = np.corrcoef(Carray_unit, Carray_Population)\n",
    "                TotCaPopCoupling= np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                TotZ_CaPopCoupling = np.arctanh(corCorrected)\n",
    "\n",
    "                Sarray_Population =np.mean(Sarray[:,otherunit_range], axis=1)\n",
    "                corr_matrix = np.corrcoef(Darray_unit, Sarray_Population)\n",
    "                TotSpPopCoupling = np.round(corr_matrix[0, 1],5)\n",
    "                corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                TotZ_SpPopCoupling= np.arctanh(corCorrected)\n",
    "\n",
    "                # Correlation between each neurons independent of vigilance states \n",
    "\n",
    "                otherunit_range = [x for x in range(nb_unit) if x != unit]\n",
    "                for unit2 in otherunit_range:\n",
    "\n",
    "                    Carray_unit2 =Carray[:,unit2]\n",
    "                    Darray_unit2 =Sarray[:,unit2]  \n",
    "                \n",
    "                    indexMapp = str(np.where(B[session] == Calcium.index[unit])[0]).replace('[','').replace(']','')\n",
    "                    indexMapp2 = np.where(B[session] == Calcium.index[unit2])[0]\n",
    "\n",
    "                    if any(indexMapp) and len(indexMapp2)>0:    \n",
    "                        \n",
    "                        corr_matrix = np.corrcoef(Carray_unit, Carray_unit2)\n",
    "                        TotCaCorrMatrix[f'{mice}{indexMapp}'][indexMapp2]={1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                        \n",
    "                        corr_matrix = np.corrcoef(Darray_unit, Darray_unit2)\n",
    "                        TotSpCorrMatrix[f'{mice}{indexMapp}'][indexMapp2]={1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "\n",
    "                # For each substates\n",
    "                for index in range(len(substates)):\n",
    "                    \n",
    "                    ca_input_sub=Carray_unit[substates.Start[index]:substates.End[index]]\n",
    "                    ds_input_sub=Darray_unit[substates.Start[index]:substates.End[index]]\n",
    "                    sp_input_sub=Sarray_unit[substates.Start[index]:substates.End[index]]\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Mice'] = mice\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Session'] = session\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Session_Time'] = None \n",
    "                    \n",
    "                    indexMapp = np.where(B[session] == Calcium.index[unit])[0]\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Unique_Unit'] = indexMapp if len(indexMapp)>0 else None\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'UnitNumber'] = unit\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'UnitValue'] = Calcium.index[unit]\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Drug'] =  os.path.basename(os.path.dirname(dict_Path[session])) if DrugExperiment else 'Baseline'\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Substate'] = substates.Identity[index]\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'SubstateNumber'] = substates.index[index]\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'DurationSubstate'] = (substates.Duration[index]/minian_freq)\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'CalciumActivity'] = ca_input_sub.mean()\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Avg_CalciumActivity'] = Carray_unit.mean()\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'AUC_calcium'] = np.trapz(ca_input_sub,np.arange(0,len(ca_input_sub),1))\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Avg_AUC_calcium'] = np.trapz(Carray_unit,np.arange(0,len(Carray_unit),1))\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'DeconvSpikeMeanActivity'] = ds_input_sub.mean()\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Avg_DeconvSpikeActivity'] = Darray_unit.mean()\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'SpikeActivityHz'] = sp_input_sub.sum()/(len(sp_input_sub)/minian_freq)\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Avg_SpikeActivityHz'] = Sarray_unit.sum()/(len(Sarray_unit)/minian_freq)\n",
    "\n",
    "                    otherunit_range = [x for x in range(nb_unit) if x != unit]\n",
    "                    Carray_Population =np.mean(Carray[:,otherunit_range], axis=1)\n",
    "                    ca_input_sub2=Carray_Population[substates.Start[index]:substates.End[index]]\n",
    "                    corr_matrix = np.corrcoef(ca_input_sub, ca_input_sub2)\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'CaPopCoupling'] = np.round(corr_matrix[0, 1],5)\n",
    "                    corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_CaPopCoupling'] = np.arctanh(corCorrected)\n",
    "\n",
    "                    Sarray_Population =np.mean(Sarray[:,otherunit_range], axis=1)\n",
    "                    ds_input_sub2=Sarray_Population[substates.Start[index]:substates.End[index]]\n",
    "                    corr_matrix = np.corrcoef(ds_input_sub, ds_input_sub2)\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'SpPopCoupling'] = np.round(corr_matrix[0, 1],5)\n",
    "                    corCorrected = {1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_SpPopCoupling'] = np.arctanh(corCorrected)\n",
    "                    \n",
    "                    VigilanceState_GlobalResults.loc[counter, 'TotCaPopCoupling'] = TotCaPopCoupling\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'TotZ_CaPopCoupling'] = TotZ_CaPopCoupling\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'TotSpPopCoupling'] = TotSpPopCoupling\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'TotZ_SpPopCoupling'] = TotZ_SpPopCoupling\n",
    "                    \n",
    "                    VigilanceState_GlobalResults.loc[counter, 'SOS1_corr'] = CorrSOS1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'SOPFC_corr'] = CorrSOPFC\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'DeltaS1_corr'] = CorrDeltaS1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'DeltaPFC_corr'] = CorrDeltaPFC\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'ThetaCA1_corr'] = CorrThetaCA1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'SigmaS1_corr'] = CorrSigmaS1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'SigmaPFC_corr'] = CorrSigmaPFC\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'BetaS1_corr'] = CorrBetaS1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'BetaPFC_corr'] = CorrBetaPFC\n",
    "\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_SOS1_corr'] = Z_CorrSOS1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_SOPFC_corr'] = Z_CorrSOPFC\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_DeltaS1_corr'] = Z_CorrDeltaS1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_DeltaPFC_corr'] = Z_CorrDeltaPFC\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_ThetaCA1_corr'] = Z_CorrThetaCA1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_SigmaS1_corr'] = Z_CorrSigmaS1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_SigmaPFC_corr'] = Z_CorrSigmaPFC\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_BetaS1_corr'] = Z_CorrBetaS1\n",
    "                    VigilanceState_GlobalResults.loc[counter, 'Z_BetaPFC_corr'] = Z_CorrBetaPFC\n",
    "\n",
    "                    StatesCaCorrName=f'StatesCaCorr{substates.Identity[index]}Matrix{drug}'\n",
    "                    StatesCaCorrMatrix = locals()[StatesCaCorrName]\n",
    "                    IterationMatrixName=f'ITStatesCaCorr{substates.Identity[index]}Matrix{drug}'\n",
    "                    IterationMatrix = locals()[IterationMatrixName]\n",
    "                    \n",
    "                    # Correlation between each neurons dependent of vigilance states \n",
    "                    if (substates.Duration[index]/minian_freq)>=20:\n",
    "                        otherunit_range = [x for x in range(nb_unit) if x != unit]\n",
    "                        for unit2 in otherunit_range:\n",
    "                            Carray_unit2 =Carray[:,unit2]\n",
    "                            ca2_input_sub=Carray_unit2[substates.Start[index]:substates.End[index]]\n",
    "                        \n",
    "                            indexMapp = str(np.where(B[session] == Calcium.index[unit])[0]).replace('[','').replace(']','')\n",
    "                            indexMapp2 = np.where(B[session] == Calcium.index[unit2])[0]\n",
    "\n",
    "                            if any(indexMapp) and len(indexMapp2)>0:    \n",
    "\n",
    "                                corr_matrix = np.corrcoef(ca_input_sub, ca2_input_sub)\n",
    "                                StatesCaCorrMatrix[f'{mice}{indexMapp}'][indexMapp2]=StatesCaCorrMatrix[f'{mice}{indexMapp}'][indexMapp2]+  np.arctanh({1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5))) if not math.isnan(StatesCaCorrMatrix[f'{mice}{indexMapp}'][indexMapp2]) else  np.arctanh({1: 0.99999, -1: -0.99999}.get(np.round(corr_matrix[0, 1],5), np.round(corr_matrix[0, 1],5)))\n",
    "                                if not math.isnan(StatesCaCorrMatrix[f'{mice}{indexMapp}'][indexMapp2]):\n",
    "                                    if not math.isnan(IterationMatrix[f'{mice}{indexMapp}'][indexMapp2]):\n",
    "                                        IterationMatrix[f'{mice}{indexMapp}'][indexMapp2]= IterationMatrix[f'{mice}{indexMapp}'][indexMapp2]+1 \n",
    "                                    else:\n",
    "                                        IterationMatrix[f'{mice}{indexMapp}'][indexMapp2]= 1 \n",
    "                    counter+=1\n",
    "\n",
    "            TotCaCorr.append(TotCaCorrMatrix)\n",
    "            TotSpCorr.append(TotSpCorrMatrix)\n",
    "\n",
    "        dataCaCorr={}\n",
    "        dataSpCorr={}\n",
    "        dataCaCorr2={}\n",
    "        dataSpCorr2={}\n",
    "        dataStatesCaCorr={}\n",
    "\n",
    "        for Drug in Drugs:\n",
    "            TotCaCorrName=f'TotCaCorr{Drug}'\n",
    "            TotCaCorr = locals()[TotCaCorrName]\n",
    "            TotSpCorrName=f'TotSpCorr{Drug}'\n",
    "            TotSpCorr = locals()[TotSpCorrName]\n",
    "            if len(TotCaCorr)>0: \n",
    "                combined_df = pd.concat(TotCaCorr, ignore_index=False)\n",
    "                IterationNb=combined_df.groupby(combined_df.index).count()\n",
    "                combined_df = combined_df.groupby(combined_df.index).sum() #mean\n",
    "                combined_df.index= [mice + str(idx) for idx in combined_df.index]\n",
    "                combined_df = combined_df[~(combined_df.fillna(0) == 0).all(axis=1)]\n",
    "                combined_df = combined_df.loc[:, ~(combined_df.fillna(0) == 0).all(axis=0)]\n",
    "                IterationNb = IterationNb[~(IterationNb.fillna(0) == 0).all(axis=1)]\n",
    "                IterationNb = IterationNb.loc[:, ~(IterationNb.fillna(0) == 0).all(axis=0)]\n",
    "                IterationNb.index=combined_df.index\n",
    "                dataCaCorr2[f'{Drug}']=combined_df\n",
    "\n",
    "                combined_df = pd.concat(TotCaCorr, ignore_index=False)\n",
    "                combined_df = combined_df.applymap(lambda x: np.arctanh(x) if not pd.isna(x) else np.nan)\n",
    "                combined_df = combined_df.groupby(combined_df.index).sum() #mean\n",
    "                combined_df.index = [mice + str(idx) for idx in combined_df.index]\n",
    "                combined_df = combined_df[~(combined_df.fillna(0) == 0).all(axis=1)]\n",
    "                combined_df = combined_df.loc[:, ~(combined_df.fillna(0) == 0).all(axis=0)]\n",
    "                dataCaCorr2[f'Z_{Drug}']=combined_df\n",
    "                dataCaCorr2[f'{Drug}_IterationNb']=IterationNb\n",
    "\n",
    "                combined_df = pd.concat(TotSpCorr, ignore_index=False)\n",
    "                IterationNb=combined_df.groupby(combined_df.index).count()\n",
    "                combined_df = combined_df.groupby(combined_df.index).sum() #mean\n",
    "                combined_df.index= [mice + str(idx) for idx in combined_df.index]\n",
    "                combined_df = combined_df[~(combined_df.fillna(0) == 0).all(axis=1)]\n",
    "                combined_df = combined_df.loc[:, ~(combined_df.fillna(0) == 0).all(axis=0)]\n",
    "                IterationNb = IterationNb[~(IterationNb.fillna(0) == 0).all(axis=1)]\n",
    "                IterationNb = IterationNb.loc[:, ~(IterationNb.fillna(0) == 0).all(axis=0)]\n",
    "                IterationNb.index=combined_df.index\n",
    "                dataSpCorr2[f'{Drug}']=combined_df\n",
    "\n",
    "                combined_df = pd.concat(TotSpCorr, ignore_index=False)\n",
    "                combined_df = combined_df.applymap(lambda x: np.arctanh(x) if not pd.isna(x) else np.nan)\n",
    "                combined_df = combined_df.groupby(combined_df.index).sum() #mean\n",
    "                combined_df.index = [mice + str(idx) for idx in combined_df.index]\n",
    "                combined_df = combined_df[~(combined_df.fillna(0) == 0).all(axis=1)]\n",
    "                combined_df = combined_df.loc[:, ~(combined_df.fillna(0) == 0).all(axis=0)]\n",
    "                dataSpCorr2[f'Z_{Drug}']=combined_df\n",
    "                dataSpCorr2[f'{Drug}_IterationNb']=IterationNb\n",
    "\n",
    "            for m in mapp:\n",
    "                IterationMatrixName=f'ITStatesCaCorr{mapp[m]}Matrix{Drug}'\n",
    "                IterationMatrix = locals()[IterationMatrixName]\n",
    "                StatesCaCorrMatrixName=f'StatesCaCorr{mapp[m]}Matrix{Drug}'\n",
    "                StatesCaCorrMatrix = locals()[StatesCaCorrMatrixName]\n",
    "                if len(StatesCaCorrMatrix)>0: # cause sometimes no Baseline conditions in CGP experiments\n",
    "                    StatesCaCorrMatrix.index = [mice + str(idx) for idx in StatesCaCorrMatrix.index]\n",
    "                    IterationMatrix.index = StatesCaCorrMatrix.index\n",
    "                    dataStatesCaCorr[f'{Drug}_{mapp[m]}']=StatesCaCorrMatrix\n",
    "                    dataStatesCaCorr[f'Iteration_{Drug}_{mapp[m]}']=IterationMatrix\n",
    "\n",
    "                CaCorrVigStateMatrixName=f'CaCorr{mapp[m]}Matrix{Drug}'\n",
    "                CaCorrVigStateMatrix = locals()[CaCorrVigStateMatrixName]\n",
    "                if len(CaCorrVigStateMatrix)>0: # cause sometimes no Baseline conditions in CGP experiments\n",
    "                    combined_df = pd.concat(CaCorrVigStateMatrix, ignore_index=False)\n",
    "                    IterationNb=combined_df.groupby(combined_df.index).count()\n",
    "                    combined_df = combined_df.groupby(combined_df.index).sum() #mean\n",
    "                    combined_df.index= [mice + str(idx) for idx in combined_df.index]\n",
    "                    combined_df = combined_df[~(combined_df.fillna(0) == 0).all(axis=1)]\n",
    "                    combined_df = combined_df.loc[:, ~(combined_df.fillna(0) == 0).all(axis=0)]\n",
    "                    IterationNb = IterationNb[~(IterationNb.fillna(0) == 0).all(axis=1)]\n",
    "                    IterationNb = IterationNb.loc[:, ~(IterationNb.fillna(0) == 0).all(axis=0)]\n",
    "                    IterationNb.index=combined_df.index\n",
    "                    if saveexcel: combined_df.to_excel(excel_writerCa, sheet_name=f'{Drug}_{mapp[m]}', index=True, header=True) \n",
    "                    dataCaCorr[f'{Drug}_{mapp[m]}']=combined_df\n",
    "                    \n",
    "                    combined_df = pd.concat(CaCorrVigStateMatrix, ignore_index=False)\n",
    "                    combined_df = combined_df.applymap(lambda x: np.arctanh(x) if not pd.isna(x) else np.nan)\n",
    "                    combined_df = combined_df.groupby(combined_df.index).sum() #mean\n",
    "                    combined_df.index = [mice + str(idx) for idx in combined_df.index]\n",
    "                    combined_df = combined_df[~(combined_df.fillna(0) == 0).all(axis=1)]\n",
    "                    combined_df = combined_df.loc[:, ~(combined_df.fillna(0) == 0).all(axis=0)]\n",
    "                    if saveexcel: combined_df.to_excel(excel_writerCa, sheet_name=f'Z_{Drug}_{mapp[m]}', index=True, header=True)   \n",
    "                    dataCaCorr[f'Z_{Drug}_{mapp[m]}']=combined_df\n",
    "                    if saveexcel: IterationNb.to_excel(excel_writerCa, sheet_name=f'{Drug}_{mapp[m]}_IterationNb', index=True, header=True) \n",
    "                    dataCaCorr[f'{Drug}_{mapp[m]}_IterationNb']=IterationNb\n",
    "\n",
    "                    SpCorrVigStateMatrixName=f'SpCorr{mapp[m]}Matrix{Drug}'\n",
    "                    SpCorrVigStateMatrix = locals()[SpCorrVigStateMatrixName]\n",
    "                    combined_df = pd.concat(SpCorrVigStateMatrix, ignore_index=False)\n",
    "                    IterationNb=combined_df.groupby(combined_df.index).count()\n",
    "                    combined_df = combined_df.groupby(combined_df.index).sum()\n",
    "                    combined_df.index = [mice + str(idx) for idx in combined_df.index]\n",
    "                    combined_df = combined_df[~(combined_df.fillna(0) == 0).all(axis=1)]\n",
    "                    combined_df = combined_df.loc[:, ~(combined_df.fillna(0) == 0).all(axis=0)]\n",
    "                    IterationNb = IterationNb[~(IterationNb.fillna(0) == 0).all(axis=1)]\n",
    "                    IterationNb = IterationNb.loc[:, ~(IterationNb.fillna(0) == 0).all(axis=0)]\n",
    "                    IterationNb.index=combined_df.index\n",
    "                    if saveexcel: combined_df.to_excel(excel_writerSp, sheet_name=f'{Drug}_{mapp[m]}', index=True, header=True) \n",
    "                    dataSpCorr[f'{Drug}_{mapp[m]}']=combined_df\n",
    "                    \n",
    "                    combined_df = pd.concat(SpCorrVigStateMatrix, ignore_index=False)\n",
    "                    combined_df = combined_df.applymap(lambda x: np.arctanh(x) if not pd.isna(x) else np.nan)\n",
    "                    combined_df = combined_df.groupby(combined_df.index).sum()\n",
    "                    combined_df.index = [mice + str(idx) for idx in combined_df.index]\n",
    "                    combined_df = combined_df[~(combined_df.fillna(0) == 0).all(axis=1)]\n",
    "                    combined_df = combined_df.loc[:, ~(combined_df.fillna(0) == 0).all(axis=0)]\n",
    "                    if saveexcel: combined_df.to_excel(excel_writerSp, sheet_name=f'Z_{Drug}_{mapp[m]}', index=True, header=True) \n",
    "                    dataSpCorr[f'Z_{Drug}_{mapp[m]}']=combined_df                \n",
    "                    if saveexcel: IterationNb.to_excel(excel_writerSp, sheet_name=f'{Drug}_{mapp[m]}_IterationNb', index=True, header=True) \n",
    "                    dataSpCorr[f'{Drug}_{mapp[m]}_IterationNb']=IterationNb\n",
    "                \n",
    "                if saveexcel:\n",
    "                    RawCaTracesVigStateMatrixName=f'RawCaTraces{mapp[m]}_{Drug}'\n",
    "                    RawCaTracesVigStateMatrix= locals()[RawCaTracesVigStateMatrixName]\n",
    "                    if len(RawCaTracesVigStateMatrix)>0: # cause sometimes no Baseline conditions in CGP experiments\n",
    "                        combined_df = pd.concat(RawCaTracesVigStateMatrix, ignore_index=False)\n",
    "                        combined_df.index = [mice + str(idx) for idx in combined_df.index]\n",
    "                        combined_df = combined_df.dropna(axis=0, how='all')\n",
    "                        combined_df = combined_df.dropna(axis=1, how='all')\n",
    "                        combined_df.to_excel(excel_writerRawCa, sheet_name=f'{Drug}_{mapp[m]}', index=False, header=True)   \n",
    "\n",
    "                        RawSpTracesVigStateMatrixName=f'RawSpTraces{mapp[m]}_{Drug}'\n",
    "                        RawSpTracesVigStateMatrix= locals()[RawSpTracesVigStateMatrixName]\n",
    "                        combined_df = pd.concat(RawSpTracesVigStateMatrix, ignore_index=False)\n",
    "                        combined_df.index = [mice + str(idx) for idx in combined_df.index]\n",
    "                        combined_df = combined_df.dropna(axis=0, how='all')\n",
    "                        combined_df = combined_df.dropna(axis=1, how='all')\n",
    "                        combined_df.to_excel(excel_writerRawSp, sheet_name=f'{Drug}_{mapp[m]}', index=False, header=True)   \n",
    "            \n",
    "        if saveexcel: \n",
    "            excel_writerCa.close() \n",
    "            excel_writerSp.close() \n",
    "            filenameOut = folder_to_save / f'VigSt_Global_{mice}.xlsx'\n",
    "            writer = pd.ExcelWriter(filenameOut)\n",
    "            VigilanceState_GlobalResults.to_excel(writer)\n",
    "            writer.close()\n",
    "            excel_writerRawCa.close()\n",
    "            excel_writerRawSp.close()\n",
    "\n",
    "        filenameOut = folder_to_save / f'VigSt_CaCorr_{mice}.pkl'\n",
    "        with open(filenameOut, 'wb') as pickle_file:\n",
    "            pickle.dump(dataCaCorr, pickle_file)\n",
    "        filenameOut = folder_to_save / f'VigSt_SpCorr_{mice}.pkl'\n",
    "        with open(filenameOut, 'wb') as pickle_file:\n",
    "            pickle.dump(dataSpCorr, pickle_file)\n",
    "            \n",
    "        filenameOut = folder_to_save / f'TotCaCorr_{mice}.pkl'\n",
    "        with open(filenameOut, 'wb') as pickle_file:\n",
    "            pickle.dump(dataCaCorr2, pickle_file)\n",
    "        filenameOut = folder_to_save / f'TotSpCorr_{mice}.pkl'\n",
    "        with open(filenameOut, 'wb') as pickle_file:\n",
    "            pickle.dump(dataSpCorr2, pickle_file)\n",
    "\n",
    "        filenameOut = folder_to_save / f'StatesCaCorr_{mice}.pkl'\n",
    "        with open(filenameOut, 'wb') as pickle_file:\n",
    "            pickle.dump(dataStatesCaCorr, pickle_file)\n",
    "\n",
    "        filenameOut = folder_to_save / f'VigSt_Global_{mice}.pkl'\n",
    "        with open(filenameOut, 'wb') as pickle_file:\n",
    "            pickle.dump(VigilanceState_GlobalResults, pickle_file)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027.3"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_dur /minian_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'session32'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3331669"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(StartTime*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4358969"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(EndTime*1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian311new2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
