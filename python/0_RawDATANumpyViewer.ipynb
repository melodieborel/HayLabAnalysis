{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is just a notebook to visualise 1kHz filtered raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, TimeFreqViewer, InMemoryAnalogSignalSource, EventList\n",
    "from ephyviewer import AnalogSignalSourceWithScatter, SpikeInterfaceRecordingSource, InMemoryEventSource\n",
    "\n",
    "import mbTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose experiment\n",
    "Select the folder of the experiment to display. If the experiment was already analyzed, you can select the iterimAnalysis folder. Otherwise select the raw data recording folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local config file loaded from localConfig.ini\n",
      "current folder \\\\10.69.168.1\\crnldata\\waking\\audrey_hay\\NPX\\interimAnalysis\\NPX1\\Reuniens\\Expe_2024-07-20_12-45-29 contains a config file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec4675cc83848c296f9345f7d9484f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='\\\\10.69.168.1\\crnldata\\waking\\audrey_hay\\NPX\\interimAnalysis\\NPX1\\Reuniens\\Expe_2024-07-20_1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theExpe = mbTools.experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the whole data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping found and loaded\n",
      "{'EMG': [{'canal': '6', 'status': 1}], 'PFC': [{'canal': '21', 'status': 2}, {'canal': '20', 'status': 1}], 'OFC': [{'canal': '19', 'status': 2}, {'canal': '18', 'status': 1}], 'M2': [{'canal': '27', 'status': 2}, {'canal': '26', 'status': 1}], 'M1 -> DOWN States': [{'canal': '16', 'status': 2}, {'canal': '17', 'status': 1}], 'S1fl': [{'canal': '29', 'status': 2}, {'canal': '28', 'status': 1}], 'RSP': [{'canal': '30', 'status': 2}, {'canal': '31', 'status': 1}], 'CA1-1': [{'canal': '1', 'status': 2}, {'canal': '0', 'status': 1}], 'V1': [{'canal': '11', 'status': 2}, {'canal': '10', 'status': 1}], 'CA1-2': [{'canal': '2', 'status': 2}, {'canal': '3', 'status': 1}], 'S1bf': [{'canal': '14', 'status': 2}, {'canal': '15', 'status': 1}], 'mEC': [{'canal': '13', 'status': 2}, {'canal': '12', 'status': 1}]}\n",
      "********found some .bin files********\n",
      "data recorded with Bonsai\n",
      "importing \\\\10.69.168.1\\crnldata\\waking\\audrey_hay\\NPX\\NPX1\\Reuniens\\Expe_2024-07-20_12-45-29\\OE_32ch_data_2024-07-20T12_45_29.bin\n",
      "applying offset\n",
      "converting to int16\n",
      "IntanLFP file loaded, with 32 channels and 106671104 datapoint\n",
      "expeconfig exists so loading it\n",
      "the mapping: {'EMG': [{'canal': '6', 'status': 1}], 'PFC': [{'canal': '21', 'status': 2}, {'canal': '20', 'status': 1}], 'OFC': [{'canal': '19', 'status': 2}, {'canal': '18', 'status': 1}], 'M2': [{'canal': '27', 'status': 2}, {'canal': '26', 'status': 1}], 'M1 -> DOWN States': [{'canal': '16', 'status': 2}, {'canal': '17', 'status': 1}], 'S1fl': [{'canal': '29', 'status': 2}, {'canal': '28', 'status': 1}], 'RSP': [{'canal': '30', 'status': 2}, {'canal': '31', 'status': 1}], 'CA1-1': [{'canal': '1', 'status': 2}, {'canal': '0', 'status': 1}], 'V1': [{'canal': '11', 'status': 2}, {'canal': '10', 'status': 1}], 'CA1-2': [{'canal': '2', 'status': 2}, {'canal': '3', 'status': 1}], 'S1bf': [{'canal': '14', 'status': 2}, {'canal': '15', 'status': 1}], 'mEC': [{'canal': '13', 'status': 2}, {'canal': '12', 'status': 1}]}\n",
      "the offset:  51.44846048\n",
      "the sampling rate:  20046.76684681\n",
      "********found some NPX files********\n",
      "the calculated sampling rate is 30070.243213822876 Hz\n",
      "launch start would be 2024-07-20 12:45:29.896598+02:00\n",
      "the interval to first clock is 0.041224\n",
      "the first timestamp for 10306075 samples, corresponding to 0.041224 s, would be 2024-07-20 12:45:29.937822+02:00\n",
      "there are 161553312 timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manip\\Documents\\MB\\HayLabAnalysis\\.venv\\Lib\\site-packages\\spikeinterface\\core\\baserecording.py:488: UserWarning: Setting times with Recording.set_times() is not recommended because times are not always propagated across preprocessingUse this carefully!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "theExpe.analyseExpe_findData(fullSampling=False)\n",
    "#theExpe.setNumLFPchannels(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract submatrix of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate combined and channelLabels\n",
    "combined =  {}\n",
    "channelLabels = {}\n",
    "sample_rates = {}\n",
    "t_start = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['EMG', 'PFC', 'OFC', 'M2', 'M1 -> DOWN States', 'S1fl', 'RSP', 'CA1-1', 'V1', 'CA1-2', 'S1bf', 'mEC'])\n",
      "EMG -> [{'canal': '6', 'status': 1}]\n",
      "Getting floating signal of channel 6 for EMG\n",
      "PFC -> [{'canal': '21', 'status': 2}, {'canal': '20', 'status': 1}]\n",
      "Getting differential signal of channel 21 - channel 20 for PFC\n",
      "OFC -> [{'canal': '19', 'status': 2}, {'canal': '18', 'status': 1}]\n",
      "Getting differential signal of channel 19 - channel 18 for OFC\n",
      "M2 -> [{'canal': '27', 'status': 2}, {'canal': '26', 'status': 1}]\n",
      "Getting differential signal of channel 27 - channel 26 for M2\n",
      "M1 -> DOWN States -> [{'canal': '16', 'status': 2}, {'canal': '17', 'status': 1}]\n",
      "Getting differential signal of channel 16 - channel 17 for M1 -> DOWN States\n",
      "S1fl -> [{'canal': '29', 'status': 2}, {'canal': '28', 'status': 1}]\n",
      "Getting differential signal of channel 29 - channel 28 for S1fl\n",
      "RSP -> [{'canal': '30', 'status': 2}, {'canal': '31', 'status': 1}]\n",
      "Getting differential signal of channel 30 - channel 31 for RSP\n",
      "CA1-1 -> [{'canal': '1', 'status': 2}, {'canal': '0', 'status': 1}]\n",
      "Getting differential signal of channel 1 - channel 0 for CA1-1\n",
      "V1 -> [{'canal': '11', 'status': 2}, {'canal': '10', 'status': 1}]\n",
      "Getting differential signal of channel 11 - channel 10 for V1\n",
      "CA1-2 -> [{'canal': '2', 'status': 2}, {'canal': '3', 'status': 1}]\n",
      "Getting differential signal of channel 2 - channel 3 for CA1-2\n",
      "S1bf -> [{'canal': '14', 'status': 2}, {'canal': '15', 'status': 1}]\n",
      "Getting differential signal of channel 14 - channel 15 for S1bf\n",
      "mEC -> [{'canal': '13', 'status': 2}, {'canal': '12', 'status': 1}]\n",
      "Getting differential signal of channel 13 - channel 12 for mEC\n",
      "LFP data combined\n"
     ]
    }
   ],
   "source": [
    "#LFP\n",
    "if 'OE_LFP' in theExpe.data:\n",
    "    sample_rates['LFP'] = theExpe.data['OE_LFP'].sampling_rate #20000\n",
    "    t_start['LFP'] = theExpe.data['OE_LFP'].start\n",
    "    combined['LFP'] = theExpe.data['OE_LFP'].combineStructures(\"All\")#['M1'])\n",
    "    channelLabels['LFP'] = theExpe.data['OE_LFP'].channelLabels[:]\n",
    "    print(\"LFP data combined\")\n",
    "else:\n",
    "    print(\"no LFP data to combine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no LFP data to combine\n"
     ]
    }
   ],
   "source": [
    "#LFP\n",
    "if 'LFP_DS' in theExpe.data:\n",
    "    theExpe.data['LFP_DS'].sampling_rate=1000\n",
    "    theExpe.data['LFP_DS'].start=0\n",
    "    print(theExpe.data['LFP_DS'].sampling_rate)\n",
    "\n",
    "    sample_rates['LFP_DS'] = theExpe.data['LFP_DS'].sampling_rate #20000\n",
    "    t_start['LFP_DS'] = theExpe.data['LFP_DS'].start\n",
    "    combined['LFP_DS'] = theExpe.data['LFP_DS'].combineStructures(\"All\")#['M1'])\n",
    "    channelLabels['LFP_DS'] = theExpe.data['LFP_DS'].channelLabels[:]\n",
    "    print(\"LFP data combined\")\n",
    "else:\n",
    "    print(\"no LFP data to combine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPX data combined\n"
     ]
    }
   ],
   "source": [
    "#NPX\n",
    "if 'NPX' in theExpe.data:\n",
    "    sample_rates['NPX'] = theExpe.data['NPX'].sampling_rate #30000\n",
    "    t_start['NPX'] = theExpe.data['NPX'].start\n",
    "    combined['NPX'] = theExpe.data['NPX'].signal['spike']\n",
    "    channelLabels['NPX'] = theExpe.data['NPX'].channelLabels\n",
    "    print(\"NPX data combined\")\n",
    "else:\n",
    "    print(\"no NPX data to combine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Spindles' in theExpe.data:\n",
    "    structure = 'M1'\n",
    "    All_Spindle = theExpe.data['Spindles'][structure]\n",
    "    print(All_Spindle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell can be used to plot very precisely time of interest. Beware that it conflicts with ephyviewer however. It might be possible to have 2 notebooks open simultanéeously...\n",
    "if False:\n",
    "    %matplotlib widget\n",
    "    #you can confiure a y-offset and some scaling, have a look at the help of superCleanPlot\n",
    "    mbTools.superCleanPlot(thedata.data['OE_LFP'], thedata.data['NPX'], structureLFP=['M1'], canauxNPX=[0], time=55) #canauxLFP=16, \n",
    "    picFN = os.path.sep.join([theExpe.rawDataPath,'A1-8978.svg'])\n",
    "    plt.savefig(picFN, format=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/melodieborel/ephyviewer.git\n",
      "  Cloning https://github.com/melodieborel/ephyviewer.git to c:\\users\\manip\\appdata\\local\\temp\\pip-req-build-h8tub6a_\n",
      "  Resolved https://github.com/melodieborel/ephyviewer.git to commit 0ad259517085fefcd0a207b74096606c8fa33ccf\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=2.0 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from ephyviewer==1.7.1.dev0) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from ephyviewer==1.7.1.dev0) (1.26.4)\n",
      "Requirement already satisfied: pyqtgraph>=0.10.0 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from ephyviewer==1.7.1.dev0) (0.13.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from ephyviewer==1.7.1.dev0) (1.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from matplotlib>=2.0->ephyviewer==1.7.1.dev0) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from matplotlib>=2.0->ephyviewer==1.7.1.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from matplotlib>=2.0->ephyviewer==1.7.1.dev0) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from matplotlib>=2.0->ephyviewer==1.7.1.dev0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from matplotlib>=2.0->ephyviewer==1.7.1.dev0) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from matplotlib>=2.0->ephyviewer==1.7.1.dev0) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from matplotlib>=2.0->ephyviewer==1.7.1.dev0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from matplotlib>=2.0->ephyviewer==1.7.1.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\manip\\documents\\mb\\haylabanalysis\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.0->ephyviewer==1.7.1.dev0) (1.16.0)\n",
      "Building wheels for collected packages: ephyviewer\n",
      "  Building wheel for ephyviewer (pyproject.toml): started\n",
      "  Building wheel for ephyviewer (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ephyviewer: filename=ephyviewer-1.7.1.dev0-py3-none-any.whl size=112638 sha256=36385288dcb96ef5f2a53296228b45874d11244b24519611b7ff6c8e915c01bd\n",
      "  Stored in directory: C:\\Users\\manip\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-ds4y5oye\\wheels\\5e\\11\\66\\d3d933455190ef461a89da3e61a4d7bef38be838de4a5e2c79\n",
      "Successfully built ephyviewer\n",
      "Installing collected packages: ephyviewer\n",
      "  Attempting uninstall: ephyviewer\n",
      "    Found existing installation: ephyviewer 1.7.0\n",
      "    Uninstalling ephyviewer-1.7.0:\n",
      "      Successfully uninstalled ephyviewer-1.7.0\n",
      "Successfully installed ephyviewer-1.7.1.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/melodieborel/ephyviewer.git 'C:\\Users\\manip\\AppData\\Local\\Temp\\pip-req-build-h8tub6a_'\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/melodieborel/ephyviewer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug True\n",
      "QT_MODE PySide6\n",
      "auto_scale same_for_all\n",
      "compute_auto_clim\n",
      "[ True False False False False False False False False False False False]\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.001001119613647461 s\n",
      "viewer has moved already 0 51.44846048 0.0\n",
      "viewer has moved already 0 51.44846048 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_scale same_for_all\n",
      "compute_auto_clim\n",
      "[ True False False False False False False False False False False False]\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0019989013671875 s\n",
      "refresh duration for LFP 0.0010020732879638672 s\n",
      "refresh duration for tfr 0.0009984970092773438 s\n",
      "refresh duration for LFP 0.0010008811950683594 s\n",
      "refresh duration for tfr 0.0009992122650146484 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0010318756103515625 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0009620189666748047 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0009987354278564453 s\n",
      "viewer has moved already 0 987.9533890977483 854.9271208281818\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.00099945068359375 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0019991397857666016 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.002001523971557617 s\n",
      "refresh duration for LFP 0.0010001659393310547 s\n",
      "refresh duration for tfr 0.0010001659393310547 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0009605884552001953 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0010001659393310547 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0020003318786621094 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0010020732879638672 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0010006427764892578 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0029973983764648438 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0009984970092773438 s\n",
      "refresh duration for LFP 0.0 s\n",
      "viewer has moved already 0 2030.87933233115 1913.8162162539313\n",
      "refresh duration for tfr 0.0019998550415039062 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0010004043579101562 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0010001659393310547 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.001001596450805664 s\n",
      "refresh duration for LFP 0.0 s\n",
      "refresh duration for tfr 0.0 s\n",
      "refresh duration for LFP 0.0010027885437011719 s\n",
      "refresh duration for tfr 0.0010004043579101562 s\n",
      "auto_scale same_for_all\n",
      "compute_auto_clim\n",
      "[ True False False False False False False False False False False False]\n",
      "save_all_settings\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%gui qt\n",
    "app = mkQApp()\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True)\n",
    "\n",
    "if 'LFP' in combined:\n",
    "    source = InMemoryAnalogSignalSource(combined['LFP'], np.round(sample_rates['LFP']), t_start['LFP'], channel_names=channelLabels['LFP'])\n",
    "    view1 = TraceViewer(source=source, name = 'LFP')\n",
    "\n",
    "    #Parameters can be set in script\n",
    "    view1.params['display_labels'] = True\n",
    "    view1.params['scale_mode'] = 'same_for_all'\n",
    "    view1.auto_scale()\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"hsv\"]#Wistia\"]\n",
    "    nCh = len(view1.by_channel_params.children())\n",
    "    for ch in range(nCh):\n",
    "        #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.00002\n",
    "        #view1.by_channel_params[f'ch{ch}', 'offset'] = 0.1\n",
    "        view1.by_channel_params[f'ch{ch}', 'color'] = matplotlib.colors.to_hex(cmap(ch/nCh), keep_alpha=False)\n",
    "        pass\n",
    "\n",
    "    #create a time freq viewer conencted to the same source\n",
    "    view2 = TimeFreqViewer(source=source, name='tfr')\n",
    "    view2.params['show_axis'] = False\n",
    "    view2.params['timefreq', 'deltafreq'] = 1\n",
    "    #view2.by_channel_params['ch3', 'visible'] = False\n",
    "    view2.auto_scale()\n",
    "\n",
    "    win.add_view(view1)\n",
    "    win.add_view(view2)\n",
    "\n",
    "if 'LFP_DS' in combined:\n",
    "\n",
    "    if All_Spindle is not None:\n",
    "        #Create one data source with 3 event channel\n",
    "        all_events = []\n",
    "        conditions = ['All','Good','Bad']\n",
    "        for c,cond in enumerate(conditions):\n",
    "            match cond:\n",
    "                case 'All':\n",
    "                    selection = \"All_Spindle['toKeep'] | ~All_Spindle['toKeep']\"\n",
    "                case 'Good':\n",
    "                    selection = \"All_Spindle['toKeep']\"\n",
    "                case 'Bad':\n",
    "                    selection = \"~All_Spindle['toKeep']\"\n",
    "            ev_times = mbTools.convertTheoricIndex2realTime(All_Spindle.loc[pd.eval(selection),'peak time'].values, realFreq=sample_rates['LFP_DS'], offset=t_start['LFP_DS'])\n",
    "            ev_labels = [f'spindle {i}'for i in All_Spindle[pd.eval(selection)].index]\n",
    "            all_events.append({ 'time':ev_times, 'label':ev_labels, 'name': conditions[c] })\n",
    "        source_ev = InMemoryEventSource(all_events=all_events)\n",
    "\n",
    "        Spindle_peak = All_Spindle['peak time'].astype(int)\n",
    "        Spindle_start = All_Spindle['start time'].astype(int)\n",
    "        Spindle_end = All_Spindle['end time'].astype(int)\n",
    "\n",
    "        #create 2 familly scatters from theses 2 indexes\n",
    "        scatter_indexes = {0: Spindle_peak, 1: Spindle_start, 2: Spindle_end}\n",
    "        #and asign them to some channels each\n",
    "        scatter_channels = {0: [0], 1: [0], 2: [0]}\n",
    "        source = AnalogSignalSourceWithScatter(combined['LFP_DS'], sample_rates['LFP_DS'], t_start['LFP_DS'], scatter_indexes, scatter_channels, channel_names=channelLabels['LFP_DS'])\n",
    "        view_Events = EventList(source=source_ev, name='event')\n",
    "        \n",
    "    else:\n",
    "        source = InMemoryAnalogSignalSource(combined['LFP_DS'], sample_rates['LFP_DS'], t_start['LFP_DS'], channel_names=channelLabels['LFP_DS'])\n",
    "        view_Events = None\n",
    "    view_DS = TraceViewer(source=source, name = 'LFP_DS')\n",
    "\n",
    "    #Parameters can be set in script\n",
    "    view_DS.params['display_labels'] = True\n",
    "    view_DS.params['scale_mode'] = 'same_for_all'\n",
    "    view_DS.auto_scale()\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"hsv\"]#Wistia\"]\n",
    "    nCh = len(view_DS.by_channel_params.children())\n",
    "    for ch in range(nCh):\n",
    "        #view_DS.by_channel_params[f'ch{ch}', 'gain'] = 0.00002\n",
    "        #view_DS.by_channel_params[f'ch{ch}', 'offset'] = 0.1\n",
    "        view_DS.by_channel_params[f'ch{ch}', 'color'] = matplotlib.colors.to_hex(cmap(ch/nCh), keep_alpha=False)\n",
    "        pass\n",
    "\n",
    "    #create a time freq viewer conencted to the same source\n",
    "    viewTFR_DS = TimeFreqViewer(source=source, name='tfr')\n",
    "    viewTFR_DS.params['show_axis'] = False\n",
    "    viewTFR_DS.params['timefreq', 'deltafreq'] = 1\n",
    "    #viewTFR_DS.by_channel_params['ch3', 'visible'] = False\n",
    "    viewTFR_DS.auto_scale()\n",
    "\n",
    "    win.add_view(view_DS)\n",
    "    win.add_view(viewTFR_DS)\n",
    "\n",
    "    \n",
    "else:\n",
    "    view_Events=None\n",
    "\n",
    "\n",
    "if 'NPX' in combined:\n",
    "    sig_source = SpikeInterfaceRecordingSource(recording=combined['NPX'], high_precision=False)\n",
    "    view3 = TraceViewer(source=sig_source, name='NPX')\n",
    "    win.add_view(view3)\n",
    "\n",
    "    #Parameters can be set in script\n",
    "    view3.params['display_labels'] = True\n",
    "    view3.params['scale_mode'] = 'same_for_all'\n",
    "    view3.auto_scale()\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"hsv\"]#Wistia\"]\n",
    "    nCh = len(view3.by_channel_params.children())\n",
    "    for ch in range(nCh):\n",
    "        #view3.by_channel_params[f'ch{ch}', 'gain'] = 0.00002\n",
    "        #view3.by_channel_params[f'ch{ch}', 'offset'] = 0.1\n",
    "        view3.by_channel_params[f'ch{ch}', 'color'] = matplotlib.colors.to_hex(cmap(ch/nCh), keep_alpha=False)\n",
    "        pass\n",
    "\n",
    "if view_Events is not None:\n",
    "    win.add_view(view_Events)\n",
    "\n",
    "\n",
    "#Run\n",
    "win.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
