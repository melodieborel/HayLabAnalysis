{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Associate Ca2+ signal with sleep stages for each session & subsessions using crossregistration\n",
    "\n",
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"C:/Users/Manip2/SCRIPTS/Code python audrey/code python aurelie/interfaceJupyter/minian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "%matplotlib widget\n",
    "\n",
    "from itertools import groupby\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "# add the Contrib dir that contains all tools developped by MB : mbTools.py\n",
    "#sys.path.append(os.path.join(os.path.dirname(sys.path[0]),'python'))\n",
    "#print(os.path.join(os.path.dirname(sys.path[0]),'python'))\n",
    "import HayLabAnalysis as hla\n",
    "\n",
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sleep score and Ca2+ time series numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording\"\n",
    "try:\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"data not in strore\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "    dpath =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording\"\n",
    "\n",
    "# Set up Initial Basic Parameters#\n",
    "minian_path = \".\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Folder with videos</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_base = Path(dpath)\n",
    "\n",
    "nb_sessions = sum(1 for p in folder_base.iterdir() if p.is_dir() and p.name.startswith(\"session\"))\n",
    "try:\n",
    "    mfile = open(folder_base / f'mappingsAB.pkl', 'rb')\n",
    "    mapping = pickle.load(mfile)\n",
    "except:\n",
    "    mfile = open(folder_base / f'mappings.pkl', 'rb')\n",
    "    mapping = pickle.load(mfile)\n",
    "\n",
    "sessions = []\n",
    "subsessions = []\n",
    "nb_minian_total=0\n",
    "dict_Calcium = {}\n",
    "dict_Spike = {}\n",
    "dict_Scoring = {}\n",
    "dict_Stamps = {}\n",
    "dict_TodropFile = {}\n",
    "\n",
    "for y in range(1, nb_sessions+1):\n",
    "    session= 'session' + str(y)\n",
    "    print(session)\n",
    "    sessions.append(session)\n",
    "    folder_mini = folder_base / f'session{y}/V4_Miniscope'\n",
    "    nb_subsessions = sum(1 for p in folder_mini.iterdir() if p.is_dir() and p.name.startswith(\"session\"))\n",
    "    ScoringFile = folder_base / f'session{y}/OpenEphys/ScoredSleep.npy'\n",
    "    StampsFile = folder_base / f'session{y}/SynchroFile.xlsx'\n",
    "\n",
    "    if nb_subsessions!=0:\n",
    "        for x in range(1, nb_subsessions+1):            \n",
    "            subsession= \"session\"  + str(y) + str(x)\n",
    "            subsessions.append(subsession)    \n",
    "            minian_ds = open_minian(folder_mini / subsession / f'minian')      # OR minianAB\n",
    "            dict_Calcium[subsession] = minian_ds['C'] # calcium traces \n",
    "            dict_Spike[subsession] = minian_ds['S'] # estimated spikes\n",
    "            dict_Scoring[subsession]  = np.load(ScoringFile)\n",
    "            dict_Stamps[subsession]  = pd.read_excel(StampsFile)\n",
    "            try:\n",
    "                TodropFile = folder_mini / subsession / f'minian/TodropFileAB.json'\n",
    "                with open(TodropFile, 'r') as f:\n",
    "                    unit_to_drop = json.load(f)\n",
    "                    dict_TodropFile[subsession]  = unit_to_drop\n",
    "            except:\n",
    "                TodropFile = folder_mini / subsession / f'minian/TodropFile.json'\n",
    "                with open(TodropFile, 'r') as f:\n",
    "                    unit_to_drop = json.load(f)\n",
    "                    dict_TodropFile[subsession]  = unit_to_drop\n",
    "            nb_minian_total+=1\n",
    "            print(nb_minian_total)\n",
    "    else:\n",
    "        minian_ds = open_minian(folder_mini / f'minian')            # OR minianAB\n",
    "        dict_Calcium[session] = minian_ds['C'] # calcium traces \n",
    "        dict_Spike[session] = minian_ds['S'] # estimated spikes\n",
    "        dict_Scoring[session]  = np.load(ScoringFile) \n",
    "        dict_Stamps[session]  = pd.read_excel(StampsFile)\n",
    "        try:\n",
    "            TodropFile = folder_mini / f'minian/TodropFileAB.json'\n",
    "            with open(TodropFile, 'r') as f:\n",
    "                unit_to_drop = json.load(f)\n",
    "                dict_TodropFile[session]  = unit_to_drop\n",
    "        except:\n",
    "            TodropFile = folder_mini / f'minian/TodropFile.json'\n",
    "            with open(TodropFile, 'r') as f:\n",
    "                unit_to_drop = json.load(f)\n",
    "                dict_TodropFile[session]  = unit_to_drop\n",
    "        nb_minian_total+=1  \n",
    "        print(nb_minian_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross registration results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = mapping['session']\n",
    "for c in range(len(B)):\n",
    "    print('unit nÂ°', c)\n",
    "    for sess in B.keys(): #list(dict_Stamps.keys()):\n",
    "        print('= unit', int(B[sess][c]), 'in', sess) if math.isnan (float(B[sess][c])) == False else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribute Ca2+ intensity & spikes to vigilance state for each sessions/subsessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "counter=0\n",
    "VigilanceState_GlobalResults= pd.DataFrame(data, columns=['Mice','Session', 'Session_Time', 'Unique_Unit','UnitNumber','UnitValue', 'Substate','SubstateNumber','DurationSubstate', 'CalciumActivity', 'AUC_calcium', 'Avg_CalciumActivity','Avg_AUC_calcium','SpikeActivity', 'AUC_spike','Avg_SpikeActivity','Avg_AUC_spike'])\n",
    "\n",
    "for i in list(dict_Stamps.keys()):\n",
    "\n",
    "    # Start time & freq miniscope\n",
    "    StartTime = list(dict_Stamps[i][0])[0]\n",
    "    minian_freq=list(dict_Stamps[i][0])[2]\n",
    "\n",
    "    First_frame = StartTime*minian_freq\n",
    "    C=dict_Calcium[i]\n",
    "    Cupd = C.loc[:, :] #C.loc[:, First_frame:]\n",
    "    nb_unit = Cupd.shape[0]\n",
    "    rec_dur = Cupd.shape[1]\n",
    "    S=dict_Spike[i] \n",
    "    Supd = S.loc[:, :] #S.loc[:, First_frame:]\n",
    "\n",
    "    # Upscale scoring to miniscope frequency\n",
    "    scale_factor=minian_freq/0.2  #cause scoring was done in 5 seconds bin, ie 0.2 Hz\n",
    "    SleepScoredTS=dict_Scoring[i]\n",
    "    SleepScoredTS_upscaled = np.repeat(SleepScoredTS, scale_factor, axis=0)\n",
    "    StartTime_frame=int(StartTime*minian_freq)\n",
    "    SleepScoredTS_upscaled_ministart=SleepScoredTS_upscaled[int(StartTime_frame):int(StartTime_frame)+rec_dur]\n",
    "\n",
    "    # Identify start time and upscale scoring to miniscope acquisition frequency\n",
    "    unit_to_drop=dict_TodropFile[i]\n",
    "    D = C['unit_id']\n",
    "    copyD = list(D.copy())\n",
    "    for r in range(len(unit_to_drop)):\n",
    "        elem = unit_to_drop[r]\n",
    "        copyD.remove(elem)\n",
    "    unit_to_keep = copyD\n",
    "\n",
    "    C_upd = Cupd.loc[unit_to_keep,:]\n",
    "    S_upd = Supd.loc[unit_to_keep,:]\n",
    "    nb_unit = C_upd.shape[0]\n",
    "    print(len(C_upd.unit_id), 'selected units in', i)\n",
    "\n",
    "        \n",
    "    # Determine each substate identity and duration\n",
    "    array=SleepScoredTS_upscaled_ministart\n",
    "    substates_duration = [len(list(group)) for key, group in groupby(array)]\n",
    "    substates_identity = [key for key, _ in groupby(array)]\n",
    "    substates_end = np.array(substates_duration).cumsum()\n",
    "    substates_start =np.append([1],substates_end+1)\n",
    "    mapp = {0: 'NREM', 0.5: 'N2', 1: 'REM', 1.5: 'Wake'}\n",
    "    substates_identity = [mapp[num] for num in substates_identity]\n",
    "    substates = pd.DataFrame(list(zip(substates_identity, substates_duration, substates_start, substates_end)), columns=['Identity', 'Duration', 'Start','End'])\n",
    "\n",
    "    C_upd_unit_id = C_upd['unit_id'].values #added by AB\n",
    "    calciumtraces_all = C_upd.to_series()\n",
    "    spikestraces_all = S_upd.to_series()\n",
    "\n",
    "    for unit in range(nb_unit): # nb_unit):\n",
    "        ca_input = np.array(calciumtraces_all)[(unit)*rec_dur:(unit+1)*rec_dur]\n",
    "        sp_input = np.array(spikestraces_all)[(unit)*rec_dur:(unit+1)*rec_dur]\n",
    "        for index in range(len(substates)):\n",
    "            ca_input_sub=ca_input[substates.Start[index]:substates.End[index]]\n",
    "            sp_input_sub=sp_input[substates.Start[index]:substates.End[index]]\n",
    "            VigilanceState_GlobalResults.loc[counter, 'Mice'] = os.path.basename(folder_base)\n",
    "            VigilanceState_GlobalResults.loc[counter, 'Session'] = i \n",
    "            VigilanceState_GlobalResults.loc[counter, 'Session_Time'] = None \n",
    "            \n",
    "            keys_list = list(dict_Stamps.keys())\n",
    "            key_to_find = i\n",
    "            position = keys_list.index(key_to_find)\n",
    "            keys_list2 = list(B.keys())\n",
    "            key_at_position = keys_list2[position]\n",
    "            indexMapp = np.where(B[key_at_position] == C_upd_unit_id[unit])[0]\n",
    "\n",
    "            VigilanceState_GlobalResults.loc[counter, 'Unique_Unit'] = indexMapp\n",
    "            VigilanceState_GlobalResults.loc[counter, 'UnitNumber'] = unit\n",
    "            VigilanceState_GlobalResults.loc[counter, 'UnitValue'] = C_upd_unit_id[unit]\n",
    "            VigilanceState_GlobalResults.loc[counter, 'Substate'] = substates.Identity[index]\n",
    "            VigilanceState_GlobalResults.loc[counter, 'SubstateNumber'] = substates.index[index]\n",
    "            VigilanceState_GlobalResults.loc[counter, 'DurationSubstate'] = substates.Duration[index]\n",
    "            VigilanceState_GlobalResults.loc[counter, 'CalciumActivity'] = ca_input_sub.mean()\n",
    "            VigilanceState_GlobalResults.loc[counter, 'AUC_calcium'] = np.trapz(ca_input_sub,np.arange(0,len(ca_input_sub),1))\n",
    "            VigilanceState_GlobalResults.loc[counter, 'Avg_CalciumActivity'] = ca_input.mean()\n",
    "            VigilanceState_GlobalResults.loc[counter, 'Avg_AUC_calcium'] = np.trapz(ca_input,np.arange(0,len(ca_input),1))\n",
    "            VigilanceState_GlobalResults.loc[counter, 'SpikeActivity'] = sp_input_sub.mean()\n",
    "            VigilanceState_GlobalResults.loc[counter, 'AUC_spike'] = np.trapz(sp_input_sub,np.arange(0,len(sp_input_sub),1))\n",
    "            VigilanceState_GlobalResults.loc[counter, 'Avg_SpikeActivity'] = sp_input.mean()\n",
    "            VigilanceState_GlobalResults.loc[counter, 'Avg_AUC_spike'] = np.trapz(sp_input,np.arange(0,len(sp_input),1))\n",
    "            counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VigilanceState_GlobalResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice=os.path.basename(folder_base) \n",
    "filenameOut = folder_base / f'VigilanceState_GlobalResultsAB_{mice}.xlsx'\n",
    "writer = pd.ExcelWriter(filenameOut)\n",
    "VigilanceState_GlobalResults.to_excel(writer)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('minian')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d28f0aa69d972f186b6eef62f149b885b857325c1e4e259a67006c9c0c737cc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
