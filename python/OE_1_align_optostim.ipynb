{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate evoked LFP response by optogenetic stimulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from scipy.stats import zscore\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "import IPython\n",
    "import ast\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load LFP coordinates \n",
    "notebook_path = Path(\"/\".join(IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[-5:]))\n",
    "Channels = f'{notebook_path.parent}/_LFP_coordinates_of_all_mice.csv'\n",
    "all_LFPcoordinates = pd.read_csv(Channels, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose OpenEphys folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dpath either from a previous run or from a previous notebook\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    dpath = \"//10.69.168.1/crnldata/forgetting/\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Go inside the folder containing the LFP raw file</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load LFPs data, TTL, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_base = Path(dpath) \n",
    "miceIDflipped=[]\n",
    "\n",
    "if Path(f'{folder_base}\\DataFrame_rawdataDS.pkl').exists(): # prefer loading downsample file over original file\n",
    "    print('DataFrame_rawdataDS.pkl file')\n",
    "    LFPfile = Path(f'{folder_base}\\DataFrame_rawdataDS.pkl')\n",
    "    LFPs_df = pd.read_pickle(LFPfile)\n",
    "    samplerate = 1000 \n",
    "    numchannel = LFPs_df.shape[1]\n",
    "    rec_ch_list = LFPs_df.columns.values\n",
    "    # Load LFPs timestamps \n",
    "    for file_pathTS in folder_base.parent.parent.glob('**/continuous/*/timeStampsDS.npy'):\n",
    "        print('LFPs timestamps file found')\n",
    "        LFPtimestamps = np.load(file_pathTS)  \n",
    "elif Path(f'{folder_base}\\continuous.dat').exists():\n",
    "    print('continuous.dat file')\n",
    "    LFPfile = Path(f'{folder_base}\\continuous.dat')\n",
    "    DataRec = np.fromfile(LFPfile, dtype=\"int16\")\n",
    "    filepath = Path(os.path.join(folder_base.parent.parent, f'structure.oebin'))\n",
    "    with open(filepath) as f:\n",
    "        metadata = json.load(f)\n",
    "    samplerate = metadata['continuous'][0]['sample_rate']  \n",
    "    numchannel = metadata['continuous'][0]['num_channels'] \n",
    "    rec_ch_list = np.array([int(''.join(c for c in metadata['continuous'][0]['channels'][x]['channel_name'] if c.isdigit()))-1 for x in range(0, len(metadata['continuous'][0]['channels']))])\n",
    "    DataRec = DataRec.reshape(-1,numchannel)\n",
    "    print('Metadata found')\n",
    "    # Load LFPs timestamps \n",
    "    for file_pathTS in folder_base.parent.parent.glob('**/continuous/*/timeStamps.npy'):\n",
    "        print('LFPs timestamps file found')\n",
    "        LFPtimestamps = np.load(file_pathTS) \n",
    "    LFPs_df=pd.DataFrame(DataRec, columns=rec_ch_list) \n",
    "else: \n",
    "    print('no LFPs file found')\n",
    "\n",
    "print('sample rate =', samplerate, 'Hz')\n",
    "print(numchannel, 'channels recorded')\n",
    "print(round(LFPs_df.shape[0]/samplerate/60), 'min of recording')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_decimal=3 # 4 = 0.1ms precision / 3 = 1ms precision\n",
    "\n",
    "# Load TTLs\n",
    "TTL_Opto_duration=[]\n",
    "for file_pathTTL in folder_base.parent.parent.glob('**/TTL/timeStamps.npy'):\n",
    "    print('TTL opto file = ', file_pathTTL)\n",
    "    TTL_Opto_o = np.load(file_pathTTL)\n",
    "    TTL_Opto_duration =[round(TTL_Opto_o[i+1] - TTL_Opto_o[i],nb_decimal) for i in range(len(TTL_Opto_o) - 1)[::2]]\n",
    "    TTL_Opto= TTL_Opto_o[::2] # remove the TTL for laser OFF, only keep TTL for laser ON. CAUTION /!/ works only if it started with a TTL for laser ON\n",
    "    print(TTL_Opto.shape[0], 'opto stimulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample LFP data to 1kHz if needed & save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if samplerate > 1000:\n",
    "    new_sampling_rate = 1000 # Hz\n",
    "    Nmber_points = int(np.shape(LFPs_df)[0] * new_sampling_rate / samplerate)\n",
    "    LFPs_df_DS = pd.DataFrame(signal.resample(LFPs_df, Nmber_points, axis = 0), columns=LFPs_df.columns.values)\n",
    "    LFPtimestampsDS = LFPtimestamps[::int(samplerate/new_sampling_rate)][:-1]\n",
    "    samplerate = new_sampling_rate\n",
    "    LFPs_df_DS.to_pickle(f'{LFPfile.parent}/DataFrame_rawdataDS.pkl')\n",
    "    np.save(f'{file_pathTS.parent}/timeStampsDS.npy', LFPtimestampsDS)\n",
    "    LFPs_df = LFPs_df_DS\n",
    "    LFPtimestamps = LFPtimestampsDS\n",
    "# eventually delete original files to gain space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify LFP electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = []\n",
    "pos_mice = []\n",
    "for mouse_name in all_LFPcoordinates.index:\n",
    "    if mouse_name in LFPfile.__str__():\n",
    "        mouse.append(mouse_name)\n",
    "        pos_mice.append(LFPfile.__str__().find(mouse_name)) \n",
    "mouse = [x for _, x in sorted(zip(pos_mice, mouse))] # sort mouse in the same order as they appear in the path\n",
    "\n",
    "if len(mouse) > 1: # found multiple mouse name in the path\n",
    "    if max(rec_ch_list) <= 31: # no channels superior to 32, so only one mouse recorded\n",
    "        id = 0 # change to 0 to see the first mouse name found, 1 the second, etc\n",
    "        ID = 0\n",
    "        print(f\"/!\\ Mutliple mice name found in the path but only mouse recorded = {mouse}. The n°{id+1} was choosen automatically = {mouse[id]}.\")\n",
    "        mouse = mouse[id]\n",
    "    else:\n",
    "        ###################################################################################################################################\n",
    "        ID = 2 # choose 0 to see the first mouse recorded, 1 the second, 2 the third, 3 the fourth (only 4 mice can be recorded at the same time)\n",
    "        ###################################################################################################################################\n",
    "        print(f\"/!\\ Mutliple mice recorded at the same time = {mouse}. The n°{ID+1} was choosen automatically = {mouse[ID]}.\")\n",
    "        mouse = mouse[ID] \n",
    "elif len(mouse) == 1: # found only one mouse name in the path\n",
    "    ID = 0\n",
    "    mouse = mouse[ID]\n",
    "    \n",
    "all_LFPcoordinates= all_LFPcoordinates.astype(str)\n",
    "for region in all_LFPcoordinates.loc[mouse].index:\n",
    "    locals()[f'{region}_0']=[]\n",
    "    locals()[f'{region}_1']=[]\n",
    "    locals()[f'{region}_0ch']=[]\n",
    "    locals()[f'{region}_1ch']=[]\n",
    "\n",
    "RecordedArea = []\n",
    "ChoosenChannels = []\n",
    "combined = []\n",
    "if mouse:\n",
    "    rec_ch_list_mouse = [value for value in rec_ch_list if 0+(ID*32) <= value <= 31+(ID*32)]\n",
    "    for rec_ch in rec_ch_list_mouse:\n",
    "        for idx, LFPcoord_str in enumerate(all_LFPcoordinates.loc[mouse]):\n",
    "            region = all_LFPcoordinates.loc[mouse].index[idx]\n",
    "            if LFPcoord_str != 'nan' and region != 'EMG':\n",
    "                LFPcoord = LFPcoord_str.split('_')[:2] # only take into account the 2 first of electrode of that region \n",
    "                num_ch = np.where(str(rec_ch-(ID*32)) == np.array(LFPcoord))[0]\n",
    "                if len(num_ch)>0:\n",
    "                    region=all_LFPcoordinates.loc[mouse].index[idx]\n",
    "                    LFP=locals()[f'{region}_0']\n",
    "                    if len(LFP)>0:\n",
    "                        LFP= np.array(LFPs_df[(rec_ch)])\n",
    "                        locals()[f'{region}_1']=LFP\n",
    "                        locals()[f'{region}_1ch']=rec_ch\n",
    "                    else:\n",
    "                        LFP= np.array(LFPs_df[(rec_ch)])\n",
    "                        locals()[f'{region}_0']=LFP\n",
    "                        locals()[f'{region}_0ch']=rec_ch\n",
    "                    break\n",
    "                continue\n",
    "    \n",
    "    for region in all_LFPcoordinates.loc[mouse].index:\n",
    "        for n in range(0,2,1):\n",
    "            LFP=locals()[f'{region}_{n}']\n",
    "            LFP_ch=locals()[f'{region}_{n}ch']\n",
    "            if len(LFP)>0:\n",
    "                combined=zscore(LFP[:,np.newaxis]) if len(combined)==0 else np.append(combined, zscore(LFP[:,np.newaxis]), axis=1)\n",
    "                RecordedArea.append(f'{region}_{n}') \n",
    "                ChoosenChannels.append(LFP_ch) \n",
    "else:\n",
    "    print(\"/!\\ No mouse name found in the path OR in the csv file '_LFP_coordinates_of_all_mice.csv'\")\n",
    "    mouse = '' # fill mouse name\n",
    "    RecordedArea = ['PFC','S1'] \n",
    "    PFC_0 = LFPs_df[0]\n",
    "    S1_1 = LFPs_df[1]\n",
    "    combined = np.stack([zscore(PFC_0), zscore(S1_1)], axis=1)\n",
    "\n",
    "print(mouse)\n",
    "print(RecordedArea)\n",
    "print(ChoosenChannels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check TTL durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.stairs(np.array(TTL_Opto_duration)*1000)\n",
    "plt.xlabel('# Opto stimulations')\n",
    "plt.ylabel('Opto stimulation durations (ms)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get response of each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllEPSPs=[]\n",
    "for ttl in TTL_Opto:   \n",
    "    idx = (np.abs(LFPtimestamps - ttl)).argmin() # find the closest LFP timestamps to the TTL\n",
    "    AllEPSPs.append(combined[idx-round(0.5*samplerate):idx+round(0.5*samplerate), :]) #500 ms before and after TTL\n",
    "\n",
    "plt.close()\n",
    "plt.figure(figsize=(6, 3))\n",
    "time_axis = np.linspace(-500, 500, np.shape(AllEPSPs)[1]) \n",
    "mEPSPs=np.mean(AllEPSPs, axis=0)\n",
    "colors = cm.rainbow(np.linspace(0, 1, np.shape(mEPSPs)[1]))\n",
    "for i in np.arange(0,np.shape(AllEPSPs)[2]):\n",
    "    plt.plot(time_axis, mEPSPs[:,i], label=f'{RecordedArea[i]}', color=colors[i])\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Averaged EPSPs\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncols=1)\n",
    "plt.subplots_adjust(right=.5)\n",
    "plt.xlim([-25, 50])\n",
    "plt.title(f'Mouse = {mouse}, Stim opto duration = {np.unique(TTL_Opto_duration)[0]*1000} - {np.round(np.unique(TTL_Opto_duration)[-1]*1000,2)} ms \\nfilename = {folder_base.parts[-6]}', fontsize=12) # Change to indicate where is located that LFP\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get response for one brain region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_region='oPFC_0' # to change\n",
    "SelectedLFP=locals()[Selected_region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_differentStim=len(np.unique(TTL_Opto_duration)) # how many different opto stim are performed in the arduino protocol (here a loop of 19 stim with different durations)\n",
    "DurStim=np.unique(TTL_Opto_duration)*1000 # durations of each unique stim (from 1 ms to 20 ms with a step of 1)\n",
    "\n",
    "halfdurEPSP=0.1 #sec\n",
    "analyseWindow= 0.025 #sec post stim\n",
    "\n",
    "AllStim={}\n",
    "for i, ttl  in enumerate(TTL_Opto):\n",
    "    idx = (np.abs(LFPtimestamps - ttl)).argmin() # find the closest LFP timestamps to the TTL    \n",
    "    if str(TTL_Opto_duration[i]*1000) in AllStim:\n",
    "        AllStim[str(TTL_Opto_duration[i]*1000) ]=pd.concat([AllStim[str(TTL_Opto_duration[i]*1000) ],pd.DataFrame(SelectedLFP[idx-round(halfdurEPSP*samplerate):idx+round(halfdurEPSP*samplerate)])],axis=1)\n",
    "    else:\n",
    "        AllStim[str(TTL_Opto_duration[i]*1000) ]=pd.DataFrame(SelectedLFP[idx-round(halfdurEPSP*samplerate):idx+round(halfdurEPSP*samplerate)])\n",
    "   \n",
    "AllStim_sorted = dict(sorted(AllStim.items()))\n",
    "meanAllStim= pd.DataFrame([np.mean(AllStim_sorted[key], axis=1) for key in AllStim_sorted.keys()]).T\n",
    "meanAllStim= pd.DataFrame([meanAllStim[key]-np.mean(meanAllStim[key][int((halfdurEPSP*samplerate)-(halfdurEPSP*samplerate)):int(halfdurEPSP*samplerate)]) for key in meanAllStim.columns]).T\n",
    "meanAllStim.columns=DurStim #convert columns names in ms\n",
    "\n",
    "\"\"\"                         \n",
    "Amplitude=[]\n",
    "Max=[]\n",
    "HalfMaxWidth=[]\n",
    "for i in meanAllStim.columns:\n",
    "    y=meanAllStim[i][round(halfdurEPSP*samplerate):round((halfdurEPSP+analyseWindow)*samplerate)]\n",
    "    peaks, properties = signal.find_peaks(y, height=min(y), prominence=0)\n",
    "    if len(peaks) > 0:\n",
    "        widths, width_heights, left_ips, right_ips = signal.peak_widths(y, peaks, rel_height=0.5)\n",
    "        biggest_peak_idx = np.argmax(properties[\"peak_heights\"])\n",
    "        biggest_peak = peaks[biggest_peak_idx]\n",
    "        half_width = widths[biggest_peak_idx] / 2\n",
    "        Amplitude.append(properties[\"prominences\"][biggest_peak_idx])\n",
    "        Max.append(properties[\"peak_heights\"][biggest_peak_idx])\n",
    "        HalfMaxWidth.append(half_width)\n",
    "    else:\n",
    "        Amplitude.append(np.nan)\n",
    "        Max.append(np.nan)\n",
    "        HalfMaxWidth.append(np.nan)\n",
    "\"\"\"\n",
    "Amplitude=meanAllStim[round(halfdurEPSP*samplerate):round((halfdurEPSP+analyseWindow)*samplerate)].max()-meanAllStim[round(halfdurEPSP*samplerate):round((halfdurEPSP+analyseWindow)*samplerate)].min()\n",
    "Max=meanAllStim[round(halfdurEPSP*samplerate):round((halfdurEPSP+analyseWindow)*samplerate)].max()\n",
    "HalfMaxWidth = [((np.abs(meanAllStim[i][meanAllStim[i][meanAllStim[i]==Max[i]].index[0]:] - Max[i]/2)).argmin() -round(halfdurEPSP*samplerate) + meanAllStim[i][meanAllStim[i]==Max[i]].index[0])/samplerate*1000 for i in meanAllStim.columns]\n",
    "\n",
    "# Plot\n",
    "plt.close()\n",
    "fig, axs = plt.subplots(2,2, figsize=(12,6))\n",
    "fig.suptitle(f'Mouse = {mouse}, LFP = {Selected_region} \\nfilename = {folder_base.parts[-6]}', fontsize=12) # Change to indicate where is located that LFP\n",
    "\n",
    "time_axis = np.linspace(-halfdurEPSP*1000, halfdurEPSP*1000, meanAllStim.shape[0]) \n",
    "grey_shades = np.linspace(0.9, 0.1, len(meanAllStim.columns)) \n",
    "for i, col in enumerate(meanAllStim.columns):\n",
    "    axs[0,0].plot(time_axis, meanAllStim[col], color=(grey_shades[i], grey_shades[i], grey_shades[i]), label=f'{round(col,4)} ms')\n",
    "axs[0,0].plot(time_axis, np.mean(meanAllStim, axis= 1), color='red')\n",
    "axs[0,0].set(xlabel=\"Time (ms)\", ylabel=\"Averaged EPSPs\")\n",
    "#axs[0,0].set(ylim=(-750, 1000))\n",
    "axs[0,0].set(xlim=(-25, 50))\n",
    "\n",
    "axs[0,1].plot(DurStim,Amplitude, 'k')\n",
    "axs[0,1].set(xlabel=\"Opto stim duration (ms)\", ylabel=\"Amplitude \")\n",
    "\n",
    "axs[1,0].plot(DurStim,Max, 'k')\n",
    "axs[1,0].set(xlabel=\"Opto stim duration (ms)\", ylabel=\"Maximum \")\n",
    "\n",
    "axs[1,1].plot(DurStim, HalfMaxWidth, 'k')\n",
    "axs[1,1].set(xlabel=\"Opto stim duration (ms)\", ylabel=\"HalfWidth (ms)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "axs[0,0].legend(loc='upper center', bbox_to_anchor=(2.5, 1.2),\n",
    "          fancybox=True, shadow=True, ncol=max(int(nb_differentStim/18), 1))\n",
    "plt.subplots_adjust(right=.8)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip omnetics headstage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell bellow if you believe omnetic headstage was reverted for this mouse during this session (if you run it twice it will go back to the initial configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ch_list_ID = LFPs_df.columns-ID*32\n",
    "rec_ch_list_mouse = [value for value in rec_ch_list_ID if 0 <= value <= 31]\n",
    "i = np.argmax(rec_ch_list_ID>=0)\n",
    "inverted_chs = np.concatenate([range(16,32,1), range(0,16,1)], axis=0)\n",
    "LFPs_df_mouse=LFPs_df.iloc[:,i:i+len(rec_ch_list_mouse)]\n",
    "flipped_ch=(inverted_chs[LFPs_df_mouse.columns-(ID*32)])+(ID*32)\n",
    "LFPs_df.columns.values[i:i+len(rec_ch_list_mouse)] = flipped_ch\n",
    "LFPs_df = LFPs_df.sort_index(axis=1)\n",
    "\n",
    "# Reselect electrodes    \n",
    "all_LFPcoordinates= all_LFPcoordinates.astype(str)\n",
    "for region in all_LFPcoordinates.loc[mouse].index:\n",
    "    locals()[f'{region}_0']=[]\n",
    "    locals()[f'{region}_1']=[]\n",
    "    locals()[f'{region}_0ch']=[]\n",
    "    locals()[f'{region}_1ch']=[]\n",
    "\n",
    "RecordedArea = []\n",
    "ChoosenChannels = []\n",
    "combined = []\n",
    "if mouse:\n",
    "    rec_ch_list_mouse = [value for value in rec_ch_list if 0+(ID*32) <= value <= 31+(ID*32)]\n",
    "    for rec_ch in rec_ch_list_mouse:\n",
    "        for idx, LFPcoord_str in enumerate(all_LFPcoordinates.loc[mouse]):\n",
    "            region = all_LFPcoordinates.loc[mouse].index[idx]\n",
    "            if LFPcoord_str != 'nan' and region != 'EMG':\n",
    "                LFPcoord = LFPcoord_str.split('_')[:2] # only take into account the 2 first of electrode of that region \n",
    "                num_ch = np.where(str(rec_ch-(ID*32)) == np.array(LFPcoord))[0]\n",
    "                if len(num_ch)>0:\n",
    "                    region=all_LFPcoordinates.loc[mouse].index[idx]\n",
    "                    LFP=locals()[f'{region}_0']\n",
    "                    if len(LFP)>0:\n",
    "                        LFP= np.array(LFPs_df[(rec_ch)])\n",
    "                        locals()[f'{region}_1']=LFP\n",
    "                        locals()[f'{region}_1ch']=rec_ch\n",
    "                    else:\n",
    "                        LFP= np.array(LFPs_df[(rec_ch)])\n",
    "                        locals()[f'{region}_0']=LFP\n",
    "                        locals()[f'{region}_0ch']=rec_ch\n",
    "                    break\n",
    "                continue\n",
    "    \n",
    "    for region in all_LFPcoordinates.loc[mouse].index:\n",
    "        for n in range(0,2,1):\n",
    "            LFP=locals()[f'{region}_{n}']\n",
    "            LFP_ch=locals()[f'{region}_{n}ch']\n",
    "            if len(LFP)>0:\n",
    "                combined=zscore(LFP[:,np.newaxis]) if len(combined)==0 else np.append(combined, zscore(LFP[:,np.newaxis]), axis=1)\n",
    "                RecordedArea.append(f'{region}_{n}') \n",
    "                ChoosenChannels.append(LFP_ch) \n",
    "else:\n",
    "    print(\"/!\\ No mouse name found in the path OR in the csv file '_LFP_coordinates_of_all_mice.csv'\")\n",
    "    mouse = '' # fill mouse name\n",
    "    RecordedArea = ['PFC','S1'] \n",
    "    PFC_0 = LFPs_df[0]\n",
    "    S1_1 = LFPs_df[1]\n",
    "    combined = np.stack([zscore(PFC_0), zscore(S1_1)], axis=1)\n",
    "\n",
    "print(mouse)\n",
    "print(RecordedArea)\n",
    "print(ChoosenChannels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save if you're now sure that the omnetic headstage was reverted for this mouse during this recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if samplerate <= 1000:\n",
    "    LFPs_df.to_pickle(f'{LFPfile.parent}/DataFrame_rawdataDS.pkl')\n",
    "else: # best to downsample too\n",
    "    new_sampling_rate = 1000 # Hz\n",
    "    Nmber_points = int(np.shape(LFPs_df)[0] * new_sampling_rate / samplerate)\n",
    "    LFPs_df_DS = pd.DataFrame(signal.resample(LFPs_df, Nmber_points, axis = 0), columns=LFPs_df.columns.values)\n",
    "    LFPtimestampsDS = LFPtimestamps[::int(samplerate/new_sampling_rate)][:-1]\n",
    "    samplerate = new_sampling_rate\n",
    "    LFPs_df_DS.to_pickle(f'{LFPfile.parent}/DataFrame_rawdataDS.pkl')\n",
    "    np.save(f'{file_pathTS.parent}/timeStampsDS.npy', LFPtimestampsDS)\n",
    "    LFPs_df = LFPs_df_DS\n",
    "    LFPtimestamps = LFPtimestampsDS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
