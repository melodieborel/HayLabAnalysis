{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7dda0d",
   "metadata": {},
   "source": [
    "# Spike sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4cdd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reAnalyse = True\n",
    "engine = \"dask\" #\"dask\", \"submitit\", or None\n",
    "GPU_available = True\n",
    "sorterFolder='kilosort4_output'\n",
    "training_folder = 'sorting_analyzer_training'\n",
    "fullAnalyzer_folder = 'sorting_analyzer_full'\n",
    "whitenFirst = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd66156",
   "metadata": {},
   "source": [
    "## Set up everything\n",
    "You shouldn't have to change anything from here so you can keep that part folded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b006d50",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4c2661-565d-4949-aa45-d44200c20f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "from spikeinterface.sortingcomponents.motion import estimate_motion, interpolate_motion\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import submitit\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import asyncio\n",
    "import gc\n",
    "\n",
    "#import mbTools\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython import get_ipython\n",
    "import IPython\n",
    "from IPython.display import Javascript\n",
    "import pickleshare\n",
    "\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e190a",
   "metadata": {},
   "source": [
    "### Define a few variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cf29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_extract = 1 #min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac2f4e",
   "metadata": {},
   "source": [
    "#### Structural (important for the process but no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e310982",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_job=None\n",
    "sorter='kilosort4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ed711",
   "metadata": {},
   "source": [
    "### Define a few functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4a6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magicretrieve(stored_var):\n",
    "   # myvar will contain the variable previously stored with \"%store test\"\n",
    "   myvar_filename = get_ipython().ipython_dir + '/profile_default/db/autorestore/' + stored_var\n",
    "   with open(myvar_filename, 'rb') as f:\n",
    "      return pickle.load(f)\n",
    "\n",
    "def magicstore(stored_var, value):\n",
    "   # myvar will contain the variable previously stored with \"%store test\"\n",
    "   myvar_filename = get_ipython().ipython_dir + '/profile_default/db/autorestore/' + stored_var\n",
    "   with open(myvar_filename, 'wb') as f:\n",
    "      pickle.dump(value,f)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbf1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_my_expe_choice(chooser):\n",
    "    currentFile_data = str(chooser.selected)\n",
    "    currentFile_mnt = os.path.join('/mnt/data/ahay',os.path.split(currentFile_data)[1])\n",
    "    if not currentFile_data.startswith('/crnldata/'):\n",
    "        print('please make sure to select the file on crnldata')\n",
    "        return\n",
    "    # check if the file already exists on /mnt/\n",
    "    if os.path.isfile(currentFile_mnt):\n",
    "        print(f\"{currentFile_mnt} already exists\")\n",
    "    else:\n",
    "        print(f\"there is no version of {currentFile_data} on /mnt/\")\n",
    "        shouldCopy = False # it took a while (20 min for a file of about 150Gb)\n",
    "        if shouldCopy:\n",
    "            print(f'it will be copied to {currentFile_mnt}')\n",
    "            startTime = time.time()\n",
    "            shutil.copyfile(currentFile_data, currentFile_mnt)\n",
    "            print(f'the transfer is complete, it took {time.time()-startTime} seconds')\n",
    "        else:\n",
    "            print('it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources')\n",
    "\n",
    "    magicstore('currentFile_data', currentFile_data)\n",
    "    magicstore('currentFile_mnt', currentFile_mnt)\n",
    "\n",
    "\n",
    "def selectData(currentFile):\n",
    "    print(currentFile)\n",
    "    if currentFile is not None:\n",
    "        pathName, fileName = os.path.split(currentFile)\n",
    "    else:\n",
    "        pathName = '/crnldata/waking/audrey_hay/'\n",
    "        fileName = ''\n",
    "    fc = FileChooser(path=pathName, filename=fileName, filter_pattern='NP_spikes_*.raw', select_default=True, show_only_dirs = False, title = \"<b>Select file on crnldata</b>\")\n",
    "    display(fc)\n",
    "\n",
    "    # Register callback function\n",
    "    fc.register_callback(update_my_expe_choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a4a6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def runFunction(engine,funcName,*params,**engineParams):\n",
    "    start_time = time.time()\n",
    "    match engine:\n",
    "        case \"dask\":\n",
    "            print(\"dask\")\n",
    "            cluster = SLURMCluster(\n",
    "                                **engineParams,\n",
    "                                nanny=False,\n",
    "                                log_directory=\"si_dask_logs\",\n",
    "                                scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                                )\n",
    "            cluster.scale(1)\n",
    "            client = Client(cluster)\n",
    "\n",
    "            print(client.get_versions(check=True))\n",
    "    \n",
    "            \"\"\"\n",
    "            from dask.distributed import PipInstall\n",
    "            plugin = PipInstall(packages=[\"git+https://github.com/SpikeInterface/spikeinterface.git\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            plugin = PipInstall(packages=[\"git+https://github.com/SpikeInterface/probeinterface.git\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            plugin = PipInstall(packages=[\"git+https://github.com/SpikeInterface/spikeinterface-gui.git\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            plugin = PipInstall(packages=[\"kilosort\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "\n",
    "            plugin = PipInstall(packages=[\"numpy\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            \"\"\"\n",
    "            \n",
    "            print(cluster.job_script()) \n",
    "\n",
    "            future = client.submit(funcName, *params)\n",
    "            res = future.result()\n",
    "                        \n",
    "            # Close cluster\n",
    "            client.close()\n",
    "            cluster.close()\n",
    "\n",
    "        \n",
    "        case \"submitit\":\n",
    "            print(\"submitit\")\n",
    "\n",
    "            executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "            executor.update_parameters(**engineParams)\n",
    "\n",
    "            job = executor.submit(funcName, *params)\n",
    "\n",
    "            # print the ID of your job\n",
    "            print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "            # await a single result\n",
    "            await job.awaitable().results()\n",
    "            res = job.result()\n",
    "\n",
    "        case _:\n",
    "            print(\"no engine\")\n",
    "            res = funcName(*params) \n",
    "            \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b539b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateDict(rec, probe, folder, **sorter_params):\n",
    "    rec = rec.set_probe(probe)\n",
    "    si.set_global_job_kwargs(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    sorting = si.run_sorter(sorter, rec, verbose=True, folder=folder, remove_existing_folder=True, **sorter_params)\n",
    "    return sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484a0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_analyzer(sorting,rec,probe,folder,append=False):\n",
    "\n",
    "    rec = rec.set_probe(probe)\n",
    "    si.set_global_job_kwargs(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    \n",
    "    if append:\n",
    "        sorting_analyzer = si.load_sorting_analyzer(folder)\n",
    "    else:\n",
    "        sorting_analyzer = si.create_sorting_analyzer(sorting, rec, sparse=True, folder=folder,overwrite=True)\n",
    "\n",
    "    sorting_analyzer.compute(\"random_spikes\", method=\"uniform\", max_spikes_per_unit=500)\n",
    "    sorting_analyzer.compute(\"waveforms\")\n",
    "    sorting_analyzer.compute(\"templates\")\n",
    "    sorting_analyzer.compute(\"noise_levels\")\n",
    "    sorting_analyzer.compute(\"unit_locations\", method=\"monopolar_triangulation\")\n",
    "    sorting_analyzer.compute(\"isi_histograms\")\n",
    "    sorting_analyzer.compute(\"correlograms\") #, window_ms=100, bin_ms=5.\n",
    "    sorting_analyzer.compute(\"principal_components\", n_components=3, mode='by_channel_global', whiten=True)\n",
    "    sorting_analyzer.compute(\"quality_metrics\", metric_names=[\"snr\", \"firing_rate\"])\n",
    "    sorting_analyzer.compute(\"template_similarity\")\n",
    "    sorting_analyzer.compute(\"spike_amplitudes\")\n",
    "\n",
    "    #print(folder)\n",
    "    #print(sorting_analyzer)\n",
    "    #sorting_analyzer.save_as(folder=folder, format='zarr')\n",
    "    #print(sorting_analyzer)\n",
    "\n",
    "    return sorting_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "017793bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_traces(rec):\n",
    "    # filter traces\n",
    "    rec = rec.astype('float32')\n",
    "    print(\"filtering trace, please wait\")\n",
    "    rec_filt = si.bandpass_filter(rec)\n",
    "    display(rec_filt)\n",
    "\n",
    "    # Account for the slight delays in recordings due to the fact the 384 channels are only digitilized with 32 ADCs\n",
    "    print(\"aligning trace, please wait\")\n",
    "    isi=0.076923077\n",
    "    inter_sample_shift = np.arange(12)*isi\n",
    "    inter_sample_shift = np.expand_dims(np.repeat(inter_sample_shift,2),0)\n",
    "    inter_sample_shift = np.repeat(inter_sample_shift,16,0).flatten()\n",
    "    rec_filt_shifted = si.phase_shift(rec_filt, inter_sample_shift=inter_sample_shift)\n",
    "    \n",
    "    # Remove bad channels\n",
    "    print(\"removing bad channels, please wait\")\n",
    "    try:\n",
    "        bad_channel_ids, channel_labels = si.detect_bad_channels(rec_filt_shifted)\n",
    "        print('bad_channel_ids', bad_channel_ids)\n",
    "        rec = rec.remove_channels(bad_channel_ids)\n",
    "        rec_filt = rec_filt.remove_channels(bad_channel_ids)\n",
    "        rec_filt_shifted = rec_filt_shifted.remove_channels(bad_channel_ids)\n",
    "    except Exception as error:\n",
    "        print(\"could not remove bad channels because there was an error:\")\n",
    "        print(error)\n",
    "\n",
    "\n",
    "    # Remove the common noisy events (artefacts)\n",
    "    print(\"remove commonn ref, please wait\")\n",
    "    rec_filt_ref = si.common_reference(rec_filt_shifted)\n",
    "    display(rec_filt_ref)\n",
    "\n",
    "    recording_layers = dict(\n",
    "        raw = rec,\n",
    "        filter = rec_filt,\n",
    "        realigned = rec_filt_shifted,\n",
    "        cmr = rec_filt_ref,\n",
    "    )\n",
    "\n",
    "    return recording_layers, bad_channel_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_drift(rec, probe):      \n",
    "    #rec = rec.set_probe(probe)\n",
    "\n",
    "    job_kwargs_global = dict(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    si.set_global_job_kwargs(**job_kwargs_global)\n",
    "    \n",
    "    recording_corrected, motion, motion_info = si.correct_motion(\n",
    "            rec, preset=\"dredge_fast\", folder=None, output_motion=True, output_motion_info=True, estimate_motion_kwargs=dict(rigid=True)#,\n",
    "        )\n",
    "    return recording_corrected, motion, motion_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d616f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiten(rec,recording_layers,layerName):\n",
    "\n",
    "    rec_whitened = si.WhitenRecording(rec)\n",
    "\n",
    "    recording_layers[layerName] = rec_whitened\n",
    "\n",
    "    return recording_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339081a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRessources():\n",
    "    # check node and CPU information\n",
    "    print(\"### Node counts: \\nA: currently in use \\B available\")\n",
    "    !sinfo -o%A\n",
    "    print(\"### CPU counts: \\nA: core currently in use \\nI: available \\nO: unavailable (maintenance, down, etc) \\nT: total\")\n",
    "    !sinfo -o%C\n",
    "    !sinfo\n",
    "\n",
    "    # check some stats of our last job\n",
    "    if last_job is not None:\n",
    "        print('### CPU time and MaxRSS of our last job (about 1000Mb should be added to your MaxRSS (Mb) in order to cover safely the memory needs of the python runtime)###')\n",
    "        os.system(f'sacct -j {last_job.job_id} --format=\"CPUTime,MaxRSS\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a24596",
   "metadata": {},
   "source": [
    "## Choose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c6dc444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16/NP_spikes_2024-07-22T17_55_16.raw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598abce909cd4f0f9e1bab4cb14cf423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16', filename='NP_spikes_2024-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#currentFile_data = '/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16/NP_spikes_2024-07-22T17_55_16.raw'\n",
    "#mbTools.magicstore('currentFile_data', currentFile_data)\n",
    "currentFile_data = magicretrieve('currentFile_data')\n",
    "selectData(currentFile_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8669ae",
   "metadata": {},
   "source": [
    "### Move data to /mnt/ if appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbf2a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shouldCopy = False # it took a while (20 min for a file of about 150Gb)\n",
    "if shouldCopy:\n",
    "    currentFile_data = magicretrieve('currentFile_data')\n",
    "    currentFile_mnt = magicretrieve('currentFile_mnt')\n",
    "    print(f'The file {currentFile_data} will be copied to {currentFile_mnt}')\n",
    "    startTime = time.time()\n",
    "    shutil.copyfile(currentFile_data, currentFile_mnt)\n",
    "    print(f'the transfer is complete, it took {time.time()-startTime} seconds')\n",
    "else:\n",
    "    print('it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532274e",
   "metadata": {},
   "source": [
    "### Lazy load data and probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8606c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFile_data = magicretrieve('currentFile_data')\n",
    "currentFile_mnt = magicretrieve('currentFile_mnt')\n",
    "\n",
    "raw_rec = si.read_binary(currentFile_mnt, dtype='uint16', num_channels=384, sampling_frequency=30_000.,gain_to_uV=1, offset_to_uV=0)\n",
    "raw_rec.annotate(raw_path = currentFile_data)\n",
    "raw_rec = si.ScaleRecording(raw_rec, gain=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3d0a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spikeinterface.widgets.probe_map.ProbeMapWidget at 0x7f4ce205b3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e92ff2831542a19e265f401d75af4a",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxy0lEQVR4nO3daXQUZb7H8V+HLISlk7CkQyQwAREIAkE2M4ozSI5BAw6KC8soOiCDEmUThFEQHRAJbqgjDOoRvIgCV1G2ATmARCQCAmGJYVOUoHaHEdINKElI6r7Q1CUGBIWkQz/fzzl9xlQ9Xf0vXtzzvdWpisOyLEsAAAAwRpC/BwAAAEDlIgABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQwAXJyMhQz549FRsbK4fDoffff7/MfsuyNGHCBDVo0EDh4eFKTk7Wvn37yqw5cuSI+vfvL6fTqcjISA0cOFDHjx8vs2bHjh3q0qWLqlevrri4OKWnp5ebZeHChWrRooWqV6+u1q1ba/ny5Rf9fAEgEBCAAC7IiRMn1LZtW/3rX/864/709HS9+OKLmjlzpjZu3KiaNWsqJSVFJ0+etNf0799f2dnZWrVqlZYuXaqMjAwNHjzY3u/z+XTDDTeocePG2rJli6ZNm6aJEydq1qxZ9poNGzaob9++GjhwoLZt26ZevXqpV69e2rVrV8WdPABcohyWZVn+HgJAYHA4HFq0aJF69eol6aerf7GxsRo1apQefvhhSZLX65XL5dLs2bPVp08f5eTkKCEhQZs3b1aHDh0kSStWrNBNN92kQ4cOKTY2VjNmzNCjjz4qt9ut0NBQSdLYsWP1/vvva/fu3ZKkO++8UydOnNDSpUvtea6++molJiZq5syZlfivAABVH1cAAVSYAwcOyO12Kzk52d4WERGhzp07KzMzU5KUmZmpyMhIO/4kKTk5WUFBQdq4caO95rrrrrPjT5JSUlK0Z88eHT161F5z+ueUrin9nPNRUlKiQ4cOyev1yufz2S+v16tDhw6ppKTkt/8jAEAVFOzvAQAELrfbLUlyuVxltrtcLnuf2+1WdHR0mf3BwcGqU6dOmTXx8fHljlG6LyoqSm63+1c/50wKCgpUUFBg//zNN98oISHhrOtzc3PVsGHDs+4HgEsFAQjAWFOmTNETTzxRbvuBAweUmZWpYhWrmqopKTFJ8fHxql27th+mBICLj6+AAVSYmJgYSZLH4ymz3ePx2PtiYmKUl5dXZv+pU6d05MiRMmvOdIzTP+Nsa0r3n8m4cePk9XrtV25uriSpRo0aKqpRpIiWESqqUaQaNWpI+ul3HAEgEBCAACpMfHy8YmJitHr1anubz+fTxo0blZSUJElKSkpSfn6+tmzZYq9Zs2aNSkpK1LlzZ3tNRkaGioqK7DWrVq1S8+bNFRUVZa85/XNK15R+zpmEhYXJ6XSWeQGACQhAABfk+PHjysrKUlZWlqSfvj7NysrSwYMH5XA4NHz4cE2aNEmLFy/Wzp07dffddys2Nta+U7hly5bq3r277rvvPm3atEmffPKJ0tLS1KdPH8XGxkqS+vXrp9DQUA0cOFDZ2dmaP3++pk+frpEjR9pzDBs2TCtWrNCzzz6r3bt3a+LEifrss8+UlpZW2f8kAFD1WQBwAdauXWtJKvcaMGCAZVmWVVJSYo0fP95yuVxWWFiY1a1bN2vPnj1ljvH9999bffv2tWrVqmU5nU7r3nvvtY4dO1Zmzfbt261rr73WCgsLsy677DLr6aefLjfLggULrCuuuMIKDQ21WrVqZS1btuw3nYvX67UkWR6Px5qzco61ePdia87KOZbH47EkWV6v97f94wBAFcVzAAHgZz6fTxEREfJ4PFqRtUJRjaN09Ouj6p7YXS6XS16vl6+JAQQEvgIGAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAqVHFxscaPH6/4+HiFh4eradOm+uc//ynLsuw1lmVpwoQJatCggcLDw5WcnKx9+/aVOc6RI0fUv39/OZ1ORUZGauDAgTp+/HiZNTt27FCXLl1UvXp1xcXFKT09vVLOEQAuNQQggAo1depUzZgxQy+//LJycnI0depUpaen66WXXrLXpKen68UXX9TMmTO1ceNG1axZUykpKTp58qS9pn///srOztaqVau0dOlSZWRkaPDgwfZ+n8+nG264QY0bN9aWLVs0bdo0TZw4UbNmzarU8wWAS4HDOv3/DQeAi6xHjx5yuVx6/fXX7W29e/dWeHi45s6dK8uyFBsbq1GjRunhhx+WJHm9XrlcLs2ePVt9+vRRTk6OEhIStHnzZnXo0EGStGLFCt100006dOiQYmNjNWPGDD366KNyu90KDQ2VJI0dO1bvv/++du/efV6z+nw+RUREyOPxaEXWCkU1jtLRr4+qe2J3uVwueb1eOZ3Oi/wvBACVjyuAACrUH//4R61evVp79+6VJG3fvl3r16/XjTfeKEk6cOCA3G63kpOT7fdERESoc+fOyszMlCRlZmYqMjLSjj9JSk5OVlBQkDZu3Givue666+z4k6SUlBTt2bNHR48erfDzBIBLSbC/BwAQ2MaOHSufz6cWLVqoWrVqKi4u1uTJk9W/f39JktvtliS5XK4y73O5XPY+t9ut6OjoMvuDg4NVp06dMmvi4+PLHaN0X1RUVLnZCgoKVFBQYP/s8/ku5FQB4JLBFUAAFWrBggV66623NG/ePG3dulVz5szRM888ozlz5vh7NE2ZMkURERH2Ky4uzt8jAUClIAABVKjRo0dr7Nix6tOnj1q3bq277rpLI0aM0JQpUyRJMTExkiSPx1PmfR6Px94XExOjvLy8MvtPnTqlI0eOlFlzpmOc/hm/NG7cOHm9XvuVm5t7gWcLAJcGAhBAhfrhhx8UFFT2/9RUq1ZNJSUlkqT4+HjFxMRo9erV9n6fz6eNGzcqKSlJkpSUlKT8/Hxt2bLFXrNmzRqVlJSoc+fO9pqMjAwVFRXZa1atWqXmzZuf8etfSQoLC5PT6SzzAgATEIAAKlTPnj01efJkLVu2TF999ZUWLVqk5557TrfccoskyeFwaPjw4Zo0aZIWL16snTt36u6771ZsbKx69eolSWrZsqW6d++u++67T5s2bdInn3yitLQ09enTR7GxsZKkfv36KTQ0VAMHDlR2drbmz5+v6dOna+TIkf46dQCosrgJBECFeumllzR+/Hg98MADysvLU2xsrP7+979rwoQJ9poxY8boxIkTGjx4sPLz83XttddqxYoVql69ur3mrbfeUlpamrp166agoCD17t1bL774or0/IiJCH374oYYOHar27durXr16mjBhQplnBQIAfsJzAAHgZzwHEIAp+AoYAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAKocN98843++te/qm7dugoPD1fr1q312Wef2fsty9KECRPUoEEDhYeHKzk5Wfv27StzjCNHjqh///5yOp2KjIzUwIEDdfz48TJrduzYoS5duqh69eqKi4tTenp6pZwfAFxqCEAAFero0aO65pprFBISov/85z/6/PPP9eyzzyoqKspek56erhdffFEzZ87Uxo0bVbNmTaWkpOjkyZP2mv79+ys7O1urVq3S0qVLlZGRocGDB9v7fT6fbrjhBjVu3FhbtmzRtGnTNHHiRM2aNatSzxcALgUOy7Isfw8BIHCNHTtWn3zyiT7++OMz7rcsS7GxsRo1apQefvhhSZLX65XL5dLs2bPVp08f5eTkKCEhQZs3b1aHDh0kSStWrNBNN92kQ4cOKTY2VjNmzNCjjz4qt9ut0NBQ+7Pff/997d69+7xm9fl8ioiIkMfj0YqsFYpqHKWjXx9V98Tucrlc8nq9cjqdF+FfBQD8iyuAACrU4sWL1aFDB91+++2Kjo5Wu3bt9Oqrr9r7Dxw4ILfbreTkZHtbRESEOnfurMzMTElSZmamIiMj7fiTpOTkZAUFBWnjxo32muuuu86OP0lKSUnRnj17dPTo0Yo+TQC4pBCAACrUl19+qRkzZqhZs2ZauXKl7r//fj300EOaM2eOJMntdkuSXC5Xmfe5XC57n9vtVnR0dJn9wcHBqlOnTpk1ZzrG6Z/xSwUFBfL5fGVeAGCCYH8PACCwlZSUqEOHDnrqqackSe3atdOuXbs0c+ZMDRgwwK+zTZkyRU888YRfZwAAf+AKIIAK1aBBAyUkJJTZ1rJlSx08eFCSFBMTI0nyeDxl1ng8HntfTEyM8vLyyuw/deqUjhw5UmbNmY5x+mf80rhx4+T1eu1Xbm7u7zlFALjkEIAAKtQ111yjPXv2lNm2d+9eNW7cWJIUHx+vmJgYrV692t7v8/m0ceNGJSUlSZKSkpKUn5+vLVu22GvWrFmjkpISde7c2V6TkZGhoqIie82qVavUvHnzMnccny4sLExOp7PMCwBMQAACqFAjRozQp59+qqeeekr79+/XvHnzNGvWLA0dOlSS5HA4NHz4cE2aNEmLFy/Wzp07dffddys2Nla9evWS9NMVw+7du+u+++7Tpk2b9MknnygtLU19+vRRbGysJKlfv34KDQ3VwIEDlZ2drfnz52v69OkaOXKkv04dAKosfgcQQIXq2LGjFi1apHHjxunJJ59UfHy8XnjhBfXv399eM2bMGJ04cUKDBw9Wfn6+rr32Wq1YsULVq1e317z11ltKS0tTt27dFBQUpN69e+vFF1+090dEROjDDz/U0KFD1b59e9WrV08TJkwo86xAAMBPeA4gAPyM5wACMAVfAQMAABiGr4CBAFdYWKicnBwdPnxY+fn5ioyMVP369dWyZcsyD00GAJiDAAQC0OHDhzV79mwtW7ZMmzZtUkFBQbk1YWFh6tSpk3r06KEBAwaofv36fpgUAOAPBCAQQPbv36/x48dr0aJFKiwslCTVq1dP7du3V506deR0OuX1enX06FHt3r1bGRkZysjI0GOPPaZbb71VTz75pC6//HI/nwUAoKIRgECASEtL06uvvqri4mJ17dpV/fr105///GfFx8ef9T1ffvml1q5dq3nz5mnBggV69913NXjwYL300kuVODkAoLJxFzAQIGrUqKHBgwdrzJgx9rPxfotvvvlG6enpeu2113TixIkKmLDq4y5gAKbgCiAQIL788suz/smz83HZZZdp+vTpGjdu3EWcCgBQFfEYGCBAXEj8VcRxAABVFwEIAABgGL4CBgJUcXGxnnvuOb333nv67rvvVK9ePSUkJKhdu3Zq166dEhMTFRkZ6e8xAQB+QAACAeqxxx5Tenq6Su/zOnjwoLZu3aq5c+fK4XBIkho1amQH4fjx4/05LgCgEhGAQIB66623FBISogULFujGG2+U1+vVzp07lZWVpe3btysrK0s5OTn6+uuv9cEHHxCAAGAQAhAIUPn5+erevbtuvvlmST89ELpr167q2rWrvaaoqEjZ2dnavn27v8YEAPgBAQgEqLZt2+pcj/kMCQlRYmKiEhMTK2coAECVwF3AQIAaOnSo1q5dq7y8PH+PAgCoYghAIED16dNHt956q/7yl7/ou+++8/c4AIAqhAAEAti4ceP03//+V61bt9bo0aOVkZFh7J95AwD8P34HEAhQy5cvV+/evVVYWCjLsvTss8/queeek8PhUNOmTe3Hv5Q+EzA6OtrfIwMAKgkBCASof/zjHyooKFDPnj114403yufz2Y9/2bt3r/bt26cFCxbI4XDI4XDo1KlT/h4ZAFBJCEAgQO3du1ft2rXTBx98UG7fyZMntWPHDmVlZWnr1q08BgYADEMAAgEqJiZGzZs3P+O+6tWrq1OnTurUqVMlTwUAqAq4CQQIUL1799amTZvO+SxAAIB5CEAgQD322GMqKSnRpEmT/D0KAKCKIQCBANWrVy+1bdtWEydOVN++fZWTk+PvkQAAVQS/AwgEqHXr1tn/PX/+fC1YsEBNmzZVx44dlZiYaD8Cpm7dun6cEgDgDwQgEKAOHDigrKws+9EvWVlZ2r9/v/bv36+3335bDodDknTZZZed9W5hAEBgIgCBANW4cWM1btxYf/nLX+xtpz8LsPR/s7OztXTpUj9OCgCobAQgYBCn06kuXbqoS5cu9rbi4mLt3r3bj1MBACobN4EAAWrt2rU6evToOddVq1ZNrVq1qoSJAABVBVcAgQDVrVs3ORwONWzYUImJiWVe8fHx9rqBAweqffv2euCBB/w4LQCgMjksnhILBKRBgwYpKytLu3btUmFhoSTZN344nU61adNGV1xxhRYtWqTg4GC53W5/jlsl+Hw+RUREyOPxaEXWCkU1jtLRr4+qe2J3uVwueb1eOZ1Of48JABeMK4BAgHrttdckSadOndLnn3+urKwsbdu2Tdu2bdOnn36qjz/+WOvXr5dlWWrUqJGfpwUAVCYCEAhwwcHBatOmjdq0aaO7775bknT8+HHNnj1bY8eO1ZVXXqm5c+f6eUoAQGXiJhDAQLVq1VJaWpoWLFigzZs3a+vWrf4eCQBQiQhAwGA33XSTWrRooSlTpvh7FABAJSIAAcPFx8drz549/h4DAFCJ+B1AIEANGzbM/pu/rVq1UkhIyBnX7d+/XzExMZU8HQDAnwhAIEC99NJL9mNfQkJC1KJFC7Vr106JiYlq3bq1atSooblz52rfvn2aOXOmn6cFAFQmAhAIUIsXL7Yf+7Jt2zbt2LFDO3bs0JtvvllmXZMmTeTxeLR8+XK1b99eLpfLTxMDACoLD4IGDHH06NEyQbh161bt3btXJSUlkv7/IdExMTFq3769Fi9e7M9x/YIHQQMwBVcAAUNERUXp+uuv1/XXX29v++GHH7Rjxw47CLdt26Zdu3Zp2bJlfpwUAFDRCEDAYDVq1NDVV1+tq6++2t5W+pdDAACBi8fAACij9C+HAAACFwEIBIjs7OwqdRwAQNVFAAIBok2bNurbt6927Njxu96/bds23XHHHWrbtu1FngwAUNUQgECAePzxx7Vs2TL7WX9Tp07Vp59+qoKCgjOuP3nypDIzMzVlyhS1bt1aHTp00IoVK/T4449X8uQAgMrGY2CAAJKXl6fJkyfrzTfflNfrlcPhUHBwsOLi4hQVFaXatWvr2LFjOnLkiHJzc1VcXCzLshQREaF7771X48aNU/369f19Gn7DY2AAmIK7gIEAEh0drenTp+vpp5/WggULtHTpUq1fv15ffvllubUxMTHq0qWLUlNTdccdd6h69ep+mBgA4A8EIBCAwsPDNWDAAA0YMECSdPjwYeXl5cnr9SoiIkLR0dFGX+kDANMRgIAB6tevT/ABAGzcBAIAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAeqJJ57QoUOH/D0GAKAKIgCBAPXEE08oPj5ePXv21OLFi1VSUuLvkQAAVQQBCASoSZMmqVGjRlq2bJluueUWxcXFafz48frqq6/8PRoAwM8IQCBA/eMf/9AXX3yhDz/8ULfffru+//57TZ48WZdffrm6d++ud999V6dOnfL3mAAAPyAAgQCXnJysd955R998842eeeYZNW/eXB9++KHuuOMONWzYUGPHjtW+ffv8PSYAoBIRgIAh6tatq5EjRyo7O1vr169X3759lZeXp2nTpqlFixbq1q2bFi1aVOFzPP3003I4HBo+fLi97eTJkxo6dKjq1q2rWrVqqXfv3vJ4PGXed/DgQaWmpqpGjRqKjo7W6NGjy13B/Oijj3TVVVcpLCxMl19+uWbPnl3h5wMAlyICEDDMF198oSVLlmj16tX2toYNG2rt2rW67bbb1KlTJ+Xm5lbIZ2/evFn//ve/1aZNmzLbR4wYoSVLlmjhwoVat26dvv32W9166632/uLiYqWmpqqwsFAbNmzQnDlzNHv2bE2YMMFec+DAAaWmpqpr167KysrS8OHDNWjQIK1cubJCzgUALmkWgIBXWFhovf3229b1119vBQUFWQ6Hw6pXr541atQoa+/evZZlWdaGDRus1NRUy+FwWDfffPNFn+HYsWNWs2bNrFWrVll/+tOfrGHDhlmWZVn5+flWSEiItXDhQnttTk6OJcnKzMy0LMuyli9fbgUFBVlut9teM2PGDMvpdFoFBQWWZVnWmDFjrFatWpX5zDvvvNNKSUk57xm9Xq8lyfJ4PNaclXOsxbsXW3NWzrE8Ho8lyfJ6vb/39AGgSuEKIBDAcnJyNHLkSMXGxqp///5au3atkpKS9Oabb+rQoUN65pln1KxZM0lSUlKSli5dqk6dOmndunUXfZahQ4cqNTVVycnJZbZv2bJFRUVFZba3aNFCjRo1UmZmpiQpMzNTrVu3lsvlstekpKTI5/MpOzvbXvPLY6ekpNjHAAD8v2B/DwCgYlx77bXKzMyUZVlyOp26//77NWTIEF155ZW/+r5WrVpp8+bNF3WWd955R1u3bj3jcd1ut0JDQxUZGVlmu8vlktvtttecHn+l+0v3/doan8+nH3/8UeHh4eU+u6CgQAUFBfbPPp/vt58cAFyCCEAgQG3YsEFXXXWVhgwZon79+qlGjRrn9b5Bgwbpuuuuu2hz5ObmatiwYVq1apWqV69+0Y57MUyZMkVPPPFEue0ul0sOh0PRl0Xr9ntuV/fE7n6YDgAqDgEIBKjNmzerffv2v/l9SUlJSkpKumhzbNmyRXl5ebrqqqvsbcXFxcrIyNDLL7+slStXqrCwUPn5+WWuAno8HsXExEiSYmJitGnTpjLHLb1L+PQ1v7xz2OPxyOl0nvHqnySNGzdOI0eOtH/2+XyKi4tTcHCwTp06Jc8hj16e9LLqBNX5/f8AAFAF8TuAQID6PfFXEbp166adO3cqKyvLfnXo0EH9+/e3/zskJKTMXcl79uzRwYMH7RBNSkrSzp07lZeXZ69ZtWqVnE6nEhIS7DWnH6N0za/FbFhYmJxOZ5mXpHKPl3nyyScv7B8BAKoYrgACqFC1a9cu93uHNWvWVN26de3tAwcO1MiRI1WnTh05nU49+OCDSkpK0tVXXy1JuuGGG5SQkKC77rpL6enpcrvdeuyxxzR06FCFhYVJkoYMGaKXX35ZY8aM0d/+9jetWbNGCxYs0LJlyyr3hAHgEkAAAvC7559/XkFBQerdu7cKCgqUkpKiV155xd5frVo1LV26VPfff7+SkpJUs2ZNDRgwoMyVufj4eC1btkwjRozQ9OnT1bBhQ7322mtKSUnxxykBQJXmsCzL8vcQAFAV+Hw+RUREnHW/1+u1vyYGgEsZvwMIAABgGAIQAM7B4XD4ewQAuKgIQAAAAMMQgABwDvyqNIBAQwACwDlUq1bN3yMAwEVFAALAORQXF/t7BAC4qAhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAnEPPnj39PQIAXFQEIACcw/79+/09AgBcVAQgAJxDTk6Ov0cAgIuKAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAACrclClT1LFjR9WuXVvR0dHq1auX9uzZU2bNyZMnNXToUNWtW1e1atVS79695fF4yqw5ePCgUlNTVaNGDUVHR2v06NE6depUmTUfffSRrrrqKoWFhenyyy/X7NmzK/r0AOCSQwACqHDr1q3T0KFD9emnn2rVqlUqKirSDTfcoBMnTthrRowYoSVLlmjhwoVat26dvv32W9166632/uLiYqWmpqqwsFAbNmzQnDlzNHv2bE2YMMFec+DAAaWmpqpr167KysrS8OHDNWjQIK1cubJSzxcAqjqHZVmWv4cAYJbDhw8rOjpa69at03XXXSev16v69etr3rx5uu222yRJu3fvVsuWLZWZmamrr75a//nPf9SjRw99++23crlckqSZM2fqkUce0eHDhxUaGqpHHnlEy5Yt065du+zP6tOnj/Lz87VixYpzzuXz+RQREXHW/V6vV06n8wLPHgD8jyuAACqd1+uVJNWpU0eStGXLFhUVFSk5Odle06JFCzVq1EiZmZmSpMzMTLVu3dqOP0lKSUmRz+dTdna2veb0Y5SuKT0GAOAnwf4eAIBZSkpKNHz4cF1zzTW68sorJUlut1uhoaGKjIwss9blcsntdttrTo+/0v2l+35tjc/n048//qjw8PAy+woKClRQUGD/7PP5LvwEAeASwBVAAJVq6NCh2rVrl9555x1/j6IpU6YoIiLCfsXFxfl7JACoFAQggEqTlpampUuXau3atWrYsKG9PSYmRoWFhcrPzy+z3uPxKCYmxl7zy7uCS38+1xqn01nu6p8kjRs3Tl6v137l5uZe8DkCwKWAAARQ4SzLUlpamhYtWqQ1a9YoPj6+zP727dsrJCREq1evtrft2bNHBw8eVFJSkiQpKSlJO3fuVF5enr1m1apVcjqdSkhIsNecfozSNaXH+KWwsDA5nc4yLwAwAXcBA6hwDzzwgObNm6cPPvhAzZs3t7dHRETYV+buv/9+LV++XLNnz5bT6dSDDz4oSdqwYYOknx4Dk5iYqNjYWKWnp8vtduuuu+7SoEGD9NRTT0n66TEwV155pYYOHaq//e1vWrNmjR566CEtW7ZMKSkp55yTu4ABmIIABFDhHA7HGbe/8cYbuueeeyT99CDoUaNG6e2331ZBQYFSUlL0yiuv2F/vStLXX3+t+++/Xx999JFq1qypAQMG6Omnn1Zw8P/fz/bRRx9pxIgR+vzzz9WwYUONHz/e/oxzIQABmIIABICfEYAATMHvAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgABwDhEREf4eAQAuKgIQAM7B6/X6ewQAuKgIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAACAYQhAAAAAwxCAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCAAAYBgCEAAAwDAEIAAAgGEIQAAAAMMQgAAAAIYhAAEAAAxDAAIAABiGAAQAADAMAQgAAGAYAhAAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQQMD517/+pT/84Q+qXr26OnfurE2bNvl7JACoUghAAAFl/vz5GjlypB5//HFt3bpVbdu2VUpKivLy8vw9GgBUGQ7Lsix/DwEAF0vnzp3VsWNHvfzyy5KkkpISxcXF6cEHH9TYsWN/9b0+n08RERGSpLDwUBX8WFhmv9frldPprJjBAaAScQUQQMAoLCzUli1blJycbG8LCgpScnKyMjMzy60vKCiQz+cr87L3/SL+ACCQEIAAAsZ///tfFRcXy+VyldnucrnkdrvLrZ8yZYoiIiLsV1xcXGWNCgB+RQACMNa4cePk9XrtV25urqSfrhpKUkSdCH+OBwAVJtjfAwDAxVKvXj1Vq1ZNHo+nzHaPx6OYmJhy68PCwhQWFlZue0lJiSTJe8RbMYMCgJ9xBRBAwAgNDVX79u21evVqe1tJSYlWr16tpKSk8z7OkCFDKmI8AKgyuAsYQECZP3++BgwYoH//+9/q1KmTXnjhBS1YsEC7d+8u97uBv1R6F7DX61Xef/P0n13/0U2tb1L9uvXt7dwFDCAQ8BUwgIBy55136vDhw5owYYLcbrcSExO1YsWKc8bfL9WrU0+n8k+pblTdCpoUAPyHAAQQcNLS0pSWlnZBx3A6nYquGS2n06njx49fpMkAoGogAAHgZ6W/EVP6PMD2rdrr+PHj9s/8xgyAQEEAAsDPvv/+e0k66/MAjx07Zv+lEAC4lHEXMAD8rE6dOpKk7OxsSdLnn38uSTp48KByc3MVGxvrt9kA4GLiCiAA/Kz0AdCld/rWrl1bkhQREcHdvwACClcAAQAADEMAAgAAGIYABICfhYWF6fHHH5fT6Szzv2f6c3EAcCnjL4EAAAAYhiuAAAAAhiEAAQAADEMAAgAAGIYABAAAMAwBCMBoEydOlMPhOOMrJCREHTt21G233aa6deuqRo0aqlevnsLCwhQXF6f09HR/jw8AvwsBCMB4rVq1UsOGDTV69GhNnTpVISEhev7555WZmakTJ07ovffe0/Tp0xUeHi6Hw6GEhARNmzZNEydO1KxZs/w9PgD8ZgQgAOMFBwerWrVqio2N1bvvvqvBgwdr+PDhatasmfbv36/IyEj97//+ryzL0urVq5WVlaU//OEPeuihh/Tcc8/5e3wA+M34W8AAjLdv3z4VFBRo1KhRKikp0bfffqvGjRsrMTFRRUVFSklJ0fr163XdddepTZs2atSokTIzM5WSkqKpU6fq6NGjioqK8vdpAMB5IwABGK1z586aPXu2Nm7cqOrVq2vy5Mny+XyaPHmy/vjHPyo0NFRxcXHy+XxyuVySJJfLJbfbbf/sdrsJQACXFL4CBhCwxo4de9YbPEpf8fHxuv322/XMM8/ogQcekCQVFxfrlltu0cqVK/18BgBQMbgCCCBgjRo1Svfcc8+vrmnSpIn93/Xq1VO1atXUoEEDVatWTSUlJSosLFRubq6cTqc8Ho8kyePxKCYmxv45Jiamws4BACoCAQggYNWvX1/169c/7/WhoaFKTEzUrl27VFhYKIfDoeDgYH344Yfq0qWLMjIytGvXLh08eFBJSUlavHixmjdvzte/AC45BCAAoz388MNq0qSJ3G63mjZtqmPHjqmgoEDvvfeeevbsqX379mn37t3q3bu3Pv74Y11//fVq27atvv76a02fPl3PP/+8v08BAH4zh2VZlr+HAAB/6dOnj1avXq3vv/9ekuRwOBQVFaXi4mL98MMPatOmjRo3bqw1a9boxx9/VM2aNXXs2DHVr19fDz74oB555BE/nwEA/HYEIAAAgGG4CxgAAMAwBCAAAIBhCEAAAADDEIAAAACGIQABAAAMQwACAAAYhgAEAAAwDAEIAABgGAIQAADAMAQgAGM8+eSTCgoK0s6dO/09SjnfffedwsPD9cADD/h7FAAG4E/BATCCx+PR5ZdfrhtvvFELFizw9zhnNGzYML3yyivKzs7WFVdc4e9xAAQwrgACMMJTTz2l48ePa9y4cf4e5azGjBmjkpISjR8/3t+jAAhwXAEEEPB++OEHxcbGKi4urkp+/Xu65ORkZWRkKDc3Vy6Xy9/jAAhQXAEEUCXdeeedcjgcGjNmTLl9e/fuVa1atVSrVi3t27fvnMdauHChvF6v+vbte9Y1S5YskcPh0IMPPnjG/YMGDZLD4dDq1avtbV999ZUcDof+9Kc/KT8/X6NHj1Z8fLzCw8PVtm1bLVu2zF77zjvv6Nprr1Xt2rUVFxensWPHqqioqNzn9OvXT0VFRZo9e/Y5zwsAfi8CEECVNHPmTDVs2FDPPvus1q5da28vKipS//79deLECb3wwgtq1qzZOY+1dOlSSdKf//zns67Ztm2bJCkxMfG892dlZUmSIiMj1a5dO7377rvq3LmzWrRooR07dujWW2/V7t27dc8992jQoEGKiopS165d5fF4NHXqVD333HPlPqd0xtPjEQAuNgIQQJUUFRWlN998U5J099136+jRo5KkiRMn6rPPPlOvXr00aNCg8zrWxx9/rODgYLVr1+6sa0oD70xrioqKtGvXLjVs2FB169a1t2/fvl2StHjxYg0YMED79u3TO++8o61bt6pnz54qLCxUjx49lJOTo3379mnJkiVavHixFi5cKEl67733yn1WkyZNVK9ePW3atEknT548r/MDgN+KAARQZXXt2lWjRo3SoUOHNGTIEH388cd6+umn1aBBA7366qvndYy8vDx5PB7FxcUpPDz8rOu2bdumkJAQtWrVqty+zz//XIWFheWuDpZeAbz99ts1ceJEVatWTZLkcDh04403SpKOHDmid999Vw0aNLDfV7rvu+++O+MszZs3V0FBgXJycs7rHAHgtyIAAVRpkyZNUmJiohYsWKAePXrIsiy98cYbqlev3nm9Py8vT9JPVxTP5siRI/r666/VokULhYWFldtfGnpnC8DHH3+83Ht8Pp8k6Z577lHDhg3L7PN6vZJ01nOoU6eOJOnw4cNnnRkALgQBCKBKCw0N1Zw5cyT9FFVDhgxRSkrKeb+/NLZq16591jW/9vXv6ftPD0Cv16uvvvpKTZs2PeNVw9Kvh2+++eZy+0rvRE5ISDjj5zmdTklSfn7+WWcGgAtBAAKo8ubPn2//d1ZWloqLi8/7vREREZKkY8eOnXXN77kBpDTwOnbseMb3ZGVlyeFwqH379mfcJ509OEujNTIy8qwzA8CFIAABVGnr16/X1KlTFRMTo+TkZGVmZmry5Mnn/f7o6GhJP33Nezalgde6dety+44dO6ZPP/1UTqdTTZo0sbef7WthSfrxxx+1d+9eNW3a9IxXHkvj8WwBWHrDS/369c86MwBcCAIQQJXl8/l01113qbi4WG+88Ybmzp2r+vXr65///Kc2btx4XseIjo5WTEyMcnNz9cMPP5xxzdatWyVJNWrUKLdvzpw5KiwsVJs2beRwOOztvxZxO3bsUHFx8VkD79fiUZJ2796tsLAwtWzZ8qznBQAXggAEUGWlpaXpq6++Ulpamrp37y6Xy6XXXntNp06d0l//+ledOHHivI7TpUsXFRcX21f6TnfixAnt3btXkjR37lyd/seRli9frkceeUSSyv1t3l/7GvfX9hUWFionJ0eNGjWyb/Y43RdffKHvv/9enTp1UvXq1c/r/ADgtyIAAVRJCxcu1P/8z/8oISFB6enp9vabb75Z9913n/bv369hw4ad17FSU1MlSR999FG5fTt27FBJSYmaNGmiGTNmqEWLFkpNTVVCQoJSU1PtGzzef/993XvvvZKkU6dOKTs7W5dddtkZv6b9tZtKsrOzVVRUdNarg6Uzls4MABWBAARQ5XzzzTf6+9//rtDQUL311lvlnt/3/PPPq1mzZnr99de1aNGicx7vjjvuUEREhObNm1duX2msDRgwQDNnzlRBQYFWr16tkJAQzZs3T3PnzlVcXJyqVaumq666StJPX9EWFBSc9SvcX/uKt/Sr47O9d968eQoJCdE999xzzvMCgN/LYZ3+fQcABKgRI0bohRde0GeffVbmztxBgwbp9ddf15IlS9SjRw8/TigdOnRIjRs31m233VbmzmcAuNi4AgjACOPGjVOtWrU0ZcqUMttLrwCe6XEtlW3atGkKCgrSk08+6e9RAAQ4AhCAEaKjozV69Gi999579oOYS//Gb0xMTJk/1eYP3333nWbNmqX77rtPzZs39+ssAAIfXwEDMNb27duVmJiom266ScuWLfP3OABQaQhAAAAAw/AVMAAAgGH+D+Qi92KTTtz7AAAAAElFTkSuQmCC",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('/crnldata/waking/audrey_hay/NPX/NPXprobe.pkl', 'rb') as outp: \n",
    "    probe = pickle.load(outp)\n",
    "probe.set_device_channel_indices(np.arange(384))\n",
    "\n",
    "raw_rec = raw_rec.set_probe(probe)\n",
    "display(si.plot_probe_map(raw_rec, with_channel_ids=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a43680",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c250e0",
   "metadata": {},
   "source": [
    "### Filter and apply common ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf29d4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/audrey.hay/HayLabAnalysis/.si-env/lib/python3.11/site-packages/distributed/node.py:187: UserWarning: Port 8780 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 46241 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scheduler': {'host': {'python': '3.11.2.final.0', 'python-bits': 64, 'OS': 'Linux', 'OS-release': '6.1.0-22-amd64', 'machine': 'x86_64', 'processor': '', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'fr_FR.UTF-8'}, 'packages': {'python': '3.11.2.final.0', 'dask': '2024.11.2', 'distributed': '2024.11.2', 'msgpack': '1.1.0', 'cloudpickle': '3.0.0', 'tornado': '6.4.1', 'toolz': '0.12.1', 'numpy': '1.26.3', 'pandas': '2.2.2', 'lz4': None}}, 'workers': {}, 'client': {'host': {'python': '3.11.2.final.0', 'python-bits': 64, 'OS': 'Linux', 'OS-release': '6.1.0-22-amd64', 'machine': 'x86_64', 'processor': '', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'fr_FR.UTF-8'}, 'packages': {'python': '3.11.2.final.0', 'dask': '2024.11.2', 'distributed': '2024.11.2', 'msgpack': '1.1.0', 'cloudpickle': '3.0.0', 'tornado': '6.4.1', 'toolz': '0.12.1', 'numpy': '1.26.3', 'pandas': '2.2.2', 'lz4': None}}}\n",
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e si_dask_logs/dask-worker-%J.err\n",
      "#SBATCH -o si_dask_logs/dask-worker-%J.out\n",
      "#SBATCH -p CPU\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=1\n",
      "#SBATCH --mem=3G\n",
      "#SBATCH -t 00:30:00\n",
      "\n",
      "/home/audrey.hay/HayLabAnalysis/.si-env/bin/python -m distributed.cli.dask_worker tcp://10.69.168.93:45471 --name dummy-name --nthreads 1 --memory-limit 2.79GiB --no-nanny --death-timeout 60 --lifetime 2m\n",
      "\n",
      "job done in 52.35610389709473 s\n",
      "computing done, please wait for display\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357d634b4f404ef9ae0e936df806b100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(TimeSlider(children=(Dropdown(description='segment', options=(0,), value=0), Button(icon='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if reAnalyse:\n",
    "    match engine,GPU_available:\n",
    "        case \"dask\", _: # no real interest in using gpu\n",
    "            engineParam=dict(\n",
    "                                queue='CPU',\n",
    "                                cores=1,\n",
    "                                memory=\"3GB\",\n",
    "                                worker_extra_args=[\"--lifetime\", \"2m\"],\n",
    "            )\n",
    "        case \"submitit\", _:\n",
    "            engineParam=dict(\n",
    "                                mem_gb=3,\n",
    "                                timeout_min=2,\n",
    "                                slurm_partition=\"CPU\",\n",
    "                                cpus_per_task=4\n",
    "            )\n",
    "        case _:\n",
    "            engineParam = dict()\n",
    "\n",
    "    recording_layers, bad_channel_ids  = await runFunction(engine, preprocess_traces, raw_rec, **engineParam)\n",
    "    \n",
    "    print(\"computing done, please wait for display\")\n",
    "    si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637e35e",
   "metadata": {},
   "source": [
    "### Correct for motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "348fd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitenFirst = True\n",
    "canal_lim=300 #limitation of canals to keep for drift correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8efb7e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>WhitenRecording: 383 channels - 30.0kHz - 1 segments - 189,418,428 samples - 6,313.95s (1.75 hours) - float32 dtype - 270.26 GiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
       "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
       "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
       "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
       "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
       "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
       " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
       " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
       " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
       " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
       " 180 181 182 183 184 185 186 187 188 189 190 192 193 194 195 196 197 198\n",
       " 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n",
       " 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n",
       " 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n",
       " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
       " 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n",
       " 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n",
       " 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n",
       " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
       " 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360\n",
       " 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
       " 379 380 381 382 383] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: True</li><li> <strong> name </strong>: None</li></ul> </details><details style='margin-left: 10px;'><summary><strong>Channel Properties</strong></summary><ul><details><summary> <strong> gain_to_uV </strong> </summary>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " 1 1 1 1 1 1 1 1 1 1 1 1 1]</details><details><summary> <strong> offset_to_uV </strong> </summary>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0]</details><details><summary> <strong> group </strong> </summary>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0]</details><details><summary> <strong> location </strong> </summary>[[  16.    0.]\n",
       " [  48.    0.]\n",
       " [   0.   20.]\n",
       " [  32.   20.]\n",
       " [  16.   40.]\n",
       " [  48.   40.]\n",
       " [   0.   60.]\n",
       " [  32.   60.]\n",
       " [  16.   80.]\n",
       " [  48.   80.]\n",
       " [   0.  100.]\n",
       " [  32.  100.]\n",
       " [  16.  120.]\n",
       " [  48.  120.]\n",
       " [   0.  140.]\n",
       " [  32.  140.]\n",
       " [  16.  160.]\n",
       " [  48.  160.]\n",
       " [   0.  180.]\n",
       " [  32.  180.]\n",
       " [  16.  200.]\n",
       " [  48.  200.]\n",
       " [   0.  220.]\n",
       " [  32.  220.]\n",
       " [  16.  240.]\n",
       " [  48.  240.]\n",
       " [   0.  260.]\n",
       " [  32.  260.]\n",
       " [  16.  280.]\n",
       " [  48.  280.]\n",
       " [   0.  300.]\n",
       " [  32.  300.]\n",
       " [  16.  320.]\n",
       " [  48.  320.]\n",
       " [   0.  340.]\n",
       " [  32.  340.]\n",
       " [  16.  360.]\n",
       " [  48.  360.]\n",
       " [   0.  380.]\n",
       " [  32.  380.]\n",
       " [  16.  400.]\n",
       " [  48.  400.]\n",
       " [   0.  420.]\n",
       " [  32.  420.]\n",
       " [  16.  440.]\n",
       " [  48.  440.]\n",
       " [   0.  460.]\n",
       " [  32.  460.]\n",
       " [  16.  480.]\n",
       " [  48.  480.]\n",
       " [   0.  500.]\n",
       " [  32.  500.]\n",
       " [  16.  520.]\n",
       " [  48.  520.]\n",
       " [   0.  540.]\n",
       " [  32.  540.]\n",
       " [  16.  560.]\n",
       " [  48.  560.]\n",
       " [   0.  580.]\n",
       " [  32.  580.]\n",
       " [  16.  600.]\n",
       " [  48.  600.]\n",
       " [   0.  620.]\n",
       " [  32.  620.]\n",
       " [  16.  640.]\n",
       " [  48.  640.]\n",
       " [   0.  660.]\n",
       " [  32.  660.]\n",
       " [  16.  680.]\n",
       " [  48.  680.]\n",
       " [   0.  700.]\n",
       " [  32.  700.]\n",
       " [  16.  720.]\n",
       " [  48.  720.]\n",
       " [   0.  740.]\n",
       " [  32.  740.]\n",
       " [  16.  760.]\n",
       " [  48.  760.]\n",
       " [   0.  780.]\n",
       " [  32.  780.]\n",
       " [  16.  800.]\n",
       " [  48.  800.]\n",
       " [   0.  820.]\n",
       " [  32.  820.]\n",
       " [  16.  840.]\n",
       " [  48.  840.]\n",
       " [   0.  860.]\n",
       " [  32.  860.]\n",
       " [  16.  880.]\n",
       " [  48.  880.]\n",
       " [   0.  900.]\n",
       " [  32.  900.]\n",
       " [  16.  920.]\n",
       " [  48.  920.]\n",
       " [   0.  940.]\n",
       " [  32.  940.]\n",
       " [  16.  960.]\n",
       " [  48.  960.]\n",
       " [   0.  980.]\n",
       " [  32.  980.]\n",
       " [  16. 1000.]\n",
       " [  48. 1000.]\n",
       " [   0. 1020.]\n",
       " [  32. 1020.]\n",
       " [  16. 1040.]\n",
       " [  48. 1040.]\n",
       " [   0. 1060.]\n",
       " [  32. 1060.]\n",
       " [  16. 1080.]\n",
       " [  48. 1080.]\n",
       " [   0. 1100.]\n",
       " [  32. 1100.]\n",
       " [  16. 1120.]\n",
       " [  48. 1120.]\n",
       " [   0. 1140.]\n",
       " [  32. 1140.]\n",
       " [  16. 1160.]\n",
       " [  48. 1160.]\n",
       " [   0. 1180.]\n",
       " [  32. 1180.]\n",
       " [  16. 1200.]\n",
       " [  48. 1200.]\n",
       " [   0. 1220.]\n",
       " [  32. 1220.]\n",
       " [  16. 1240.]\n",
       " [  48. 1240.]\n",
       " [   0. 1260.]\n",
       " [  32. 1260.]\n",
       " [  16. 1280.]\n",
       " [  48. 1280.]\n",
       " [   0. 1300.]\n",
       " [  32. 1300.]\n",
       " [  16. 1320.]\n",
       " [  48. 1320.]\n",
       " [   0. 1340.]\n",
       " [  32. 1340.]\n",
       " [  16. 1360.]\n",
       " [  48. 1360.]\n",
       " [   0. 1380.]\n",
       " [  32. 1380.]\n",
       " [  16. 1400.]\n",
       " [  48. 1400.]\n",
       " [   0. 1420.]\n",
       " [  32. 1420.]\n",
       " [  16. 1440.]\n",
       " [  48. 1440.]\n",
       " [   0. 1460.]\n",
       " [  32. 1460.]\n",
       " [  16. 1480.]\n",
       " [  48. 1480.]\n",
       " [   0. 1500.]\n",
       " [  32. 1500.]\n",
       " [  16. 1520.]\n",
       " [  48. 1520.]\n",
       " [   0. 1540.]\n",
       " [  32. 1540.]\n",
       " [  16. 1560.]\n",
       " [  48. 1560.]\n",
       " [   0. 1580.]\n",
       " [  32. 1580.]\n",
       " [  16. 1600.]\n",
       " [  48. 1600.]\n",
       " [   0. 1620.]\n",
       " [  32. 1620.]\n",
       " [  16. 1640.]\n",
       " [  48. 1640.]\n",
       " [   0. 1660.]\n",
       " [  32. 1660.]\n",
       " [  16. 1680.]\n",
       " [  48. 1680.]\n",
       " [   0. 1700.]\n",
       " [  32. 1700.]\n",
       " [  16. 1720.]\n",
       " [  48. 1720.]\n",
       " [   0. 1740.]\n",
       " [  32. 1740.]\n",
       " [  16. 1760.]\n",
       " [  48. 1760.]\n",
       " [   0. 1780.]\n",
       " [  32. 1780.]\n",
       " [  16. 1800.]\n",
       " [  48. 1800.]\n",
       " [   0. 1820.]\n",
       " [  32. 1820.]\n",
       " [  16. 1840.]\n",
       " [  48. 1840.]\n",
       " [   0. 1860.]\n",
       " [  32. 1860.]\n",
       " [  16. 1880.]\n",
       " [  48. 1880.]\n",
       " [   0. 1900.]\n",
       " [  16. 1920.]\n",
       " [  48. 1920.]\n",
       " [   0. 1940.]\n",
       " [  32. 1940.]\n",
       " [  16. 1960.]\n",
       " [  48. 1960.]\n",
       " [   0. 1980.]\n",
       " [  32. 1980.]\n",
       " [  16. 2000.]\n",
       " [  48. 2000.]\n",
       " [   0. 2020.]\n",
       " [  32. 2020.]\n",
       " [  16. 2040.]\n",
       " [  48. 2040.]\n",
       " [   0. 2060.]\n",
       " [  32. 2060.]\n",
       " [  16. 2080.]\n",
       " [  48. 2080.]\n",
       " [   0. 2100.]\n",
       " [  32. 2100.]\n",
       " [  16. 2120.]\n",
       " [  48. 2120.]\n",
       " [   0. 2140.]\n",
       " [  32. 2140.]\n",
       " [  16. 2160.]\n",
       " [  48. 2160.]\n",
       " [   0. 2180.]\n",
       " [  32. 2180.]\n",
       " [  16. 2200.]\n",
       " [  48. 2200.]\n",
       " [   0. 2220.]\n",
       " [  32. 2220.]\n",
       " [  16. 2240.]\n",
       " [  48. 2240.]\n",
       " [   0. 2260.]\n",
       " [  32. 2260.]\n",
       " [  16. 2280.]\n",
       " [  48. 2280.]\n",
       " [   0. 2300.]\n",
       " [  32. 2300.]\n",
       " [  16. 2320.]\n",
       " [  48. 2320.]\n",
       " [   0. 2340.]\n",
       " [  32. 2340.]\n",
       " [  16. 2360.]\n",
       " [  48. 2360.]\n",
       " [   0. 2380.]\n",
       " [  32. 2380.]\n",
       " [  16. 2400.]\n",
       " [  48. 2400.]\n",
       " [   0. 2420.]\n",
       " [  32. 2420.]\n",
       " [  16. 2440.]\n",
       " [  48. 2440.]\n",
       " [   0. 2460.]\n",
       " [  32. 2460.]\n",
       " [  16. 2480.]\n",
       " [  48. 2480.]\n",
       " [   0. 2500.]\n",
       " [  32. 2500.]\n",
       " [  16. 2520.]\n",
       " [  48. 2520.]\n",
       " [   0. 2540.]\n",
       " [  32. 2540.]\n",
       " [  16. 2560.]\n",
       " [  48. 2560.]\n",
       " [   0. 2580.]\n",
       " [  32. 2580.]\n",
       " [  16. 2600.]\n",
       " [  48. 2600.]\n",
       " [   0. 2620.]\n",
       " [  32. 2620.]\n",
       " [  16. 2640.]\n",
       " [  48. 2640.]\n",
       " [   0. 2660.]\n",
       " [  32. 2660.]\n",
       " [  16. 2680.]\n",
       " [  48. 2680.]\n",
       " [   0. 2700.]\n",
       " [  32. 2700.]\n",
       " [  16. 2720.]\n",
       " [  48. 2720.]\n",
       " [   0. 2740.]\n",
       " [  32. 2740.]\n",
       " [  16. 2760.]\n",
       " [  48. 2760.]\n",
       " [   0. 2780.]\n",
       " [  32. 2780.]\n",
       " [  16. 2800.]\n",
       " [  48. 2800.]\n",
       " [   0. 2820.]\n",
       " [  32. 2820.]\n",
       " [  16. 2840.]\n",
       " [  48. 2840.]\n",
       " [   0. 2860.]\n",
       " [  32. 2860.]\n",
       " [  16. 2880.]\n",
       " [  48. 2880.]\n",
       " [   0. 2900.]\n",
       " [  32. 2900.]\n",
       " [  16. 2920.]\n",
       " [  48. 2920.]\n",
       " [   0. 2940.]\n",
       " [  32. 2940.]\n",
       " [  16. 2960.]\n",
       " [  48. 2960.]\n",
       " [   0. 2980.]\n",
       " [  32. 2980.]\n",
       " [  16. 3000.]\n",
       " [  48. 3000.]\n",
       " [   0. 3020.]\n",
       " [  32. 3020.]\n",
       " [  16. 3040.]\n",
       " [  48. 3040.]\n",
       " [   0. 3060.]\n",
       " [  32. 3060.]\n",
       " [  16. 3080.]\n",
       " [  48. 3080.]\n",
       " [   0. 3100.]\n",
       " [  32. 3100.]\n",
       " [  16. 3120.]\n",
       " [  48. 3120.]\n",
       " [   0. 3140.]\n",
       " [  32. 3140.]\n",
       " [  16. 3160.]\n",
       " [  48. 3160.]\n",
       " [   0. 3180.]\n",
       " [  32. 3180.]\n",
       " [  16. 3200.]\n",
       " [  48. 3200.]\n",
       " [   0. 3220.]\n",
       " [  32. 3220.]\n",
       " [  16. 3240.]\n",
       " [  48. 3240.]\n",
       " [   0. 3260.]\n",
       " [  32. 3260.]\n",
       " [  16. 3280.]\n",
       " [  48. 3280.]\n",
       " [   0. 3300.]\n",
       " [  32. 3300.]\n",
       " [  16. 3320.]\n",
       " [  48. 3320.]\n",
       " [   0. 3340.]\n",
       " [  32. 3340.]\n",
       " [  16. 3360.]\n",
       " [  48. 3360.]\n",
       " [   0. 3380.]\n",
       " [  32. 3380.]\n",
       " [  16. 3400.]\n",
       " [  48. 3400.]\n",
       " [   0. 3420.]\n",
       " [  32. 3420.]\n",
       " [  16. 3440.]\n",
       " [  48. 3440.]\n",
       " [   0. 3460.]\n",
       " [  32. 3460.]\n",
       " [  16. 3480.]\n",
       " [  48. 3480.]\n",
       " [   0. 3500.]\n",
       " [  32. 3500.]\n",
       " [  16. 3520.]\n",
       " [  48. 3520.]\n",
       " [   0. 3540.]\n",
       " [  32. 3540.]\n",
       " [  16. 3560.]\n",
       " [  48. 3560.]\n",
       " [   0. 3580.]\n",
       " [  32. 3580.]\n",
       " [  16. 3600.]\n",
       " [  48. 3600.]\n",
       " [   0. 3620.]\n",
       " [  32. 3620.]\n",
       " [  16. 3640.]\n",
       " [  48. 3640.]\n",
       " [   0. 3660.]\n",
       " [  32. 3660.]\n",
       " [  16. 3680.]\n",
       " [  48. 3680.]\n",
       " [   0. 3700.]\n",
       " [  32. 3700.]\n",
       " [  16. 3720.]\n",
       " [  48. 3720.]\n",
       " [   0. 3740.]\n",
       " [  32. 3740.]\n",
       " [  16. 3760.]\n",
       " [  48. 3760.]\n",
       " [   0. 3780.]\n",
       " [  32. 3780.]\n",
       " [  16. 3800.]\n",
       " [  48. 3800.]\n",
       " [   0. 3820.]\n",
       " [  32. 3820.]]</details></ul></details>"
      ],
      "text/plain": [
       "WhitenRecording: 383 channels - 30.0kHz - 1 segments - 189,418,428 samples \n",
       "                 6,313.95s (1.75 hours) - float32 dtype - 270.26 GiB"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "probe_good = probe.get_slice(recording_layers[\"raw\"].get_channel_ids())\n",
    "probe_2_correct = probe.get_slice([i for i in recording_layers[\"raw\"].get_channel_ids() if i < canal_lim])\n",
    "\n",
    "if whitenFirst:\n",
    "    recording_layers = whiten(recording_layers[\"cmr\"],recording_layers,\"whitenFirst\")\n",
    "    rec_2_correct = recording_layers[\"whitenFirst\"]\n",
    "else:\n",
    "    rec_2_correct = recording_layers[\"cmr\"]\n",
    "\n",
    "rec_2_correct_short = rec_2_correct.channel_slice(probe_2_correct.device_channel_indices)\n",
    "display(rec_2_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ef37904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask\n",
      "{'scheduler': {'host': {'python': '3.11.2.final.0', 'python-bits': 64, 'OS': 'Linux', 'OS-release': '6.1.0-22-amd64', 'machine': 'x86_64', 'processor': '', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'fr_FR.UTF-8'}, 'packages': {'python': '3.11.2.final.0', 'dask': '2024.11.2', 'distributed': '2024.11.2', 'msgpack': '1.1.0', 'cloudpickle': '3.0.0', 'tornado': '6.4.1', 'toolz': '0.12.1', 'numpy': '1.26.3', 'pandas': '2.2.2', 'lz4': None}}, 'workers': {}, 'client': {'host': {'python': '3.11.2.final.0', 'python-bits': 64, 'OS': 'Linux', 'OS-release': '6.1.0-22-amd64', 'machine': 'x86_64', 'processor': '', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'fr_FR.UTF-8'}, 'packages': {'python': '3.11.2.final.0', 'dask': '2024.11.2', 'distributed': '2024.11.2', 'msgpack': '1.1.0', 'cloudpickle': '3.0.0', 'tornado': '6.4.1', 'toolz': '0.12.1', 'numpy': '1.26.3', 'pandas': '2.2.2', 'lz4': None}}}\n",
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e si_dask_logs/dask-worker-%J.err\n",
      "#SBATCH -o si_dask_logs/dask-worker-%J.out\n",
      "#SBATCH -p CPU\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=55\n",
      "#SBATCH --mem=47G\n",
      "#SBATCH -t 00:30:00\n",
      "\n",
      "/home/audrey.hay/HayLabAnalysis/.si-env/bin/python -m distributed.cli.dask_worker tcp://10.69.168.93:43883 --name dummy-name --nthreads 1 --memory-limit 46.57GiB --no-nanny --death-timeout 60 --lifetime 20m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/audrey.hay/HayLabAnalysis/.si-env/lib/python3.11/site-packages/distributed/node.py:187: UserWarning: Port 8780 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 43137 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The given Probe have 'device_channel_indices' that do not match channel count \n299 vs 299 \ndevice_channel_indices are the following: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 192 193 194 195 196 197 198\n 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n 289 290 291 292 293 294 295 296 297 298 299] \nrecording channels are the following: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 192 193 194 195 196 197 198\n 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n 289 290 291 292 293 294 295 296 297 298 299] \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m         engineParam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m---> 30\u001b[0m recording_corrected_short, motion, motion_info  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m runFunction(engine,check_drift,rec_2_correct_short, probe_2_correct, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengineParam)\n\u001b[1;32m     32\u001b[0m recording_corrected \u001b[38;5;241m=\u001b[39m interpolate_motion(\n\u001b[1;32m     33\u001b[0m             recording\u001b[38;5;241m=\u001b[39mrec_2_correct,\n\u001b[1;32m     34\u001b[0m             motion\u001b[38;5;241m=\u001b[39mmotion_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmotion\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     35\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmotion_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterpolate_motion_kwargs\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     37\u001b[0m recording_layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrected\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m recording_corrected\n",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m, in \u001b[0;36mrunFunction\u001b[0;34m(engine, funcName, *params, **engineParams)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(cluster\u001b[38;5;241m.\u001b[39mjob_script()) \n\u001b[1;32m     34\u001b[0m future \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39msubmit(funcName, \u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 35\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Close cluster\u001b[39;00m\n\u001b[1;32m     38\u001b[0m client\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/HayLabAnalysis/.si-env/lib/python3.11/site-packages/distributed/client.py:402\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_initialized()\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m, in \u001b[0;36mcheck_drift\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_drift\u001b[39m(rec, probe):      \n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m probe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m         rec \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mset_probe(probe)\n\u001b[1;32m      5\u001b[0m     job_kwargs_global \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, chunk_duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     si\u001b[38;5;241m.\u001b[39mset_global_job_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjob_kwargs_global)\n",
      "File \u001b[0;32m~/HayLabAnalysis/.si-env/lib/python3.11/site-packages/spikeinterface/core/baserecordingsnippets.py:101\u001b[0m, in \u001b[0;36mset_probe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m probegroup \u001b[38;5;241m=\u001b[39m ProbeGroup()\n\u001b[1;32m    100\u001b[0m probegroup\u001b[38;5;241m.\u001b[39madd_probe(probe)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_probes(probegroup, group_mode\u001b[38;5;241m=\u001b[39mgroup_mode, in_place\u001b[38;5;241m=\u001b[39min_place)\n",
      "File \u001b[0;32m~/HayLabAnalysis/.si-env/lib/python3.11/site-packages/spikeinterface/core/baserecordingsnippets.py:180\u001b[0m, in \u001b[0;36m_set_probes\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m number_of_device_channel_indices \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_channels():\n\u001b[1;32m    174\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe given Probe have \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice_channel_indices\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m that do not match channel count \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber_of_device_channel_indices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_channels()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_channel_indices are the following: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_channel_indices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecording channels are the following: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_channel_ids()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m     )\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[1;32m    182\u001b[0m new_channel_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_channel_ids()[device_channel_indices]\n\u001b[1;32m    183\u001b[0m probe_as_numpy_array \u001b[38;5;241m=\u001b[39m probe_as_numpy_array[order]\n",
      "\u001b[0;31mValueError\u001b[0m: The given Probe have 'device_channel_indices' that do not match channel count \n299 vs 299 \ndevice_channel_indices are the following: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 192 193 194 195 196 197 198\n 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n 289 290 291 292 293 294 295 296 297 298 299] \nrecording channels are the following: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n 180 181 182 183 184 185 186 187 188 189 190 192 193 194 195 196 197 198\n 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n 289 290 291 292 293 294 295 296 297 298 299] \n"
     ]
    }
   ],
   "source": [
    "if reAnalyse:\n",
    "    match engine,GPU_available:\n",
    "        case \"dask\", _:\n",
    "            engineParam=dict(\n",
    "                                queue='CPU',\n",
    "                                cores=1,\n",
    "                                memory=\"50GB\",\n",
    "                                job_cpu=55,\n",
    "                                worker_extra_args=[\"--lifetime\", \"20m\"],\n",
    "            )\n",
    "        case \"submitit\", True:\n",
    "            engineParam=dict(\n",
    "                                slurm_array_parallelism=40,\n",
    "                                mem_gb=16,\n",
    "                                timeout_min=20,\n",
    "                                slurm_partition=\"GPU\",\n",
    "                                cpus_per_task=2\n",
    "            )\n",
    "        case \"submitit\", False:\n",
    "            engineParam=dict(\n",
    "                                slurm_array_parallelism=4,\n",
    "                                mem_gb=60,\n",
    "                                timeout_min=20,\n",
    "                                slurm_partition=\"CPU\",\n",
    "                                cpus_per_task=40\n",
    "            )\n",
    "        case _:\n",
    "            engineParam = dict()\n",
    "\n",
    "    recording_corrected_short, motion, motion_info  = await runFunction(engine,check_drift,rec_2_correct_short, probe_2_correct, **engineParam)\n",
    "\n",
    "    recording_corrected = interpolate_motion(\n",
    "                recording=rec_2_correct,\n",
    "                motion=motion_info['motion'],\n",
    "                **motion_info['parameters']['interpolate_motion_kwargs'])\n",
    "    \n",
    "    recording_layers[\"corrected\"] = recording_corrected\n",
    "    display(motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d751b0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rq: you should avoid submitting multiple small tasks with submitit, which would create many independent jobs\n",
      "      and possibly overload the cluster, while you can do it without any problem through dask.distributed.\n"
     ]
    }
   ],
   "source": [
    "# (72) 16 min (slurm_array_parallelism=4, mem_gb=60, timeout_min=20, slurm_partition=\"CPU\", cpus_per_task=40)\n",
    "print(\"\"\"rq: you should avoid submitting multiple small tasks with submitit, which would create many independent jobs\n",
    "      and possibly overload the cluster, while you can do it without any problem through dask.distributed.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7225843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spikeinterface.widgets.motion.MotionInfoWidget at 0x7f4c2db916d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si.plot_motion_info(motion_info, recording_corrected,\n",
    "                   color_amplitude=True,\n",
    "        amplitude_cmap=\"inferno\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d958a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not whitenFirst:\n",
    "    recording_layers = whiten(recording_corrected,recording_layers,\"whitenLast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28144436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56025df3e24d4cf09038e3afd365f002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(TimeSlider(children=(Dropdown(description='segment', options=(0,), value=0), Button(icon='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<spikeinterface.widgets.traces.TracesWidget at 0x7f233b4b6a10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9caa0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if whitenFirst:\n",
    "    rec = recording_layers[\"whitenFirst\"] #if whitened and not corrected\n",
    "    #rec = recording_layers[\"corrected\"] #if whitened then corrected\n",
    "else:\n",
    "    rec = recording_layers[\"whitenLast\"] #if corrected the whiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9470dc2",
   "metadata": {},
   "source": [
    "## Identify spike clusters for the first few minutes of recording"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df08855",
   "metadata": {},
   "source": [
    "It is good practice to have a look at available ressources and current use of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25f7a9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Node counts: \n",
      "A: currently in use \\B available\n",
      "NODES(A/I)\n",
      "1/18\n",
      "### CPU counts: \n",
      "A: core currently in use \n",
      "I: available \n",
      "O: unavailable (maintenance, down, etc) \n",
      "T: total\n",
      "CPUS(A/I/O/T)\n",
      "20/876/144/1040\n",
      "PARTITION   AVAIL  TIMELIMIT  NODES  STATE NODELIST\n",
      "CPU*           up   infinite      1  drain node14\n",
      "CPU*           up   infinite     16   idle node[1-11,13,15,18-20]\n",
      "CPU*           up   infinite      1   down node21\n",
      "INTERACTIVE    up   infinite      1  drain node12\n",
      "INTERACTIVE    up   infinite      1    mix node17\n",
      "INTERACTIVE    up   infinite      1   idle node16\n",
      "GPU            up   infinite      1   idle node23\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n"
     ]
    }
   ],
   "source": [
    "checkRessources()\n",
    "\n",
    "#!sinfo --nodes=node15 -o \"%50N  %10c  %20m  %30G \"\n",
    "!squeue --partition=\"GPU\"\n",
    "\n",
    "#torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 712.00 MiB. GPU 0 has a total capacity of 79.26 GiB of which 187.19 MiB is free. Process 1619368 has 77.78 GiB memory in use. Including non-PyTorch memory, this process has 1.28 GiB memory in use. Of the allocated memory 529.55 MiB is allocated by PyTorch, and 276.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "881c09f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For information, parameters that are available for the sorter kilosort4 are:\n",
      " {'batch_size': 60000, 'nblocks': 1, 'Th_universal': 9, 'Th_learned': 8, 'do_CAR': True, 'invert_sign': False, 'nt': 61, 'shift': None, 'scale': None, 'artifact_threshold': None, 'nskip': 25, 'whitening_range': 32, 'highpass_cutoff': 300, 'binning_depth': 5, 'sig_interp': 20, 'drift_smoothing': [0.5, 0.5, 0.5], 'nt0min': None, 'dmin': None, 'dminx': 32, 'min_template_size': 10, 'template_sizes': 5, 'nearest_chans': 10, 'nearest_templates': 100, 'max_channel_distance': None, 'templates_from_data': True, 'n_templates': 6, 'n_pcs': 6, 'Th_single_ch': 6, 'acg_threshold': 0.2, 'ccg_threshold': 0.25, 'cluster_downsampling': 20, 'cluster_pcs': 64, 'x_centers': None, 'duplicate_spike_ms': 0.25, 'scaleproc': None, 'save_preprocessed_copy': False, 'torch_device': 'auto', 'bad_channels': None, 'clear_cache': False, 'save_extra_vars': False, 'do_correction': True, 'keep_good_only': False, 'skip_kilosort_preprocessing': False, 'use_binary_file': None, 'delete_recording_dat': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for information, display a list of all parameters that can be modified for the sorter\n",
    "params = si.get_default_sorter_params(sorter_name_or_class=sorter)\n",
    "print(f\"For information, parameters that are available for the sorter {sorter} are:\\n\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kilosort.io:========================================\n",
      "INFO:kilosort.io:Loading recording with SpikeInterface...\n",
      "INFO:kilosort.io:number of samples: 1800000\n",
      "INFO:kilosort.io:number of channels: 384\n",
      "INFO:kilosort.io:numbef of segments: 1\n",
      "INFO:kilosort.io:sampling rate: 30000.0\n",
      "INFO:kilosort.io:dtype: float32\n",
      "INFO:kilosort.io:========================================\n",
      "INFO:kilosort.run_kilosort: \n",
      "INFO:kilosort.run_kilosort:Computing drift correction.\n",
      "INFO:kilosort.run_kilosort:----------------------------------------\n",
      "INFO:kilosort.datashift:nblocks = 0, skipping drift correction\n",
      "INFO:kilosort.run_kilosort:drift computed in  0.00s; total  0.01s\n",
      "INFO:kilosort.run_kilosort: \n",
      "INFO:kilosort.run_kilosort:Resource usage after drift correction\n",
      "INFO:kilosort.run_kilosort:********************************************************\n",
      "INFO:kilosort.run_kilosort:CPU usage:     5.00 %\n",
      "INFO:kilosort.run_kilosort:Memory:       13.03 %     |     16.37   /   125.62 GB\n",
      "INFO:kilosort.run_kilosort:------------------------------------------------------\n",
      "INFO:kilosort.run_kilosort:GPU usage:    N/A\n",
      "INFO:kilosort.run_kilosort:GPU memory:   N/A\n",
      "INFO:kilosort.run_kilosort:********************************************************\n",
      "INFO:kilosort.run_kilosort: \n",
      "INFO:kilosort.run_kilosort:Extracting spikes using templates\n",
      "INFO:kilosort.run_kilosort:----------------------------------------\n",
      "INFO:kilosort.spikedetect:Re-computing universal templates from data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping kilosort preprocessing.\n",
      "Skipping drift correction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kilosort.spikedetect:Number of universal templates: 1532\n",
      "INFO:kilosort.spikedetect:Detecting spikes...\n",
      "100%|██████████| 30/30 [07:23<00:00, 14.77s/it]\n",
      "INFO:kilosort.run_kilosort:68612 spikes extracted in  470.00s; total  470.02s\n",
      "INFO:kilosort.run_kilosort: \n",
      "INFO:kilosort.run_kilosort:First clustering\n",
      "INFO:kilosort.run_kilosort:----------------------------------------\n",
      "100%|██████████| 96/96 [00:48<00:00,  1.99it/s] \n",
      "INFO:kilosort.run_kilosort:185 clusters found, in  48.45s; total  518.47s\n",
      "INFO:kilosort.run_kilosort: \n",
      "INFO:kilosort.run_kilosort:Extracting spikes using cluster waveforms\n",
      "INFO:kilosort.run_kilosort:----------------------------------------\n",
      " 57%|█████▋    | 17/30 [01:43<01:19,  6.10s/it]"
     ]
    }
   ],
   "source": [
    "if True: #reAnalyse and engine is None:\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "    rec_training = recording_corrected.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "    sorter_params=dict(\n",
    "        do_correction = False,\n",
    "        skip_kilosort_preprocessing = True # we already did it\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    sorting = GenerateDict(rec_training, probe, sorterFolder, **sorter_params)\n",
    "\n",
    "    display(sorting)\n",
    "\n",
    "# env. 55 min pour 2 min d'enregistrement\n",
    "# env. 3 min pour 0.25 min d'enregistrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine = \"dask\"\n",
    "if False:  #reAnalyse and engine==\"dask\":\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "    rec_training = recording_corrected.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "    sorter_params=dict(\n",
    "        do_correction = False,\n",
    "        skip_kilosort_preprocessing = True # we already did it\n",
    "    )\n",
    "\n",
    "    \n",
    "    if GPU_available: # takes about 10 minutes with dask #longer?\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"4GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gpus=2'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 40 minutes\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"6GB\",\n",
    "                        job_cpu=55,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "    print(client.get_versions(check=True))\n",
    "    \n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(GenerateDict, rec_training, probe, sorterFolder, **sorter_params)\n",
    "    sorting = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: #reAnalyse and engine==\"submitit\":\n",
    "    #it takes about 90s with GPU (if available) ; 40 min otherwise\n",
    "    gc.collect()\n",
    "\n",
    "    GPU_available = True\n",
    "\n",
    "    start_time = time.time()\n",
    "    rec_training = recording_corrected.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    if GPU_available:\n",
    "        executor.update_parameters(mem_gb=5, timeout_min=10, slurm_partition=\"GPU\", cpus_per_task=2)\n",
    "        #executor.update_parameters(mem_gb=5, timeout_min=5, slurm_partition=\"GPU\", slurm_gres='gpu:1')\n",
    "    else:\n",
    "        executor.update_parameters(mem_gb=5, timeout_min=120, slurm_partition=\"CPU\", cpus_per_task=60)\n",
    "\n",
    "\n",
    "    # actually submit the job\n",
    "    job = executor.submit(GenerateDict, rec_training, probe)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")\n",
    "\n",
    "    last_job = job\n",
    "    sorting = job.result()\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277d8c6-e2e1-46e1-8dee-4424d98675d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kilosort4 run time 2212.34s for 8Gb 10cpus num1 (15.74, 15.42, 1.49, 2.11)\n",
    "#100%|██████████| 60/60 [39:44<00:00, 39.74s/it] 8/10 python\n",
    "\n",
    "#32%|███▏      | 19/60 [09:26<19:40, 28.78s/it] 8/30 submitit\n",
    "#32%|███▏      | 19/60 [09:13<19:55, 29.16s/it] 16/30 submitit\n",
    "#60%|██████    | 36/60 [12:10<07:36, 19.02s/it] 5/30 submitit\n",
    "#23%|██▎       | 14/60 [10:14<32:55, 42.95s/it] 5/10 submitit\n",
    "#42%|████▏     | 25/60 [06:35<07:23, 12.66s/it] 5/50 submitit\n",
    "#33%|███▎      | 20/60 [05:32<10:29, 15.75s/it] 5/50 submitit data in mnt\n",
    "\n",
    "\n",
    "#GPU\n",
    "#job completed: 33972 returned in 110.73936009407043 seconds 5/50\n",
    "#job completed: 33973 returned in 94.93399000167847 seconds 5/10\n",
    "#job completed: 33975 returned in 93.79518842697144 seconds 5/2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee34b754",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "file_path=\"kilosort4_output/spikeinterface_recording.pickle\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    d = pickle.load(f)\n",
    "\n",
    "for key in d[\"kwargs\"]:\n",
    "#for key in d:\n",
    "    print(key)\n",
    "\n",
    "print(d[\"kwargs\"][\"parent_recording\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf455d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not reAnalyse:\n",
    "    if os.path.isdir(sorterFolder):\n",
    "        # directory exists\n",
    "        print(f\"the previous folder {sorterFolder} was found, importing the data\")\n",
    "        sorting = si.read_sorter_folder(sorterFolder)\n",
    "        display(sorting)\n",
    "    else:\n",
    "        print(f\"the folder {sorterFolder} does not exist ; make sure of the path or reAnalyse the data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ff5c7",
   "metadata": {},
   "source": [
    "## Cure the clusters\n",
    "Here you should ensure that you are happy with the clusters that were found. For that, you should first compute analysis for the training clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037ccfe",
   "metadata": {},
   "source": [
    "### Fast initial curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66cebbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>KiloSortSortingExtractor: 88 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
       " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
       " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> phy_folder </strong>: /home/audrey.hay/HayLabAnalysis/python/kilosort4_output/sorter_output</li><li> <strong> __sorting_info__ </strong>: {'recording': None, 'params': {'sorter_name': 'kilosort4', 'sorter_params': {'batch_size': 60000, 'nblocks': 1, 'Th_universal': 9, 'Th_learned': 8, 'do_CAR': True, 'invert_sign': False, 'nt': 61, 'shift': None, 'scale': None, 'artifact_threshold': None, 'nskip': 25, 'whitening_range': 32, 'highpass_cutoff': 300, 'binning_depth': 5, 'sig_interp': 20, 'drift_smoothing': [0.5, 0.5, 0.5], 'nt0min': None, 'dmin': None, 'dminx': 32, 'min_template_size': 10, 'template_sizes': 5, 'nearest_chans': 10, 'nearest_templates': 100, 'max_channel_distance': None, 'templates_from_data': True, 'n_templates': 6, 'n_pcs': 6, 'Th_single_ch': 6, 'acg_threshold': 0.2, 'ccg_threshold': 0.25, 'cluster_downsampling': 20, 'cluster_pcs': 64, 'x_centers': None, 'duplicate_spike_ms': 0.25, 'scaleproc': None, 'save_preprocessed_copy': False, 'torch_device': 'auto', 'bad_channels': None, 'clear_cache': False, 'save_extra_vars': False, 'do_correction': False, 'keep_good_only': False, 'skip_kilosort_preprocessing': True, 'use_binary_file': None, 'delete_recording_dat': True}}, 'log': {'sorter_name': 'kilosort4', 'sorter_version': '4.0.20', 'datetime': '2024-12-03T18:21:14.752324', 'runtime_trace': [], 'error': False, 'run_time': 177.23857660777867}}</li></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul><details><summary><strong>original_cluster_id</strong></summary>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
       " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
       " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87]</details><details><summary><strong>KSLabel</strong></summary>['mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'good' 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua']</details><details><summary><strong>Amplitude</strong></summary>[11.4 13.8 14.  14.  24.  15.8 12.7 10.9 23.6 10.5 14.9 10.3 12.3 11.7\n",
       " 13.9 13.4 24.6 18.9 12.8 23.1 15.  11.  19.  15.6 11.6  9.5 14.4 13.4\n",
       " 11.6 10.1 11.5 11.4 10.9 32.7 15.6 13.5 12.3 12.1 10.8  9.6  9.1  9.5\n",
       "  9.7  9.4  9.6 11.4 10.5 11.4 20.  17.6 17.5 23.1 10.4 10.9  9.3  9.\n",
       " 10.1 11.1 10.7 13.7  8.7  9.7  8.5 10.3  9.7 12.  10.2 17.5 10.6 11.2\n",
       " 16.7  9.1 10.5 10.3 10.5 12.4 13.7  6.7 10.3 10.5  9.1 11.7 12.3  9.\n",
       " 10.   9.4 11.8 12.2]</details><details><summary><strong>ContamPct</strong></summary>[ 89.4  92.1  52.5  73.2  93.8  87.2  84.7 105.8  10.6  81.1 205.2  91.7\n",
       "  89.  116.6   0.   56.4  47.6  31.7  48.   80.8  73.1  91.4  77.2  78.1\n",
       " 146.5   0.    0.    0.    0.  125.3 156.9 163.   98.2   0.   54.2  68.5\n",
       " 124.7  10.8   0.    0.    0.    0.  125.  100.  102.6  14.1  34.5  94.3\n",
       " 116.7 100.   85.4  44.2  97.3 101.9  97.4   0.    0.    0.    0.    0.\n",
       "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
       "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
       "   0.    0.   98.1   0. ]</details><details><summary><strong>KSLabel_repeat</strong></summary>['mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'good' 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua']</details></ul></details>"
      ],
      "text/plain": [
       "KiloSortSortingExtractor: 88 units - 1 segments - 30.0kHz"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>RemoveDuplicatedSpikesSorting: 88 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
       " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
       " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> phy_folder </strong>: /home/audrey.hay/HayLabAnalysis/python/kilosort4_output/sorter_output</li><li> <strong> __sorting_info__ </strong>: {'recording': None, 'params': {'sorter_name': 'kilosort4', 'sorter_params': {'batch_size': 60000, 'nblocks': 1, 'Th_universal': 9, 'Th_learned': 8, 'do_CAR': True, 'invert_sign': False, 'nt': 61, 'shift': None, 'scale': None, 'artifact_threshold': None, 'nskip': 25, 'whitening_range': 32, 'highpass_cutoff': 300, 'binning_depth': 5, 'sig_interp': 20, 'drift_smoothing': [0.5, 0.5, 0.5], 'nt0min': None, 'dmin': None, 'dminx': 32, 'min_template_size': 10, 'template_sizes': 5, 'nearest_chans': 10, 'nearest_templates': 100, 'max_channel_distance': None, 'templates_from_data': True, 'n_templates': 6, 'n_pcs': 6, 'Th_single_ch': 6, 'acg_threshold': 0.2, 'ccg_threshold': 0.25, 'cluster_downsampling': 20, 'cluster_pcs': 64, 'x_centers': None, 'duplicate_spike_ms': 0.25, 'scaleproc': None, 'save_preprocessed_copy': False, 'torch_device': 'auto', 'bad_channels': None, 'clear_cache': False, 'save_extra_vars': False, 'do_correction': False, 'keep_good_only': False, 'skip_kilosort_preprocessing': True, 'use_binary_file': None, 'delete_recording_dat': True}}, 'log': {'sorter_name': 'kilosort4', 'sorter_version': '4.0.20', 'datetime': '2024-12-03T18:21:14.752324', 'runtime_trace': [], 'error': False, 'run_time': 177.23857660777867}}</li></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul><details><summary><strong>original_cluster_id</strong></summary>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
       " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
       " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87]</details><details><summary><strong>KSLabel</strong></summary>['mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'good' 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua']</details><details><summary><strong>Amplitude</strong></summary>[11.4 13.8 14.  14.  24.  15.8 12.7 10.9 23.6 10.5 14.9 10.3 12.3 11.7\n",
       " 13.9 13.4 24.6 18.9 12.8 23.1 15.  11.  19.  15.6 11.6  9.5 14.4 13.4\n",
       " 11.6 10.1 11.5 11.4 10.9 32.7 15.6 13.5 12.3 12.1 10.8  9.6  9.1  9.5\n",
       "  9.7  9.4  9.6 11.4 10.5 11.4 20.  17.6 17.5 23.1 10.4 10.9  9.3  9.\n",
       " 10.1 11.1 10.7 13.7  8.7  9.7  8.5 10.3  9.7 12.  10.2 17.5 10.6 11.2\n",
       " 16.7  9.1 10.5 10.3 10.5 12.4 13.7  6.7 10.3 10.5  9.1 11.7 12.3  9.\n",
       " 10.   9.4 11.8 12.2]</details><details><summary><strong>ContamPct</strong></summary>[ 89.4  92.1  52.5  73.2  93.8  87.2  84.7 105.8  10.6  81.1 205.2  91.7\n",
       "  89.  116.6   0.   56.4  47.6  31.7  48.   80.8  73.1  91.4  77.2  78.1\n",
       " 146.5   0.    0.    0.    0.  125.3 156.9 163.   98.2   0.   54.2  68.5\n",
       " 124.7  10.8   0.    0.    0.    0.  125.  100.  102.6  14.1  34.5  94.3\n",
       " 116.7 100.   85.4  44.2  97.3 101.9  97.4   0.    0.    0.    0.    0.\n",
       "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
       "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
       "   0.    0.   98.1   0. ]</details><details><summary><strong>KSLabel_repeat</strong></summary>['mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'good' 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua']</details></ul></details>"
      ],
      "text/plain": [
       "RemoveDuplicatedSpikesSorting: 88 units - 1 segments - 30.0kHz"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sorting)\n",
    "sorting = si.remove_duplicated_spikes(sorting=sorting)\n",
    "sorting = si.remove_excess_spikes(sorting=sorting, recording=recording_corrected)\n",
    "#Est-ce qu'on veut aussi remove_redundant_units?\n",
    "display(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfff988",
   "metadata": {},
   "source": [
    "### Construct analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9f54b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1552e16de084309ae9918483382f7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "estimate_sparsity:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e069c9ae6ab740edb7429a276761be50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "compute_waveforms:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea1abe961bf48ada759502c08f7d645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting PCA:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9d490df15a4965941596d5f52f0cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Projecting waveforms:   0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a926cf71f0421ca75d5e56fedcd060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spike_amplitudes:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Folder already exists sorting_analyzer_training",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m sorting_analyzer_training \u001b[38;5;241m=\u001b[39m compute_analyzer(sorting, rec_training, probe, training_folder) \u001b[38;5;66;03m#, append=True) # uncomment to redo only a few analysis\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43msorting_analyzer_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary_folder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m display(sorting_analyzer_training)\n",
      "File \u001b[0;32m~/HayLabAnalysis/.si-env/lib/python3.11/site-packages/spikeinterface/core/sortinganalyzer.py:976\u001b[0m, in \u001b[0;36mSortingAnalyzer.save_as\u001b[0;34m(self, format, folder, backend_options)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzarr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    975\u001b[0m     folder \u001b[38;5;241m=\u001b[39m clean_zarr_folder_name(folder)\n\u001b[0;32m--> 976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_or_select_or_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HayLabAnalysis/.si-env/lib/python3.11/site-packages/spikeinterface/core/sortinganalyzer.py:894\u001b[0m, in \u001b[0;36mSortingAnalyzer._save_or_select_or_merge\u001b[0;34m(self, format, folder, unit_ids, merge_unit_groups, censor_ms, merging_mode, sparsity_overlap, verbose, new_unit_ids, backend_options, **job_kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor format=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_folder\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m folder must be provided\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m     folder \u001b[38;5;241m=\u001b[39m Path(folder)\n\u001b[0;32m--> 894\u001b[0m     new_sorting_analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mSortingAnalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_binary_folder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43msorting_provenance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparsity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzarr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor format=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzarr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m folder must be provided\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/HayLabAnalysis/.si-env/lib/python3.11/site-packages/spikeinterface/core/sortinganalyzer.py:415\u001b[0m, in \u001b[0;36mSortingAnalyzer.create_binary_folder\u001b[0;34m(cls, folder, sorting, recording, sparsity, return_scaled, rec_attributes, backend_options)\u001b[0m\n\u001b[1;32m    413\u001b[0m folder \u001b[38;5;241m=\u001b[39m Path(folder)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m folder\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFolder already exists \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    416\u001b[0m folder\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    418\u001b[0m info_file \u001b[38;5;241m=\u001b[39m folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspikeinterface_info.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Folder already exists sorting_analyzer_training"
     ]
    }
   ],
   "source": [
    "if reAnalyse and True: #engine is None:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    sorting_analyzer_training = compute_analyzer(sorting, rec_training, probe, training_folder) #, append=True) # uncomment to redo only a few analysis\n",
    "\n",
    "    sorting_analyzer_training.save_as(folder=training_folder, format='binary_folder')\n",
    "    display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_available=False\n",
    "if False: #reAnalyse and engine==\"dask\":\n",
    "    #gc.collect()\n",
    "    \n",
    "    if GPU_available: # takes about 1.5 minutes with dask\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"70GB\",\n",
    "                        job_cpu=70,\n",
    "                        walltime=\"01:20:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gres=gpu:1g.20gb:1'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 1.5 min\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"60GB\",\n",
    "                        job_cpu=40,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(compute_analyzer, sorting, rec_training, probe, training_folder) #, append=True) # uncomment to redo only a few analysis\n",
    "    sorting_analyzer_training = future.result()\n",
    "\n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    #sorting_analyzer_training = si.load_sorting_analyzer(training_folder)\n",
    "    display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4112693",
   "metadata": {},
   "source": [
    "Now, you have 2 options:\n",
    "- Either go back to local computer for full benefice of spikeinterface_gui\n",
    "1. First, copy the sorting_analyzer_training folder to crnldata ([see next cell](#download))\n",
    "1. Then, go on a local (not over ssh) script at [the most interactive viewing part](#local) at the end of this notebook, reload the sorting_analyzer older, and visualize everything on a gui.\n",
    "1. Finally, when you are happy with the spike clusters, you can upload it back to the crnl cluster to proceed with [full sorting](#sort-full-recording)\n",
    "- Or use [the following embedded plotting widgets](#widgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efe0c4",
   "metadata": {},
   "source": [
    "### Option1: go back to local PC\n",
    "<a id='download'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec648099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/audrey.hay/HayLabAnalysis/.si-env/lib/python3.11/site-packages/distributed/node.py:187: UserWarning: Port 8780 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 43943 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/crnldata/waking'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     23\u001b[0m future \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39msubmit(shutil\u001b[38;5;241m.\u001b[39mcopytree, src, dst) \n\u001b[0;32m---> 24\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob done in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Close cluster\u001b[39;00m\n",
      "File \u001b[0;32m~/HayLabAnalysis/.si-env/lib/python3.11/site-packages/distributed/client.py:402\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_initialized()\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/shutil.py:561\u001b[0m, in \u001b[0;36mcopytree\u001b[0;34m()\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(src) \u001b[38;5;28;01mas\u001b[39;00m itr:\n\u001b[1;32m    560\u001b[0m     entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itr)\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _copytree(entries\u001b[38;5;241m=\u001b[39mentries, src\u001b[38;5;241m=\u001b[39msrc, dst\u001b[38;5;241m=\u001b[39mdst, symlinks\u001b[38;5;241m=\u001b[39msymlinks,\n\u001b[1;32m    562\u001b[0m                  ignore\u001b[38;5;241m=\u001b[39mignore, copy_function\u001b[38;5;241m=\u001b[39mcopy_function,\n\u001b[1;32m    563\u001b[0m                  ignore_dangling_symlinks\u001b[38;5;241m=\u001b[39mignore_dangling_symlinks,\n\u001b[1;32m    564\u001b[0m                  dirs_exist_ok\u001b[38;5;241m=\u001b[39mdirs_exist_ok)\n",
      "File \u001b[0;32m/usr/lib/python3.11/shutil.py:459\u001b[0m, in \u001b[0;36m_copytree\u001b[0;34m()\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     ignored_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 459\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(dst, exist_ok\u001b[38;5;241m=\u001b[39mdirs_exist_ok)\n\u001b[1;32m    460\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    461\u001b[0m use_srcentry \u001b[38;5;241m=\u001b[39m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy2 \u001b[38;5;129;01mor\u001b[39;00m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m()\u001b[0m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/crnldata/waking'"
     ]
    }
   ],
   "source": [
    "# copy initial sorting to crnldata for viewing\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    src=training_folder\n",
    "    currentFile_data = magicretrieve('currentFile_data')\n",
    "    dst=os.path.join(os.path.split(currentFile_data)[0],src)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cf3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/audrey.hay/HayLabAnalysis/python/sorting_analyzer_training\n",
    "cd /\n",
    "cd /mnt/data/ahay/\n",
    "cd /crnldata/forgetting/Aurelie/Annie/tests_analyses_annie/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806a8ac",
   "metadata": {},
   "source": [
    "Commandes pour copier des dossiers\n",
    "\n",
    "cp -r /home/audrey.hay/HayLabAnalysis/python/kilosort4_output /crnldata/forgetting/Aurelie/Annie/tests_analyses_annie/\n",
    "\n",
    "cp -r /home/audrey.hay/HayLabAnalysis/python/sorting_analyzer_training /crnldata/forgetting/Aurelie/Annie/tests_analyses_annie/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dbada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy initial sorting to crnldata for viewing\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    src=training_folder\n",
    "    currentFile_data = '//10.69.168.1/crnldata/waking/audrey_hay/NPX/tests_analyses_annie/'\n",
    "    dst=os.path.join(os.path.split(currentFile_data)[0],src)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a0cdd",
   "metadata": {},
   "source": [
    "**Here is when you should work locally**\n",
    "and do the last part\n",
    "\n",
    "... and then come back on ssh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ce41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import back sorting_analyzer\n",
    "# reAnalyse = True\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    dst=training_folder\n",
    "    currentFile_data = magicretrieve('currentFile_data')\n",
    "    src=os.path.join(os.path.split(currentFile_data)[0],dst)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2477c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae12783",
   "metadata": {},
   "source": [
    "### Option2: inline visualisation\n",
    "<a id='widgets'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3241794",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_analyzer_training = si.load_sorting_analyzer(training_folder)\n",
    "display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few ids (unités)\n",
    "#unit_ids=[1, 2, 5]\n",
    "unit_ids=sorting_analyzer_training.unit_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_unit_templates(sorting_analyzer_training, unit_ids=unit_ids, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97227a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few ids\n",
    "unit_ids=[1, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14860987",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_rasters(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    si.plot_isi_distribution(sorting_analyzer_training,unit_ids=unit_ids)\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_autocorrelograms(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389668da",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_crosscorrelograms(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c822e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_unit_presence(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ca0a6",
   "metadata": {},
   "source": [
    "## Sort full recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine==\"dask\":\n",
    "    gc.collect()\n",
    "    \n",
    "    if GPU_available: # takes about 10 minutes with dask\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"70GB\",\n",
    "                        job_cpu=70,\n",
    "                        walltime=\"20:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gpus=2'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 10 minutes\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"6GB\",\n",
    "                        job_cpu=55,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(compute_analyzer, sorting, recording_corrected, probe, fullAnalyzer_folder)\n",
    "    future.result()\n",
    "    #sorting_analyzer_training = future.results() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    #display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "    future = client.submit(GenerateDict, rec_training, probe, sorterFolder, **sorter_params)\n",
    "    sorting = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adef6f8-a103-40aa-a640-8ad538b056ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine=='submitit':\n",
    "    start_time = time.time()\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    #executor.update_parameters(slurm_array_parallelism=2, mem_gb=30, timeout_min=10, slurm_partition=\"CPU\", cpus_per_task=50)\n",
    "    executor.update_parameters(mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70) #cpus_per_task\n",
    "\n",
    "    # actually submit the job\n",
    "    job = executor.submit(compute_analyzer, sorting, recording_corrected, probe, fullAnalyzer_folder)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a42b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#job 34074 completed in 408.1813361644745 second (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34078 completed in 437.409494638443 seconds (slurm_array_parallelism=3, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34081 completed in 423.37460565567017 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", slurm_gres=\"gpu:2\", cpus_per_task=50)\n",
    "#job 34085 completed in 367.0000305175781 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "#job 34089 completed in 370.1982145309448 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=80)\n",
    "#job 34093 completed in 355.1876621246338 seconds (mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "\n",
    "last_job = job\n",
    "checkRessources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not reAnalyse:\n",
    "    print(\"not running analysis but loading previous one\")\n",
    "    sorting_analyzer = si.load_sorting_analyzer(fullAnalyzer_folder)\n",
    "    display(sorting_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.export_report(sorting_analyzer=sorting_analyzer,output_folder='report')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2da484",
   "metadata": {},
   "source": [
    "# Most interactive viewing on local\n",
    "<a id='local'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes 13s\n",
    "#from IPython.display import Javascript\n",
    "#Javascript(\"Jupyter.notebook.execute_cell_range(0,15)\")\n",
    "#TODO: here should find a way to execute previous cell, or have the function in a loadable module.\n",
    "currentFile_data = magicretrieve('currentFile_data')\n",
    "print(currentFile_data)\n",
    "sorting_analyzer_training = si.load_sorting_analyzer(os.path.join('//10.69.168.1',os.path.split(currentFile_data)[0],training_folder))\n",
    "display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061be488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "si.plot_sorting_summary(sorting_analyzer_training, backend=\"spikeinterface_gui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d554903",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFile_data = magicretrieve('currentFile_data', storePath='')\n",
    "print(currentFile_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".si-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
