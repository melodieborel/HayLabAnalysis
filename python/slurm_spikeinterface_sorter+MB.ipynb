{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7dda0d",
   "metadata": {},
   "source": [
    "# Spike sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4cdd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reAnalyse = True\n",
    "engine = \"dask\" #\"dask\", \"submitit\", or None\n",
    "GPU_available = False\n",
    "preprocessed_folder = 'preprocessing'\n",
    "sorter_folder='kilosort4_output_MB'\n",
    "training_folder = 'sorting_analyzer_training'\n",
    "fullAnalyzer_folder = 'sorting_analyzer_full'\n",
    "whitenFirst = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd66156",
   "metadata": {},
   "source": [
    "## Set up everything\n",
    "You shouldn't have to change anything from here so you can keep that part folded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b006d50",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4c2661-565d-4949-aa45-d44200c20f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "from spikeinterface.sortingcomponents.motion import estimate_motion, interpolate_motion\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import submitit\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import asyncio\n",
    "import gc\n",
    "\n",
    "#import mbTools\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython import get_ipython\n",
    "import IPython\n",
    "from IPython.display import Javascript\n",
    "import pickleshare\n",
    "\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e190a",
   "metadata": {},
   "source": [
    "### Define a few variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0cf29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_extract = 1 #min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac2f4e",
   "metadata": {},
   "source": [
    "#### Structural (important for the process but no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e310982",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_job=None\n",
    "sorter='kilosort4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ed711",
   "metadata": {},
   "source": [
    "### Define a few functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a4a6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magicretrieve(stored_var):\n",
    "   # myvar will contain the variable previously stored with \"%store test\"\n",
    "   myvar_filename = get_ipython().ipython_dir + '/profile_default/db/autorestore/' + stored_var\n",
    "   with open(myvar_filename, 'rb') as f:\n",
    "      return pickle.load(f)\n",
    "\n",
    "def magicstore(stored_var, value):\n",
    "   # myvar will contain the variable previously stored with \"%store test\"\n",
    "   myvar_filename = get_ipython().ipython_dir + '/profile_default/db/autorestore/' + stored_var\n",
    "   with open(myvar_filename, 'wb') as f:\n",
    "      pickle.dump(value,f)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bbf1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_my_expe_choice(chooser):\n",
    "    currentFile_data = str(chooser.selected)\n",
    "    currentFile_mnt = os.path.join('/mnt/data/ahay',os.path.split(currentFile_data)[1])\n",
    "    if not currentFile_data.startswith('/crnldata/'):\n",
    "        print('please make sure to select the file on crnldata')\n",
    "        return\n",
    "    # check if the file already exists on /mnt/\n",
    "    if os.path.isfile(currentFile_mnt):\n",
    "        print(f\"{currentFile_mnt} already exists\")\n",
    "    else:\n",
    "        print(f\"there is no version of {currentFile_data} on /mnt/\")\n",
    "        shouldCopy = False # it took a while (20 min for a file of about 150Gb)\n",
    "        if shouldCopy:\n",
    "            print(f'it will be copied to {currentFile_mnt}')\n",
    "            startTime = time.time()\n",
    "            shutil.copyfile(currentFile_data, currentFile_mnt)\n",
    "            print(f'the transfer is complete, it took {time.time()-startTime} seconds')\n",
    "        else:\n",
    "            print('it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources')\n",
    "\n",
    "    magicstore('currentFile_data', currentFile_data)\n",
    "    magicstore('currentFile_mnt', currentFile_mnt)\n",
    "\n",
    "\n",
    "def selectData(currentFile):\n",
    "    print(currentFile)\n",
    "    if currentFile is not None:\n",
    "        pathName, fileName = os.path.split(currentFile)\n",
    "    else:\n",
    "        pathName = '/crnldata/waking/audrey_hay/'\n",
    "        fileName = ''\n",
    "    fc = FileChooser(path=pathName, filename=fileName, filter_pattern='NP_spikes_*.raw', select_default=True, show_only_dirs = False, title = \"<b>Select file on crnldata</b>\")\n",
    "    display(fc)\n",
    "\n",
    "    # Register callback function\n",
    "    fc.register_callback(update_my_expe_choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4a6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def runFunction(engine,funcName,*params,**engineParams):\n",
    "    start_time = time.time()\n",
    "    match engine:\n",
    "        case \"dask\":\n",
    "            print(\"dask\")\n",
    "            cluster = SLURMCluster(\n",
    "                                **engineParams,\n",
    "                                nanny=False,\n",
    "                                log_directory=\"si_dask_logs\",\n",
    "                                scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                                )\n",
    "            cluster.scale(1)\n",
    "            client = Client(cluster)\n",
    "\n",
    "            print(client.get_versions(check=True))\n",
    "    \n",
    "            \"\"\"\n",
    "            from dask.distributed import PipInstall\n",
    "            plugin = PipInstall(packages=[\"git+https://github.com/SpikeInterface/spikeinterface.git\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            plugin = PipInstall(packages=[\"git+https://github.com/SpikeInterface/probeinterface.git\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            plugin = PipInstall(packages=[\"git+https://github.com/SpikeInterface/spikeinterface-gui.git\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            plugin = PipInstall(packages=[\"kilosort\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "\n",
    "            plugin = PipInstall(packages=[\"numpy\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            \"\"\"\n",
    "            \n",
    "            print(cluster.job_script()) \n",
    "\n",
    "            future = client.submit(funcName, *params)\n",
    "            res = future.result()\n",
    "                        \n",
    "            # Close cluster\n",
    "            client.close()\n",
    "            cluster.close()\n",
    "\n",
    "        \n",
    "        case \"submitit\":\n",
    "            print(\"submitit\")\n",
    "\n",
    "            executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "            executor.update_parameters(**engineParams)\n",
    "\n",
    "            job = executor.submit(funcName, *params)\n",
    "\n",
    "            # print the ID of your job\n",
    "            print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "            # await a single result\n",
    "            await job.awaitable().results()\n",
    "            res = job.result()\n",
    "\n",
    "        case _:\n",
    "            print(\"no engine\")\n",
    "            res = funcName(*params) \n",
    "            \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b539b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateDict(rec, probe, folder, **sorter_params):\n",
    "    rec = rec.set_probe(probe)\n",
    "    si.set_global_job_kwargs(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    sorting = si.run_sorter(sorter, rec, verbose=True, folder=folder, remove_existing_folder=True, **sorter_params)\n",
    "    return sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484a0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_analyzer(sorting,rec,probe,folder,append=False):\n",
    "\n",
    "    rec = rec.set_probe(probe)\n",
    "    si.set_global_job_kwargs(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    \n",
    "    if append:\n",
    "        sorting_analyzer = si.load_sorting_analyzer(folder)\n",
    "    else:\n",
    "        sorting_analyzer = si.create_sorting_analyzer(sorting, rec, sparse=True, folder=folder,overwrite=True)\n",
    "\n",
    "    sorting_analyzer.compute(\"random_spikes\", method=\"uniform\", max_spikes_per_unit=500)\n",
    "    sorting_analyzer.compute(\"waveforms\")\n",
    "    sorting_analyzer.compute(\"templates\")\n",
    "    sorting_analyzer.compute(\"noise_levels\")\n",
    "    sorting_analyzer.compute(\"unit_locations\", method=\"monopolar_triangulation\")\n",
    "    sorting_analyzer.compute(\"isi_histograms\")\n",
    "    sorting_analyzer.compute(\"correlograms\") #, window_ms=100, bin_ms=5.\n",
    "    sorting_analyzer.compute(\"principal_components\", n_components=3, mode='by_channel_global', whiten=True)\n",
    "    sorting_analyzer.compute(\"quality_metrics\", metric_names=[\"snr\", \"firing_rate\"])\n",
    "    sorting_analyzer.compute(\"template_similarity\")\n",
    "    sorting_analyzer.compute(\"spike_amplitudes\")\n",
    "\n",
    "    #print(folder)\n",
    "    #print(sorting_analyzer)\n",
    "    #sorting_analyzer.save_as(folder=folder, format='zarr')\n",
    "    #print(sorting_analyzer)\n",
    "\n",
    "    return sorting_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "017793bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_traces(rec):\n",
    "    # filter traces\n",
    "    rec = rec.astype('float32')\n",
    "    print(\"filtering trace, please wait\")\n",
    "    rec_filt = si.bandpass_filter(rec)\n",
    "    display(rec_filt)\n",
    "\n",
    "    # Account for the slight delays in recordings due to the fact the 384 channels are only digitilized with 32 ADCs\n",
    "    print(\"aligning trace, please wait\")\n",
    "    isi=0.076923077\n",
    "    inter_sample_shift = np.arange(12)*isi\n",
    "    inter_sample_shift = np.expand_dims(np.repeat(inter_sample_shift,2),0)\n",
    "    inter_sample_shift = np.repeat(inter_sample_shift,16,0).flatten()\n",
    "    rec_filt_shifted = si.phase_shift(rec_filt, inter_sample_shift=inter_sample_shift)\n",
    "    \n",
    "    # Remove bad channels\n",
    "    print(\"removing bad channels, please wait\")\n",
    "    try:\n",
    "        bad_channel_ids, channel_labels = si.detect_bad_channels(rec_filt_shifted)\n",
    "        print('bad_channel_ids', bad_channel_ids)\n",
    "        rec = rec.remove_channels(bad_channel_ids)\n",
    "        rec_filt = rec_filt.remove_channels(bad_channel_ids)\n",
    "        rec_filt_shifted = rec_filt_shifted.remove_channels(bad_channel_ids)\n",
    "    except Exception as error:\n",
    "        print(\"could not remove bad channels because there was an error:\")\n",
    "        print(error)\n",
    "\n",
    "\n",
    "    # Remove the common noisy events (artefacts)\n",
    "    print(\"remove commonn ref, please wait\")\n",
    "    rec_filt_ref = si.common_reference(rec_filt_shifted)\n",
    "    display(rec_filt_ref)\n",
    "\n",
    "    recording_layers = dict(\n",
    "        raw = rec,\n",
    "        filter = rec_filt,\n",
    "        realigned = rec_filt_shifted,\n",
    "        cmr = rec_filt_ref,\n",
    "    )\n",
    "\n",
    "    return recording_layers, bad_channel_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a63688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_drift(rec, probe):      \n",
    "    #rec = rec.set_probe(probe)\n",
    "\n",
    "    job_kwargs_global = dict(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    si.set_global_job_kwargs(**job_kwargs_global)\n",
    "    \n",
    "    recording_corrected, motion, motion_info = si.correct_motion(\n",
    "            rec, preset=\"dredge_fast\", folder=None, output_motion=True, output_motion_info=True, estimate_motion_kwargs=dict(rigid=True)#,\n",
    "        )\n",
    "    return recording_corrected, motion, motion_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d616f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiten(rec,recording_layers,layerName):\n",
    "\n",
    "    rec_whitened = si.WhitenRecording(rec)\n",
    "\n",
    "    recording_layers[layerName] = rec_whitened\n",
    "\n",
    "    return recording_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e05baf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessing(rec,foldername):\n",
    "    return rec.save(folder=foldername, n_jobs=20, chunk_duration='1s', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339081a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRessources():\n",
    "    # check node and CPU information\n",
    "    print(\"### Node counts: \\nA: currently in use \\B available\")\n",
    "    !sinfo -o%A\n",
    "    print(\"### CPU counts: \\nA: core currently in use \\nI: available \\nO: unavailable (maintenance, down, etc) \\nT: total\")\n",
    "    !sinfo -o%C\n",
    "    !sinfo\n",
    "\n",
    "    # check some stats of our last job\n",
    "    if last_job is not None:\n",
    "        print('### CPU time and MaxRSS of our last job (about 1000Mb should be added to your MaxRSS (Mb) in order to cover safely the memory needs of the python runtime)###')\n",
    "        os.system(f'sacct -j {last_job.job_id} --format=\"CPUTime,MaxRSS\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a24596",
   "metadata": {},
   "source": [
    "## Choose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c6dc444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16/NP_spikes_2024-07-22T17_55_16.raw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceae3d3226f944cc881211d80b45c5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16', filename='NP_spikes_2024-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#currentFile_data = '/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16/NP_spikes_2024-07-22T17_55_16.raw'\n",
    "#mbTools.magicstore('currentFile_data', currentFile_data)\n",
    "currentFile_data = magicretrieve('currentFile_data')\n",
    "selectData(currentFile_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8669ae",
   "metadata": {},
   "source": [
    "### Move data to /mnt/ if appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbf2a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shouldCopy = False # it took a while (20 min for a file of about 150Gb)\n",
    "if shouldCopy:\n",
    "    currentFile_data = magicretrieve('currentFile_data')\n",
    "    currentFile_mnt = magicretrieve('currentFile_mnt')\n",
    "    print(f'The file {currentFile_data} will be copied to {currentFile_mnt}')\n",
    "    startTime = time.time()\n",
    "    shutil.copyfile(currentFile_data, currentFile_mnt)\n",
    "    print(f'the transfer is complete, it took {time.time()-startTime} seconds')\n",
    "else:\n",
    "    print('it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532274e",
   "metadata": {},
   "source": [
    "### Lazy load data and probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8606c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFile_data = magicretrieve('currentFile_data')\n",
    "currentFile_mnt = magicretrieve('currentFile_mnt')\n",
    "\n",
    "raw_rec = si.read_binary(currentFile_mnt, dtype='uint16', num_channels=384, sampling_frequency=30_000.,gain_to_uV=1, offset_to_uV=0)\n",
    "raw_rec.annotate(raw_path = currentFile_data)\n",
    "raw_rec = si.ScaleRecording(raw_rec, gain=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb3d0a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spikeinterface.widgets.probe_map.ProbeMapWidget at 0x7f0822673bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8a9eeb1c1d40c9a14e503a5836a876",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('/crnldata/waking/audrey_hay/NPX/NPXprobe.pkl', 'rb') as outp: \n",
    "    probe = pickle.load(outp)\n",
    "probe.set_device_channel_indices(np.arange(384))\n",
    "\n",
    "raw_rec = raw_rec.set_probe(probe)\n",
    "display(si.plot_probe_map(raw_rec, with_channel_ids=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a43680",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c250e0",
   "metadata": {},
   "source": [
    "### Filter and apply common ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29d4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/audrey.hay/HayLabAnalysis/.si-env/lib/python3.11/site-packages/distributed/node.py:187: UserWarning: Port 8780 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 34723 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scheduler': {'host': {'python': '3.11.2.final.0', 'python-bits': 64, 'OS': 'Linux', 'OS-release': '6.1.0-22-amd64', 'machine': 'x86_64', 'processor': '', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'fr_FR.UTF-8'}, 'packages': {'python': '3.11.2.final.0', 'dask': '2024.11.2', 'distributed': '2024.11.2', 'msgpack': '1.1.0', 'cloudpickle': '3.0.0', 'tornado': '6.4.1', 'toolz': '0.12.1', 'numpy': '1.26.3', 'pandas': '2.2.2', 'lz4': None}}, 'workers': {}, 'client': {'host': {'python': '3.11.2.final.0', 'python-bits': 64, 'OS': 'Linux', 'OS-release': '6.1.0-22-amd64', 'machine': 'x86_64', 'processor': '', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'fr_FR.UTF-8'}, 'packages': {'python': '3.11.2.final.0', 'dask': '2024.11.2', 'distributed': '2024.11.2', 'msgpack': '1.1.0', 'cloudpickle': '3.0.0', 'tornado': '6.4.1', 'toolz': '0.12.1', 'numpy': '1.26.3', 'pandas': '2.2.2', 'lz4': None}}}\n",
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e si_dask_logs/dask-worker-%J.err\n",
      "#SBATCH -o si_dask_logs/dask-worker-%J.out\n",
      "#SBATCH -p CPU\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=1\n",
      "#SBATCH --mem=3G\n",
      "#SBATCH -t 00:30:00\n",
      "\n",
      "/home/audrey.hay/HayLabAnalysis/.si-env/bin/python -m distributed.cli.dask_worker tcp://10.69.168.93:40171 --name dummy-name --nthreads 1 --memory-limit 2.79GiB --no-nanny --death-timeout 60 --lifetime 2m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if reAnalyse:\n",
    "    match engine,GPU_available:\n",
    "        case \"dask\", _: # no real interest in using gpu\n",
    "            engineParam=dict(\n",
    "                                queue='CPU',\n",
    "                                cores=1,\n",
    "                                memory=\"3GB\",\n",
    "                                worker_extra_args=[\"--lifetime\", \"2m\"],\n",
    "            )\n",
    "        case \"submitit\", _:\n",
    "            engineParam=dict(\n",
    "                                mem_gb=3,\n",
    "                                timeout_min=2,\n",
    "                                slurm_partition=\"CPU\",\n",
    "                                cpus_per_task=4\n",
    "            )\n",
    "        case _:\n",
    "            engineParam = dict()\n",
    "\n",
    "    recording_layers, bad_channel_ids  = await runFunction(engine, preprocess_traces, raw_rec, **engineParam)\n",
    "    \n",
    "    print(\"computing done, please wait for display\")\n",
    "    si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637e35e",
   "metadata": {},
   "source": [
    "### Correct for motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348fd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitenFirst = True\n",
    "canal_lim=300 #limitation of canals to keep for drift correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb7e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    probe_good = probe.get_slice(recording_layers[\"raw\"].get_channel_ids())\n",
    "    probe_2_correct = probe.get_slice([i for i in recording_layers[\"raw\"].get_channel_ids() if i < canal_lim])\n",
    "\n",
    "    if whitenFirst:\n",
    "        recording_layers = whiten(recording_layers[\"cmr\"],recording_layers,\"whitenFirst\")\n",
    "        rec_2_correct = recording_layers[\"whitenFirst\"]\n",
    "    else:\n",
    "        rec_2_correct = recording_layers[\"cmr\"]\n",
    "\n",
    "    rec_2_correct_short = rec_2_correct.channel_slice(probe_2_correct.device_channel_indices)\n",
    "    display(rec_2_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef37904",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    match engine,GPU_available:\n",
    "        case \"dask\", _:\n",
    "            engineParam=dict(\n",
    "                                queue='CPU',\n",
    "                                cores=1,\n",
    "                                memory=\"50GB\",\n",
    "                                job_cpu=55,\n",
    "                                worker_extra_args=[\"--lifetime\", \"20m\"],\n",
    "            )\n",
    "        case \"submitit\", _:\n",
    "            engineParam=dict(\n",
    "                                slurm_array_parallelism=4,\n",
    "                                mem_gb=60,\n",
    "                                timeout_min=20,\n",
    "                                slurm_partition=\"CPU\",\n",
    "                                cpus_per_task=40\n",
    "            )\n",
    "        case _:\n",
    "            engineParam = dict()\n",
    "\n",
    "    recording_corrected_short, motion, motion_info  = await runFunction(engine,check_drift,rec_2_correct_short, probe_2_correct, **engineParam)\n",
    "\n",
    "    recording_corrected = interpolate_motion(\n",
    "                recording=rec_2_correct,\n",
    "                motion=motion_info['motion'],\n",
    "                **motion_info['parameters']['interpolate_motion_kwargs'])\n",
    "    \n",
    "    recording_layers[\"corrected\"] = recording_corrected\n",
    "    display(motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (72) 16 min (slurm_array_parallelism=4, mem_gb=60, timeout_min=20, slurm_partition=\"CPU\", cpus_per_task=40)\n",
    "print(\"\"\"rq: you should avoid submitting multiple small tasks with submitit, which would create many independent jobs\n",
    "      and possibly overload the cluster, while you can do it without any problem through dask.distributed.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7225843",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    si.plot_motion_info(motion_info, recording_corrected,\n",
    "                   color_amplitude=True,\n",
    "        amplitude_cmap=\"inferno\",)\n",
    "except Exception as e:\n",
    "    print(f\"Could not plot motion: {e}. Possibly because you have to redo the analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and not whitenFirst:\n",
    "    recording_layers = whiten(recording_corrected,recording_layers,\"whitenLast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28144436",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'\n",
    "except Exception as e:\n",
    "    print(f\"Could not plot traces: {e}. Possibly because you have to redo the analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_folder=\"prepro2\"\n",
    "if reAnalyse:\n",
    "    if whitenFirst:\n",
    "        rec = recording_layers[\"whitenFirst\"] #if whitened and not corrected\n",
    "        #rec = recording_layers[\"corrected\"] #if whitened then corrected\n",
    "    else:\n",
    "        rec = recording_layers[\"whitenLast\"] #if corrected the whiten\n",
    "        \n",
    "    match engine,GPU_available:\n",
    "        case \"dask\", _: # real interest in using gpu ?\n",
    "            engineParam=dict(\n",
    "                                queue='CPU',\n",
    "                                cores=1,\n",
    "                                memory=\"6GB\",\n",
    "                                job_cpu=20,\n",
    "                                worker_extra_args=[\"--lifetime\", \"1h\"],\n",
    "            )\n",
    "        case \"submitit\", _:\n",
    "            engineParam=dict(\n",
    "                                mem_gb=3,\n",
    "                                timeout_min=60,\n",
    "                                slurm_partition=\"CPU\",\n",
    "                                cpus_per_task=4\n",
    "            )\n",
    "        case _:\n",
    "            engineParam = dict()\n",
    "\n",
    "    recording_saved  = await runFunction(engine, save_preprocessing, rec, preprocessed_folder, **engineParam)    \n",
    "    display(recording_saved)\n",
    "else:\n",
    "    print(f\"Trying to load preprocessed data\")\n",
    "    recording_saved = si.load_extractor(preprocessed_folder)\n",
    "    display(recording_saved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9470dc2",
   "metadata": {},
   "source": [
    "## Identify spike clusters for the first few minutes of recording"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df08855",
   "metadata": {},
   "source": [
    "It is good practice to have a look at available ressources and current use of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkRessources()\n",
    "\n",
    "#!sinfo --nodes=node15 -o \"%50N  %10c  %20m  %30G \"\n",
    "!squeue --partition=\"GPU\"\n",
    "\n",
    "#torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 712.00 MiB. GPU 0 has a total capacity of 79.26 GiB of which 187.19 MiB is free. Process 1619368 has 77.78 GiB memory in use. Including non-PyTorch memory, this process has 1.28 GiB memory in use. Of the allocated memory 529.55 MiB is allocated by PyTorch, and 276.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for information, display a list of all parameters that can be modified for the sorter\n",
    "params = si.get_default_sorter_params(sorter_name_or_class=sorter)\n",
    "print(f\"For information, parameters that are available for the sorter {sorter} are:\\n\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    rec_training = recording_saved.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "    match engine,GPU_available:\n",
    "        case \"dask\", False:\n",
    "            engineParam=dict(\n",
    "                                queue='CPU',\n",
    "                                cores=1,\n",
    "                                memory=\"6GB\",\n",
    "                                job_cpu=55,\n",
    "                                worker_extra_args=[\"--lifetime\", \"2h\"],\n",
    "            )\n",
    "        case \"dask\", True:\n",
    "            engineParam=dict(\n",
    "                                queue='GPU',\n",
    "                                cores=1,\n",
    "                                memory=\"4GB\",\n",
    "                                worker_extra_args=[\"--lifetime\", \"2h\"],\n",
    "                                job_extra_directives=['--gres=gpu:1g.20gb:1'],\n",
    "\n",
    "            )                        \n",
    "        case \"submitit\", False:\n",
    "            engineParam=dict(\n",
    "                                slurm_array_parallelism=4,\n",
    "                                mem_gb=5,\n",
    "                                timeout_min=120,\n",
    "                                slurm_partition=\"CPU\",\n",
    "                                cpus_per_task=60\n",
    "            )\n",
    "        case \"submitit\", True:\n",
    "            engineParam=dict(\n",
    "                                mem_gb=5,\n",
    "                                timeout_min=10,\n",
    "                                slurm_partition=\"GPU\",\n",
    "                                cpus_per_task=2,\n",
    "            )\n",
    "        case _:\n",
    "            engineParam = dict()\n",
    "\n",
    "    sorter_params=dict(\n",
    "        do_correction = False,\n",
    "        skip_kilosort_preprocessing = True # we already did it\n",
    "    )\n",
    "     \n",
    "    sorting = GenerateDict(rec_training, probe, sorter_folder, **sorter_params)\n",
    "\n",
    "    display(sorting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf455d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not reAnalyse:\n",
    "    if os.path.isdir(sorter_folder):\n",
    "        # directory exists\n",
    "        print(f\"the previous folder {sorter_folder} was found, importing the data\")\n",
    "        sorting = si.read_sorter_folder(sorter_folder)\n",
    "        display(sorting)\n",
    "    else:\n",
    "        print(f\"the folder {sorter_folder} does not exist ; make sure of the path or reAnalyse the data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ff5c7",
   "metadata": {},
   "source": [
    "## Cure the clusters\n",
    "Here you should ensure that you are happy with the clusters that were found. For that, you should first compute analysis for the training clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037ccfe",
   "metadata": {},
   "source": [
    "### Fast initial curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cebbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sorting)\n",
    "sorting = si.remove_duplicated_spikes(sorting=sorting)\n",
    "sorting = si.remove_excess_spikes(sorting=sorting, recording=recording_corrected)\n",
    "#Est-ce qu'on veut aussi remove_redundant_units?\n",
    "display(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfff988",
   "metadata": {},
   "source": [
    "### Construct analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f54b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and True: #engine is None:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    sorting_analyzer_training = compute_analyzer(sorting, rec_training, probe, training_folder) #, append=True) # uncomment to redo only a few analysis\n",
    "\n",
    "    sorting_analyzer_training.save_as(folder=training_folder, format='binary_folder')\n",
    "    display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_available=False\n",
    "if False: #reAnalyse and engine==\"dask\":\n",
    "    #gc.collect()\n",
    "    \n",
    "    if GPU_available: # takes about 1.5 minutes with dask\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"70GB\",\n",
    "                        job_cpu=70,\n",
    "                        walltime=\"01:20:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gres=gpu:1g.20gb:1'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 1.5 min\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"60GB\",\n",
    "                        job_cpu=40,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(compute_analyzer, sorting, rec_training, probe, training_folder) #, append=True) # uncomment to redo only a few analysis\n",
    "    sorting_analyzer_training = future.result()\n",
    "\n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    #sorting_analyzer_training = si.load_sorting_analyzer(training_folder)\n",
    "    display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4112693",
   "metadata": {},
   "source": [
    "Now, you have 2 options:\n",
    "- Either go back to local computer for full benefice of spikeinterface_gui\n",
    "1. First, copy the sorting_analyzer_training folder to crnldata ([see next cell](#download))\n",
    "1. Then, go on a local (not over ssh) script at [the most interactive viewing part](#local) at the end of this notebook, reload the sorting_analyzer older, and visualize everything on a gui.\n",
    "1. Finally, when you are happy with the spike clusters, you can upload it back to the crnl cluster to proceed with [full sorting](#sort-full-recording)\n",
    "- Or use [the following embedded plotting widgets](#widgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efe0c4",
   "metadata": {},
   "source": [
    "### Option1: go back to local PC\n",
    "<a id='download'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec648099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy initial sorting to crnldata for viewing\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    src=training_folder\n",
    "    currentFile_data = magicretrieve('currentFile_data')\n",
    "    dst=os.path.join(os.path.split(currentFile_data)[0],src)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cf3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/audrey.hay/HayLabAnalysis/python/sorting_analyzer_training\n",
    "cd /\n",
    "cd /mnt/data/ahay/\n",
    "cd /crnldata/forgetting/Aurelie/Annie/tests_analyses_annie/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806a8ac",
   "metadata": {},
   "source": [
    "Commandes pour copier des dossiers\n",
    "\n",
    "cp -r /home/audrey.hay/HayLabAnalysis/python/kilosort4_output /crnldata/forgetting/Aurelie/Annie/tests_analyses_annie/\n",
    "\n",
    "cp -r /home/audrey.hay/HayLabAnalysis/python/sorting_analyzer_training /crnldata/forgetting/Aurelie/Annie/tests_analyses_annie/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dbada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy initial sorting to crnldata for viewing\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    src=training_folder\n",
    "    currentFile_data = '//10.69.168.1/crnldata/waking/audrey_hay/NPX/tests_analyses_annie/'\n",
    "    dst=os.path.join(os.path.split(currentFile_data)[0],src)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a0cdd",
   "metadata": {},
   "source": [
    "**Here is when you should work locally**\n",
    "and do the last part\n",
    "\n",
    "... and then come back on ssh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ce41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import back sorting_analyzer\n",
    "# reAnalyse = True\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    dst=training_folder\n",
    "    currentFile_data = magicretrieve('currentFile_data')\n",
    "    src=os.path.join(os.path.split(currentFile_data)[0],dst)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2477c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae12783",
   "metadata": {},
   "source": [
    "### Option2: inline visualisation\n",
    "<a id='widgets'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3241794",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_analyzer_training = si.load_sorting_analyzer(training_folder)\n",
    "display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few ids (unités)\n",
    "#unit_ids=[1, 2, 5]\n",
    "unit_ids=sorting_analyzer_training.unit_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_unit_templates(sorting_analyzer_training, unit_ids=unit_ids, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97227a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few ids\n",
    "unit_ids=[1, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14860987",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_rasters(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    si.plot_isi_distribution(sorting_analyzer_training,unit_ids=unit_ids)\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_autocorrelograms(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389668da",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_crosscorrelograms(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c822e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_unit_presence(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ca0a6",
   "metadata": {},
   "source": [
    "## Sort full recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine==\"dask\":\n",
    "    gc.collect()\n",
    "    \n",
    "    if GPU_available: # takes about 10 minutes with dask\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"70GB\",\n",
    "                        job_cpu=70,\n",
    "                        walltime=\"20:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gpus=2'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 10 minutes\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"6GB\",\n",
    "                        job_cpu=55,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(compute_analyzer, sorting, recording_corrected, probe, fullAnalyzer_folder)\n",
    "    future.result()\n",
    "    #sorting_analyzer_training = future.results() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    #display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "    future = client.submit(GenerateDict, rec_training, probe, sorter_folder, **sorter_params)\n",
    "    sorting = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adef6f8-a103-40aa-a640-8ad538b056ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine=='submitit':\n",
    "    start_time = time.time()\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    #executor.update_parameters(slurm_array_parallelism=2, mem_gb=30, timeout_min=10, slurm_partition=\"CPU\", cpus_per_task=50)\n",
    "    executor.update_parameters(mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70) #cpus_per_task\n",
    "\n",
    "    # actually submit the job\n",
    "    job = executor.submit(compute_analyzer, sorting, recording_corrected, probe, fullAnalyzer_folder)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a42b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#job 34074 completed in 408.1813361644745 second (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34078 completed in 437.409494638443 seconds (slurm_array_parallelism=3, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34081 completed in 423.37460565567017 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", slurm_gres=\"gpu:2\", cpus_per_task=50)\n",
    "#job 34085 completed in 367.0000305175781 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "#job 34089 completed in 370.1982145309448 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=80)\n",
    "#job 34093 completed in 355.1876621246338 seconds (mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "\n",
    "last_job = job\n",
    "checkRessources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not reAnalyse:\n",
    "    print(\"not running analysis but loading previous one\")\n",
    "    sorting_analyzer = si.load_sorting_analyzer(fullAnalyzer_folder)\n",
    "    display(sorting_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.export_report(sorting_analyzer=sorting_analyzer,output_folder='report')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2da484",
   "metadata": {},
   "source": [
    "# Most interactive viewing on local\n",
    "<a id='local'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes 13s\n",
    "#from IPython.display import Javascript\n",
    "#Javascript(\"Jupyter.notebook.execute_cell_range(0,15)\")\n",
    "#TODO: here should find a way to execute previous cell, or have the function in a loadable module.\n",
    "currentFile_data = magicretrieve('currentFile_data')\n",
    "print(currentFile_data)\n",
    "sorting_analyzer_training = si.load_sorting_analyzer(os.path.join('//10.69.168.1',os.path.split(currentFile_data)[0],training_folder))\n",
    "display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061be488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "si.plot_sorting_summary(sorting_analyzer_training, backend=\"spikeinterface_gui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d554903",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFile_data = magicretrieve('currentFile_data', storePath='')\n",
    "print(currentFile_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".si-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
