{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Spindles from Neocortex recordings\n",
    "\n",
    "Restarting from LFPwake0 and LFPwakeremoved.\n",
    "\n",
    "LFPwakeremoved will be used to determined signal variance for threshold adjustement. \n",
    "\n",
    "LFPwake0 will be used for time determination. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LFP and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal, stats\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "from scipy import fftpack\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "\n",
    "%matplotlib widget\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, TimeFreqViewer, CsvEpochSource, EpochEncoder,EpochViewer,InMemoryEventSource,EventList\n",
    "from ephyviewer import AnalogSignalSourceWithScatter\n",
    "from ephyviewer import InMemoryAnalogSignalSource\n",
    "import ephyviewer\n",
    "\n",
    "from mbTools import mbTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = \"\"\n",
    "try:\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"data path not in strore\")\n",
    "    dpath = os.path.expanduser(\"~\")\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>OpenEphys Folder</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = \"S1\" #S1 or PFC\n",
    "\n",
    "suffix='_AH'#'_AB'\n",
    "sep = -5 # -3 if Baseline #-4 if CGP\n",
    "animalIDPos = -4 # -3 if Baseline #-4 if CGP\n",
    "dirPathComponents = os.path.normpath(dpath).split(os.sep)\n",
    "mapPath = os.path.sep.join(dirPathComponents[:sep-1]) #\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023\" \n",
    "folder_base = os.path.sep.join(dirPathComponents[sep-1:])\n",
    "mice = dirPathComponents[animalIDPos]\n",
    "#os.chdir(mapPath)\n",
    "print(mapPath)\n",
    "print(folder_base)\n",
    "print(mice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the results in All_Spindle_prop pd dataframe and save as pkl/csv for post processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenameOutput2 = os.path.join(mapPath, folder_base,f'Spindlesproperties_{structure}{suffix}.pkl')\n",
    "#filenameOutput3 = os.path.join(mapPath, folder_base,f'Spindlesproperties_{structure}{suffix}.csv')\n",
    "filenameOutput3 = os.path.join(mapPath, folder_base,f'Spindlesproperties_{structure}{suffix}.xlsx')\n",
    "\n",
    "ResetAnalysis=True #False or True\n",
    "\n",
    "if os.path.isfile(filenameOutput3):\n",
    "    if not ResetAnalysis:         \n",
    "        print(f'previous file imported and used : {filenameOutput3}')\n",
    "        All_Spindle = pd.read_excel(filenameOutput3)\n",
    "        print(All_Spindle)\n",
    "    else:\n",
    "        print(f'/!\\ pre-existing file will be deleted and replaced : {filenameOutput3}')\n",
    "else:\n",
    "    ResetAnalysis=True\n",
    "    print(f\"no previous analysis found, creation of : {filenameOutput3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ResetAnalysis: \n",
    "    \n",
    "    filename3 = os.path.join(dpath,f'LFPwakeremoved{suffix}.npy')\n",
    "    filename2 = os.path.join(dpath,'RawDataChannelExtractedDS.npy')\n",
    "    EMGbooleaninput = os.path.join(dpath,f'EMGframeBoolean{suffix}.pkl')\n",
    "\n",
    "    EMGboolean = pd.read_pickle(EMGbooleaninput)\n",
    "    LFPwakeremoved = np.load(filename3, mmap_mode= 'r')\n",
    "    All = np.load(filename2, mmap_mode= 'r')\n",
    "\n",
    "    try:\n",
    "        Channels = os.path.join(mapPath,f'LFPChannels_perMice.xlsx')\n",
    "        allchannels = pd.read_excel(Channels)\n",
    "        PFCch1=int(allchannels[mice][0].split(',')[0])\n",
    "        PFCch2=int(allchannels[mice][0].split(',')[1])\n",
    "        S1ch1=int(allchannels[mice][1].split(',')[0])\n",
    "        S1ch2=int(allchannels[mice][1].split(',')[1])\n",
    "        CA1ch1=int(allchannels[mice][2].split(',')[0])\n",
    "        CA1ch2=int(allchannels[mice][2].split(',')[1])\n",
    "        EMGch=int(allchannels[mice][3])\n",
    "        EMG  =  All[:, EMGch]\n",
    "    except FileNotFoundError as e:\n",
    "        print(mbTools.color.BOLD + mbTools.color.YELLOW)\n",
    "        print(f\"File {os.path.join(mapPath,f'LFPChannels_perMice.xlsx')} not found!\")\n",
    "        print(\"probably you are not Aurélie... or the path to access it is wrong.\")\n",
    "        print(\"In the first case, make sure the mapping is rightfully setup in the curent cell\")\n",
    "        print(\"In the second case, you can play with the 'sep' variable of cell 3, or directly change the path\")\n",
    "        print(mbTools.color.END)\n",
    "        PFCch1=1\n",
    "        PFCch2=None\n",
    "        S1ch1=2\n",
    "        S1ch2=None\n",
    "        CA1ch1=21\n",
    "        CA1ch2=22\n",
    "\n",
    "    if structure == \"PFC\":\n",
    "        CTX  =  All[:, PFCch1]-All[:, PFCch2] if PFCch2 is not None else All[:, PFCch1]\n",
    "        CTXwakeremoved = LFPwakeremoved[:,PFCch1]-LFPwakeremoved[:,PFCch2] \n",
    "                \n",
    "\n",
    "    elif structure == \"S1\":\n",
    "        CTX  =  All[:, S1ch1]-All[:, S1ch2] if S1ch2 is not None else All[:, S1ch1]\n",
    "        CTXwakeremoved = LFPwakeremoved[:,S1ch1]-LFPwakeremoved[:,S1ch2] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band pass filter\n",
    "        Spindles: 8-20 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ResetAnalysis: \n",
    "\n",
    "    # Filtre parameter:\n",
    "    f_lowcut = 8.\n",
    "    f_hicut = 20.\n",
    "    fs = 1000\n",
    "    nyq = 0.5 * fs\n",
    "    N = 4                 # Filtre order\n",
    "    Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "\n",
    "    # Filtering:\n",
    "    b, a = signal.butter(N, Wn, 'band')\n",
    "    filt = signal.filtfilt(b, a, CTX)\n",
    "    filt_wakeremoved = signal.filtfilt(b, a, CTXwakeremoved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Wavelet Transform and projection calculation\n",
    "\n",
    "First on signal with no wake time to determine sd of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ResetAnalysis: \n",
    "    # Parameter and computation of CWT\n",
    "    w = 10.\n",
    "    freq = np.linspace(8, 20, 24)\n",
    "    widths = w*fs / (2*freq*np.pi)\n",
    "    NWcwt = signal.cwt(filt_wakeremoved, signal.morlet2, widths, w=w)\n",
    "\n",
    "    # Projection calculation\n",
    "    absNWcwt = np.absolute(NWcwt)\n",
    "    proj_NWcwt = np.sum(absNWcwt, axis = 0)/24\n",
    "    sdproj_cwt = np.std(proj_NWcwt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second on the signal for which wake times have been zeroed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ResetAnalysis: \n",
    "    # Conservative boolean filtering of PFC filtered signal\n",
    "    BooleanCons = EMGboolean['BooleanConservative']\n",
    "    fwake0C = filt.copy()\n",
    "    fwake0C[BooleanCons] = 0\n",
    "    wake0C = CTX.copy()\n",
    "    wake0C[BooleanCons] = 0\n",
    "    # Liberal boolean filtering of PFC filtered signal\n",
    "    BooleanLib = EMGboolean['BooleanLiberal']\n",
    "    fwake0L = filt.copy()\n",
    "    fwake0L[BooleanLib] = 0\n",
    "    wake0L = CTX.copy()\n",
    "    wake0L[BooleanLib] = 0\n",
    "\n",
    "    # Computation of CWT\n",
    "    cwtWake0cons = signal.cwt(fwake0C, signal.morlet2, widths, w=w)\n",
    "    cwtWake0lib = signal.cwt(fwake0L, signal.morlet2, widths, w=w)\n",
    "\n",
    "    # Projection calculation\n",
    "    absW0Ccwt = np.absolute(cwtWake0cons)\n",
    "    proj_W0Ccwt = np.sum(absW0Ccwt, axis = 0)/24\n",
    "    absW0Lcwt = np.absolute(cwtWake0lib)\n",
    "    proj_W0Lcwt = np.sum(absW0Lcwt, axis = 0)/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display subset \n",
    "\n",
    "Not necessary cell to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ResetAnalysis: \n",
    "    # Defining subset\n",
    "    start = 00000\n",
    "    end = 800000\n",
    "\n",
    "    times = np.arange(0, CTX.size/fs, 1./fs)\n",
    "    tt = times[start:end]\n",
    "    Cortext = wake0C[start:end]/10\n",
    "    #Cortexcwtt = PFCNWcwt[:, start:end]\n",
    "    proj_Cortexcwtt = proj_W0Ccwt[start:end]\n",
    "\n",
    "    plt.close('all')\n",
    "    plt.axhline(sdproj_cwt, color='r') # horizontal\n",
    "    plt.axhline(sdproj_cwt*3.5, color='g') # horizontal\n",
    "    plt.plot(tt, Cortext,'b')\n",
    "    plt.plot(tt, proj_Cortexcwtt,'k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ResetAnalysis: \n",
    "    sd_thresh = sdproj_cwt*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display with ephyviewer, not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Spindles and determining main properties \n",
    "\n",
    "First extraction of spindle peaks, initiation, end and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ResetAnalysis: \n",
    "    proj_cortex = proj_W0Lcwt\n",
    "    proj_cortexC = proj_W0Ccwt\n",
    "    sd_proj_cortex = sd_thresh\n",
    "    lib_wake0_cortex = cwtWake0lib\n",
    "    filt_cortex = filt\n",
    "\n",
    "    peaks, properties = find_peaks(proj_cortex, prominence=1, width=200, height=sd_proj_cortex)\n",
    "    properties[\"prominences\"], properties[\"widths\"]\n",
    "\n",
    "    # Spindles boundaries taken at 70% from peak of intensity. This means that the spindles with small amplitude will be longer than the big ones.\n",
    "    results_width = peak_widths(proj_cortex, peaks, rel_height=0.6)\n",
    "\n",
    "    # Organise results in numpy array\n",
    "    peaks2 = peaks.reshape(len(peaks),1)\n",
    "    npresults_width = np.array(results_width).reshape(4,-1)\n",
    "    Spindle_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()\n",
    "    print(peaks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second extraction of main frequency and power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ResetAnalysis: \n",
    "    \n",
    "    projMaxP_cwtmg = np.max(lib_wake0_cortex, axis = 0)\n",
    "    projMaxF_cwtmg = np.argmax(lib_wake0_cortex, axis = 0)/2 + 8\n",
    "    projMaxP_cwtmg.shape\n",
    "\n",
    "    nb_Spindles = len(peaks)\n",
    "    data = np.zeros((nb_Spindles,4))\n",
    "\n",
    "    for tt in np.arange(nb_Spindles):\n",
    "        Spindle_start = int(Spindle_prop[3,tt])\n",
    "        Spindle_stop = int(Spindle_prop[4,tt])\n",
    "        Spindle_MaxP = projMaxP_cwtmg[Spindle_start:Spindle_stop]\n",
    "        Spindle_MaxF = projMaxF_cwtmg[Spindle_start:Spindle_stop]\n",
    "        data[tt, 0] = max(Spindle_MaxF).round()\n",
    "        data[tt, 1] = max(Spindle_MaxP).round()\n",
    "        data[tt, 2] = round(sum(Spindle_MaxF)/len(Spindle_MaxF))\n",
    "        data[tt, 3] = round(sum(Spindle_MaxP)/len(Spindle_MaxP))\n",
    "\n",
    "    param_Spindle = pd.DataFrame(data, columns = ['Max freq', 'Max int', 'Avg freq', 'Avg int'])\n",
    "    tSpindle_prop = Spindle_prop.transpose()\n",
    "    pd_prop_Spindle = pd.DataFrame(tSpindle_prop, columns = ['peak time', 'Duration', 'peak amp', 'start time', 'end time'])\n",
    "    pd_tokeep = pd.DataFrame(np.ones(nb_Spindles).astype(bool), columns = ['toKeep'])\n",
    "    All_Spindle = pd.concat([pd_tokeep,pd_prop_Spindle, param_Spindle], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ResetAnalysis: \n",
    "    nb_spindle = All_Spindle.shape[0]\n",
    "    listtodrop = []\n",
    "    for tt in range(nb_spindle-1):\n",
    "        # merge spdl that starts within a spdl\n",
    "        if(All_Spindle['end time'][tt]>All_Spindle['start time'][tt + 1]):\n",
    "            if(All_Spindle['Duration'][tt]<All_Spindle['Duration'][tt + 1]):\n",
    "                if(All_Spindle['start time'][tt]<All_Spindle['start time'][tt + 1]):\n",
    "                    All_Spindle['start time'][tt+1] = All_Spindle['start time'][tt]\n",
    "                    listtodrop.append(tt)\n",
    "                else:\n",
    "                    listtodrop.append(tt)\n",
    "            if(All_Spindle['Duration'][tt]>All_Spindle['Duration'][tt + 1]):\n",
    "                if(All_Spindle['end time'][tt]<All_Spindle['end time'][tt + 1]):\n",
    "                    All_Spindle['end time'][tt] = All_Spindle['end time'][tt + 1]\n",
    "                    listtodrop.append(tt+1)\n",
    "                else:\n",
    "                    listtodrop.append(tt+1)\n",
    "\n",
    "    for tt in range(nb_spindle-1):\n",
    "        # merge spdls that are 200ms apart\n",
    "        if((All_Spindle['start time'][tt + 1] - All_Spindle['end time'][tt])<200):\n",
    "            if((All_Spindle['Duration'][tt])<All_Spindle['Duration'][tt + 1]): #first spdl longer so remove/merge the second one\n",
    "                All_Spindle['start time'][tt + 1] = All_Spindle['start time'][tt]\n",
    "                listtodrop.append(tt)\n",
    "            if((All_Spindle['Duration'][tt+1])<All_Spindle['Duration'][tt]): #second spdl longer so remove/merge the first one\n",
    "                All_Spindle['end time'][tt] = All_Spindle['start time'][tt + 1]\n",
    "                listtodrop.append(tt+1)\n",
    "\n",
    "    for tt in range(nb_spindle):\n",
    "        #Update duration because of the merging\n",
    "        All_Spindle['Duration'][tt]=All_Spindle['end time'][tt]-All_Spindle['start time'][tt]\n",
    "\n",
    "    for tt in range(nb_spindle): #All_Spindle.index:\n",
    "        #Remove Spdl that last than 500ms\n",
    "        if (All_Spindle['Duration'][tt]<500):\n",
    "            listtodrop.append(tt)\n",
    "\n",
    "    print('Nb of Spdl detected:', len(All_Spindle))    \n",
    "    All_Spindle = All_Spindle.drop(listtodrop) \n",
    "    print('Nb of Spdl detected after merging:', len(All_Spindle))    \n",
    "\n",
    "    #All_Spindle.to_pickle(filenameOutput2)\n",
    "    All_Spindle.to_excel(filenameOutput3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display\n",
    "\n",
    "ephys viewer to check Spindle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "\n",
    "app = mkQApp()\n",
    "\n",
    "#Create one data source with 3 event channel\n",
    "all_events = []\n",
    "conditions = ['All','Good','Bad']\n",
    "for c,cond in enumerate(conditions):\n",
    "    match cond:\n",
    "        case 'All':\n",
    "            selection = \"All_Spindle['toKeep'] | ~All_Spindle['toKeep']\"\n",
    "        case 'Good':\n",
    "            selection = \"All_Spindle['toKeep']\"\n",
    "        case 'Bad':\n",
    "            selection = \"~All_Spindle['toKeep']\"\n",
    "    ev_times = All_Spindle.loc[pd.eval(selection),'peak time'].values/1000\n",
    "    ev_labels = [f'spindle {i}'for i in All_Spindle[pd.eval(selection)].index]\n",
    "    all_events.append({ 'time':ev_times, 'label':ev_labels, 'name': conditions[c] })\n",
    "source_ev = InMemoryEventSource(all_events=all_events)\n",
    "\n",
    "\n",
    "sample_rate = 1000.\n",
    "t_start = 0.\n",
    "\n",
    "combined = np.stack([CTX, filt_cortex, proj_cortexC, proj_cortex, EMG], axis = 1)\n",
    "\n",
    "Spindle_peak = np.array(All_Spindle['peak time']).astype(int)\n",
    "Spindle_start = np.array(All_Spindle['start time']).astype(int) # Spindle_prop[3,:].astype(int)\n",
    "Spindle_end = np.array(All_Spindle['end time']).astype(int) #Spindle_prop[4,:].astype(int)\n",
    "\n",
    "#create 2 familly scatters from theses 2 indexes\n",
    "scatter_indexes = {0: Spindle_peak, 1: Spindle_start, 2: Spindle_end}\n",
    "#and asign them to some channels each\n",
    "scatter_channels = {0: [], 1: [0, 1], 2: [0, 1]}\n",
    "source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels, scatter_colors= {0: '#FFFFFF', 1: '#FFFFFF', 2: '#222222'}, channel_names=[f'{structure}','FiltLFP', 'EMGLib', 'EMGCons', 'EMG'])\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "#create a viewer for signal with TraceViewer\n",
    "#connected to the signal source\n",
    "view1 = TraceViewer(source=source)\n",
    "\n",
    "#Parameters can be set in script\n",
    "view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.params['display_labels'] = True\n",
    "view1.auto_scale()\n",
    "\n",
    "nCh = len(view1.by_channel_params.children())\n",
    "mult = 5\n",
    "for ch in range(nCh):\n",
    "    match ch%mult:\n",
    "        case 0: # raw traces\n",
    "            view1.by_channel_params[f'ch{ch}', 'offset'] = 1 + 3*int(ch/mult)\n",
    "            #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.05\n",
    "            view1.by_channel_params[f'ch{ch}', 'color'] = '#88FF88'\n",
    "        case 1: # filtered traces\n",
    "            view1.by_channel_params[f'ch{ch}', 'offset'] = .5 + 3*int(ch/mult)\n",
    "            #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.1\n",
    "            view1.by_channel_params[f'ch{ch}', 'color'] = '#0055ff'\n",
    "        case 2: # envelop\n",
    "            view1.by_channel_params[f'ch{ch}', 'offset'] = .5 + 3*int(ch/mult)\n",
    "            #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.1\n",
    "            view1.by_channel_params[f'ch{ch}', 'color'] = '#ff5500'\n",
    "        case 3: # envelop\n",
    "            view1.by_channel_params[f'ch{ch}', 'offset'] = .5 + 3*int(ch/mult)\n",
    "            #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.1\n",
    "            view1.by_channel_params[f'ch{ch}', 'color'] = '#ffffff'\n",
    "        case 4: # EMG\n",
    "            view1.by_channel_params[f'ch{ch}', 'offset'] = .2 + 3*int(ch/mult)\n",
    "            view1.by_channel_params[f'ch{ch}', 'gain'] = 1/10000\n",
    "            view1.by_channel_params[f'ch{ch}', 'color'] = '#888888'\n",
    "view1.params['ylim_max']=1.5*int((nCh+1)/mult)\n",
    "view1.params['ylim_min']=0\n",
    "\n",
    "view2 = EventList(source=source_ev, name='event')\n",
    "\n",
    "\n",
    "#create a time freq viewer conencted to the same source\n",
    "view3 = TimeFreqViewer(source=source, name='FFT')\n",
    "view3.params['show_axis'] = True\n",
    "view3.params['timefreq', 'f_start'] = 1\n",
    "view3.params['timefreq', 'f_stop'] = 30\n",
    "view3.params['timefreq', 'deltafreq'] = 1 #interval in Hz\n",
    "view3.by_channel_params['ch0', 'clim'] = 300\n",
    "view3.by_channel_params['ch0', 'visible'] = True\n",
    "\n",
    "\n",
    "#put this viewer in the main window\n",
    "win.add_view(view1)\n",
    "win.add_view(view3)\n",
    "win.add_view(view2, location='bottom',  orientation='horizontal')\n",
    "\n",
    "#Run\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select and deselect spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clicked(arg):\n",
    "    selectedEvent = view2.list_widget.currentItem().text()\n",
    "    selectedSpindle = int(selectedEvent.split('spindle')[1])\n",
    "    #print(selectedSpindle)\n",
    "    match arg.description:\n",
    "        case 'Keep spindle':\n",
    "            All_Spindle.loc[selectedSpindle,'toKeep']=True\n",
    "            print(f'Spindle {selectedSpindle} restored')\n",
    "        case 'Discard spindle':\n",
    "            All_Spindle.loc[selectedSpindle,'toKeep']=False\n",
    "            print(f'Spindle {selectedSpindle} discarded')\n",
    "    #save modif\n",
    "    #All_Spindle.to_pickle(filenameOutput2)\n",
    "    All_Spindle.to_excel(filenameOutput3)\n",
    "    #Create one data source with 3 event channel\n",
    "    all_events = []\n",
    "    conditions = ['All','Good','Bad']\n",
    "    for c,cond in enumerate(conditions):\n",
    "        match cond:\n",
    "            case 'All':\n",
    "                selection = \"All_Spindle['toKeep'] | ~All_Spindle['toKeep']\"\n",
    "            case 'Good':\n",
    "                selection = \"All_Spindle['toKeep']\"\n",
    "            case 'Bad':\n",
    "                selection = \"~All_Spindle['toKeep']\"\n",
    "        ev_times = All_Spindle.loc[pd.eval(selection),'peak time'].values/1000\n",
    "        ev_labels = [f'spindle {i}'for i in All_Spindle[pd.eval(selection)].index]\n",
    "        all_events.append({ 'time':ev_times, 'label':ev_labels, 'name': conditions[c] })\n",
    "    source_ev = InMemoryEventSource(all_events=all_events)\n",
    "    view2.source = source_ev\n",
    "    view2.refresh_list(view2.combo.currentIndex())\n",
    "\n",
    "button_Good = widgets.Button(description = 'Keep spindle')   \n",
    "button_Good.on_click(clicked)\n",
    "\n",
    "button_Bad = widgets.Button(description = 'Discard spindle')   \n",
    "button_Bad.on_click(clicked)\n",
    "\n",
    "display(button_Good, button_Bad)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "984d3fbee8ffa490637705ae3d7233e001ab0304f3daaca07b5aa8569b88ca53"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('formation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
