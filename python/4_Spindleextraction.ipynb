{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Spindles from Neocortex recordings\n",
    "\n",
    "Restarting from LFPwake0 and LFPwakeremoved.\n",
    "\n",
    "LFPwakeremoved will be used to determined signal variance for threshold adjustement. \n",
    "\n",
    "LFPwake0 will be used for time determination. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LFP and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal, stats\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "from scipy import fftpack\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, EventList, InMemoryEventSource\n",
    "from ephyviewer import AnalogSignalSourceWithScatter\n",
    "import ephyviewer\n",
    "\n",
    "# add the Contrib dir that contains all tools developped by MB : mbTools.py\n",
    "#sys.path.append(os.path.join(os.path.dirname(sys.path[0]),'python'))\n",
    "#print(os.path.join(os.path.dirname(sys.path[0]),'python'))\n",
    "import HayLabAnalysis as hla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = \"\"\n",
    "try:\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"data path not in strore\")\n",
    "    dpath = os.path.expanduser(\"~\")\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>OpenEphys Folder</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix=''#'_AB'\n",
    "sep = -5\n",
    "animalIDPos = -3\n",
    "dirPathComponents = os.path.normpath(dpath).split(os.sep)\n",
    "mapPath = os.path.sep.join(dirPathComponents[:sep])\n",
    "folder_base = os.path.sep.join(dirPathComponents[sep:])\n",
    "mice = dirPathComponents[animalIDPos]\n",
    "#os.chdir(mapPath)\n",
    "print(mapPath)\n",
    "print(folder_base)\n",
    "print(mice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for pre-existing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = \"M1\"\n",
    "filename2 = os.path.join(dpath,f'Spindlesproperties_{structure}{suffix}.pkl')\n",
    "filename3 = os.path.join(dpath,f'Spindlesproperties_{structure}{suffix}.csv')\n",
    "filenameData = os.path.join(dpath,f'Signal{structure}{suffix}.npy')\n",
    "if os.path.isfile(filename3):\n",
    "    print(f\"file {filename3} already exists so loading it and not redoing analysis\")\n",
    "    reAnalyse=False\n",
    "    All_Spindle = pd.read_csv(filename3, sep=',', header=0, index_col=0)\n",
    "    if 'toKeep' not in All_Spindle:\n",
    "        All_Spindle['toKeep'] = True\n",
    "    print(All_Spindle)\n",
    "    M1=np.load(filenameData, mmap_mode= 'r')[:,0]\n",
    "    print(M1.shape)\n",
    "else:\n",
    "    print(f\"file {filename3} doesn't exist yet which is probably because you haven't done the analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or reimport it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    filename3 = os.path.join(dpath,f'LFPwakeremoved{suffix}.npy')\n",
    "    filename2 = os.path.join(dpath,'RawDataChannelExtractedDS.npy')\n",
    "    EMGbooleaninput = os.path.join(dpath,f'EMGframeBoolean{suffix}.pkl')\n",
    "\n",
    "\n",
    "    EMGboolean = pd.read_pickle(EMGbooleaninput)\n",
    "    LFPwakeremoved = np.load(filename3, mmap_mode= 'r')\n",
    "    All = np.load(filename2, mmap_mode= 'r')\n",
    "\n",
    "    try:\n",
    "        Channels = os.path.join(mapPath,f'LFPChannels_perMice.xlsx')\n",
    "        allchannels = pd.read_excel(Channels)\n",
    "        PFCch1=int(allchannels[mice][0].split(',')[0])\n",
    "        PFCch2=int(allchannels[mice][0].split(',')[1])\n",
    "        S1ch1=int(allchannels[mice][1].split(',')[0])\n",
    "        S1ch2=int(allchannels[mice][1].split(',')[1])\n",
    "        CA1ch1=int(allchannels[mice][2].split(',')[0])\n",
    "        CA1ch2=int(allchannels[mice][2].split(',')[1])\n",
    "    except FileNotFoundError as e:\n",
    "        print(hla.tools.color.BOLD + hla.tools.color.YELLOW)\n",
    "        print(f\"File {os.path.join(mapPath,f'LFPChannels_perMice.xlsx')} not found!\")\n",
    "        print(\"probably you are not Aurélie... or the path to access it is wrong.\")\n",
    "        print(\"In the first case, make sure the mapping is rightfully setup in the curent cell\")\n",
    "        print(\"In the second case, you can play with the 'sep' variable of cell 3, or directly change the path\")\n",
    "        print(hla.tools.color.END)\n",
    "        PFCch1=21\n",
    "        PFCch2=20\n",
    "        S1ch1=19\n",
    "        S1ch2=18\n",
    "        CA1ch1=0\n",
    "        CA1ch2=1\n",
    "        M1ch1=16\n",
    "        M1ch2=17\n",
    "\n",
    "    PFC  =  All[:, PFCch1]-All[:, PFCch2] if PFCch2 is not None else All[:, PFCch1]\n",
    "    #CA1  =  All[:, CA1ch1]-All[:, CA1ch2] if CA1ch2 is not None else All[:, CA1ch1]\n",
    "    M1  =  All[:, M1ch1]-All[:, M1ch2] if M1ch2 is not None else All[:, M1ch1]\n",
    "    S1  =  All[:, S1ch1]-All[:, S1ch2] if S1ch2 is not None else All[:, S1ch1]\n",
    "    #CA1wakeremoved = LFPwakeremoved[:,CA1ch1]-LFPwakeremoved[:,CA1ch2] \n",
    "    PFCwakeremoved = LFPwakeremoved[:,PFCch1]-LFPwakeremoved[:,PFCch2] \n",
    "    S1wakeremoved = LFPwakeremoved[:,S1ch1]-LFPwakeremoved[:,S1ch2] \n",
    "    M1wakeremoved = LFPwakeremoved[:,M1ch1]-LFPwakeremoved[:,M1ch2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band pass filter\n",
    "        Spindles: 8-20 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    # Filtre parameter:\n",
    "    f_lowcut = 8.\n",
    "    f_hicut = 20.\n",
    "    fs = 1000\n",
    "    nyq = 0.5 * fs\n",
    "    N = 4                 # Filtre order\n",
    "    Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "\n",
    "    # Filtering:\n",
    "    b, a = signal.butter(N, Wn, 'band')\n",
    "    filt_PFC = signal.filtfilt(b, a, PFC)\n",
    "    filt_PFCwakeremoved = signal.filtfilt(b, a, PFCwakeremoved)\n",
    "\n",
    "    filt_S1 = signal.filtfilt(b, a, S1)\n",
    "    filt_S1wakeremoved = signal.filtfilt(b, a, S1wakeremoved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Wavelet Transform and projection calculation\n",
    "\n",
    "First on signal with no wake time to determine sd of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    # Parameter and computation of CWT\n",
    "    w = 10.\n",
    "    freq = np.linspace(8, 20, 24)\n",
    "    widths = w*fs / (2*freq*np.pi)\n",
    "    PFCNWcwt = signal.cwt(filt_PFCwakeremoved, signal.morlet2, widths, w=w)\n",
    "    S1NWcwt = signal.cwt(filt_S1wakeremoved, signal.morlet2, widths, w=w)\n",
    "\n",
    "    # Projection calculation PFC\n",
    "    absPFCNWcwt = np.absolute(PFCNWcwt)\n",
    "    proj_PFCNWcwt = np.sum(absPFCNWcwt, axis = 0)/24\n",
    "    sdproj_PFCcwt = np.std(proj_PFCNWcwt)\n",
    "    sd7proj_PFCcwt = sdproj_PFCcwt*7\n",
    "\n",
    "    # Projection calculation S1\n",
    "    absS1NWcwt = np.absolute(S1NWcwt)\n",
    "    proj_S1NWcwt = np.sum(absS1NWcwt, axis = 0)/24\n",
    "    sdproj_S1cwt = np.std(proj_S1NWcwt)\n",
    "    sd7proj_S1cwt = sdproj_S1cwt*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second on the signal for which wake times have been zeroed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    #####################################\n",
    "    ########        PFC         #########\n",
    "    #####################################\n",
    "    # Conservative boolean filtering of PFC filtered signal\n",
    "    BooleanCons = EMGboolean['BooleanConservative']\n",
    "    fPFCwake0C = filt_PFC.copy()\n",
    "    fPFCwake0C[BooleanCons] = 0\n",
    "    PFCwake0C = PFC.copy()\n",
    "    PFCwake0C[BooleanCons] = 0\n",
    "    # Liberal boolean filtering of PFC filtered signal\n",
    "    BooleanLib = EMGboolean['BooleanLiberal']\n",
    "    fPFCwake0L = filt_PFC.copy()\n",
    "    fPFCwake0L[BooleanLib] = 0\n",
    "    PFCwake0L = PFC.copy()\n",
    "    PFCwake0L[BooleanLib] = 0\n",
    "\n",
    "    # Computation of CWT\n",
    "    PFCcwtWake0cons = signal.cwt(fPFCwake0C, signal.morlet2, widths, w=w)\n",
    "    PFCcwtWake0lib = signal.cwt(fPFCwake0L, signal.morlet2, widths, w=w)\n",
    "\n",
    "    # Projection calculation\n",
    "    absPFCW0Ccwt = np.absolute(PFCcwtWake0cons)\n",
    "    proj_PFCW0Ccwt = np.sum(absPFCW0Ccwt, axis = 0)/24\n",
    "    absPFCW0Lcwt = np.absolute(PFCcwtWake0lib)\n",
    "    proj_PFCW0Lcwt = np.sum(absPFCW0Lcwt, axis = 0)/24\n",
    "\n",
    "\n",
    "\n",
    "    #####################################\n",
    "    ########         S1         #########\n",
    "    #####################################\n",
    "    # Conservative boolean filtering of S1 filtered signal\n",
    "    BooleanCons = EMGboolean['BooleanConservative']\n",
    "    fS1wake0C = filt_S1.copy()\n",
    "    fS1wake0C[BooleanCons] = 0\n",
    "    S1wake0C = S1.copy()\n",
    "    S1wake0C[BooleanCons] = 0\n",
    "    # Liberal boolean filtering of S1 filtered signal\n",
    "    BooleanLib = EMGboolean['BooleanLiberal']\n",
    "    fS1wake0L = filt_S1.copy()\n",
    "    fS1wake0L[BooleanLib] = 0\n",
    "    S1wake0L = S1.copy()\n",
    "    S1wake0L[BooleanLib] = 0\n",
    "\n",
    "    # Computation of CWT\n",
    "    S1cwtWake0cons = signal.cwt(fS1wake0C, signal.morlet2, widths, w=w)\n",
    "    S1cwtWake0lib = signal.cwt(fS1wake0L, signal.morlet2, widths, w=w)\n",
    "\n",
    "    # Projection calculation\n",
    "    absS1W0Ccwt = np.absolute(S1cwtWake0cons)\n",
    "    proj_S1W0Ccwt = np.sum(absS1W0Ccwt, axis = 0)/24\n",
    "    absS1W0Lcwt = np.absolute(S1cwtWake0lib)\n",
    "    proj_S1W0Lcwt = np.sum(absS1W0Lcwt, axis = 0)/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display subset \n",
    "\n",
    "Not necessary cell to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    # Defining subset\n",
    "    start = 00000\n",
    "    end = 800000\n",
    "\n",
    "    times = np.arange(0, PFC.size/fs, 1./fs)\n",
    "    tt = times[start:end]\n",
    "    Cortext = PFCwake0C[start:end]/10\n",
    "    #Cortexcwtt = PFCNWcwt[:, start:end]\n",
    "    proj_Cortexcwtt = proj_PFCW0Ccwt[start:end]\n",
    "\n",
    "    plt.close('all')\n",
    "    plt.axhline(sdproj_PFCcwt, color='r') # horizontal\n",
    "    plt.axhline(sd7proj_PFCcwt, color='g') # horizontal\n",
    "    plt.plot(tt, Cortext)\n",
    "    plt.plot(tt, proj_Cortexcwtt)\n",
    "    plt.show()\n",
    "\n",
    "    ## WARNING: Plot only short subsets (~ 10 s), too memory consuming otherwise\n",
    "    #plt.pcolormesh(tt, freq, np.abs(PFCcwtt), cmap='viridis', shading='gouraud')\n",
    "    #plt.plot(tt, PFCt)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display with ephyviewer, not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Spindles and determining main properties \n",
    "\n",
    "First extraction of spindle peaks, initiation, end and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    structure = \"PFC\"\n",
    "    cortex = eval(structure)\n",
    "    proj_cortex = proj_S1W0Lcwt\n",
    "    proj_cortexC = proj_S1W0Ccwt\n",
    "    sd_proj_cortex = sd7proj_S1cwt\n",
    "    lib_wake0_cortex = S1cwtWake0lib\n",
    "    filt_cortex = filt_S1\n",
    "\n",
    "    # 7 sd threshold\n",
    "    peaks, properties = find_peaks(proj_cortex, prominence=1, width=200, height=sd_proj_cortex)\n",
    "    properties[\"prominences\"], properties[\"widths\"]\n",
    "\n",
    "    # Spindles boundaries taken at 70% from peak of intensity. This means that the spindles with small amplitude will be longer than the big ones.\n",
    "    results_width = peak_widths(proj_cortex, peaks, rel_height=0.6)\n",
    "\n",
    "    # Organise results in numpy array\n",
    "    peaks2 = peaks.reshape(len(peaks),1)\n",
    "    npresults_width = np.array(results_width).reshape(4,-1)\n",
    "    Spindle_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()\n",
    "    peaks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second extraction of main frequency and power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    projMaxP_cwtmg = np.max(lib_wake0_cortex, axis = 0)\n",
    "    projMaxF_cwtmg = np.argmax(lib_wake0_cortex, axis = 0)/2 + 8\n",
    "    projMaxP_cwtmg.shape\n",
    "\n",
    "    nb_Spindles = len(peaks)\n",
    "    data = np.zeros((nb_Spindles,4))\n",
    "\n",
    "    for tt in np.arange(nb_Spindles):\n",
    "        Spindle_start = int(Spindle_prop[3,tt])\n",
    "        Spindle_stop = int(Spindle_prop[4,tt])\n",
    "        Spindle_MaxP = projMaxP_cwtmg[Spindle_start:Spindle_stop]\n",
    "        Spindle_MaxF = projMaxF_cwtmg[Spindle_start:Spindle_stop]\n",
    "        data[tt, 0] = max(Spindle_MaxF).round()\n",
    "        data[tt, 1] = max(Spindle_MaxP).round()\n",
    "        data[tt, 2] = round(sum(Spindle_MaxF)/len(Spindle_MaxF))\n",
    "        data[tt, 3] = round(sum(Spindle_MaxP)/len(Spindle_MaxP))\n",
    "\n",
    "    param_Spindle = pd.DataFrame(data, columns = ['Max freq', 'Max int', 'Avg freq', 'Avg int'])\n",
    "    tSpindle_prop = Spindle_prop.transpose()\n",
    "    pd_prop_Spindle = pd.DataFrame(tSpindle_prop, columns = ['peak time', 'Duration', 'peak amp', 'start time', 'end time'])\n",
    "    pd_tokeep = pd.DataFrame(np.ones(nb_Spindles).astype(bool), columns = ['toKeep'])\n",
    "    All_Spindle = pd.concat([pd_tokeep,pd_prop_Spindle, param_Spindle], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the results in All_Spindle_prop pd dataframe and save as pkl/csv for post processing.\n",
    "\n",
    "End of Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse:\n",
    "    filename2 = os.path.join(folder_base,f'Spindlesproperties_{structure}{suffix}.pkl')\n",
    "    filename3 = os.path.join(folder_base,f'Spindlesproperties_{structure}{suffix}.csv')\n",
    "    All_Spindle.to_pickle(filename2)\n",
    "    All_Spindle.to_csv(filename3, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.close()\n",
    "plt.plot(M1[41000:45000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display\n",
    "\n",
    "ephys viewer to check Spindle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "app = mkQApp()\n",
    "\n",
    "#Create one data source with 3 event channel\n",
    "all_events = []\n",
    "conditions = ['All','Good','Bad']\n",
    "for c,cond in enumerate(conditions):\n",
    "    match cond:\n",
    "        case 'All':\n",
    "            selection = \"All_Spindle['toKeep'] | ~All_Spindle['toKeep']\"\n",
    "        case 'Good':\n",
    "            selection = \"All_Spindle['toKeep']\"\n",
    "        case 'Bad':\n",
    "            selection = \"~All_Spindle['toKeep']\"\n",
    "    ev_times = All_Spindle.loc[pd.eval(selection),'peak time'].values/1000\n",
    "    ev_labels = [f'spindle {i}'for i in All_Spindle[pd.eval(selection)].index]\n",
    "    all_events.append({ 'time':ev_times, 'label':ev_labels, 'name': conditions[c] })\n",
    "source_ev = InMemoryEventSource(all_events=all_events)\n",
    "\n",
    "\n",
    "sample_rate = 1000.\n",
    "t_start = 0.\n",
    "\n",
    "combined = M1[:,np.newaxis]#np.stack([M1], axis = 1) #cortex, filt_cortex, proj_cortexC, proj_cortex\n",
    "\n",
    "Spindle_peak = All_Spindle['peak time'].astype(int)#peaks\n",
    "Spindle_start = All_Spindle['start time'].astype(int)#Spindle_prop[3,:].astype(int)\n",
    "Spindle_end =All_Spindle['end time'].astype(int)# Spindle_prop[4,:].astype(int)\n",
    "\n",
    "#create 2 familly scatters from theses 2 indexes\n",
    "scatter_indexes = {0: Spindle_peak, 1: Spindle_start, 2: Spindle_end}\n",
    "#and asign them to some channels each\n",
    "scatter_channels = {0: [0, 1], 1: [0, 1], 2: [0, 1]}\n",
    "source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels)\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "#create a viewer for signal with TraceViewer\n",
    "#connected to the signal source\n",
    "view1 = TraceViewer(source=source)\n",
    "\n",
    "#Parameters can be set in script\n",
    "view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.params['display_labels'] = True\n",
    "view1.auto_scale()\n",
    "\n",
    "nCh = len(view1.by_channel_params.children())\n",
    "mult = nCh\n",
    "for ch in range(nCh):\n",
    "    match ch%mult:\n",
    "        case 0: # raw traces\n",
    "            view1.by_channel_params[f'ch{ch}', 'offset'] = 2.5 + 3*int(ch/mult)\n",
    "            #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.05\n",
    "            view1.by_channel_params[f'ch{ch}', 'color'] = '#ffffff'\n",
    "        case 1: # filtered traces\n",
    "            view1.by_channel_params[f'ch{ch}', 'offset'] = 0.5 + 3*int(ch/mult)\n",
    "            #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.1\n",
    "            view1.by_channel_params[f'ch{ch}', 'color'] = '#0055ff'\n",
    "        case 2: # envelop\n",
    "            view1.by_channel_params[f'ch{ch}', 'offset'] = 0.5 + 3*int(ch/mult)\n",
    "            #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.1\n",
    "            view1.by_channel_params[f'ch{ch}', 'color'] = '#ff5500'\n",
    "        case 3: # envelop\n",
    "            view1.by_channel_params[f'ch{ch}', 'offset'] = 0.5 + 3*int(ch/mult)\n",
    "            #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.1\n",
    "            view1.by_channel_params[f'ch{ch}', 'color'] = '#ffffff'\n",
    "view1.params['ylim_max']=3*int((nCh+1)/mult)\n",
    "view1.params['ylim_min']=0\n",
    "\n",
    "view2 = EventList(source=source_ev, name='event')\n",
    "\n",
    "\n",
    "#put this viewer in the main window\n",
    "win.add_view(view1)\n",
    "win.add_view(view2, location='bottom',  orientation='horizontal')\n",
    "\n",
    "#Run\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select and deselect spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clicked(arg):\n",
    "    selectedEvent = view2.list_widget.currentItem().text()\n",
    "    selectedSpindle = int(selectedEvent.split('spindle')[1])\n",
    "    #print(selectedSpindle)\n",
    "    match arg.description:\n",
    "        case 'Keep spindle':\n",
    "            All_Spindle.loc[selectedSpindle,'toKeep']=True\n",
    "            print(f'Spindle {selectedSpindle} restored')\n",
    "        case 'Discard spindle':\n",
    "            All_Spindle.loc[selectedSpindle,'toKeep']=False\n",
    "            print(f'Spindle {selectedSpindle} discarded')\n",
    "    #save modif\n",
    "    All_Spindle.to_pickle(filename2)\n",
    "    All_Spindle.to_csv(filename3, sep = ',')\n",
    "    #Create one data source with 3 event channel\n",
    "    all_events = []\n",
    "    conditions = ['All','Good','Bad']\n",
    "    for c,cond in enumerate(conditions):\n",
    "        match cond:\n",
    "            case 'All':\n",
    "                selection = \"All_Spindle['toKeep'] | ~All_Spindle['toKeep']\"\n",
    "            case 'Good':\n",
    "                selection = \"All_Spindle['toKeep']\"\n",
    "            case 'Bad':\n",
    "                selection = \"~All_Spindle['toKeep']\"\n",
    "        ev_times = All_Spindle.loc[pd.eval(selection),'peak time'].values/1000\n",
    "        ev_labels = [f'spindle {i}'for i in All_Spindle[pd.eval(selection)].index]\n",
    "        all_events.append({ 'time':ev_times, 'label':ev_labels, 'name': conditions[c] })\n",
    "    source_ev = InMemoryEventSource(all_events=all_events)\n",
    "    view2.source = source_ev\n",
    "    view2.refresh_list(view2.combo.currentIndex())\n",
    "\n",
    "button_Good = widgets.Button(description = 'Keep spindle')   \n",
    "button_Good.on_click(clicked)\n",
    "\n",
    "button_Bad = widgets.Button(description = 'Discard spindle')   \n",
    "button_Bad.on_click(clicked)\n",
    "\n",
    "display(button_Good, button_Bad)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
