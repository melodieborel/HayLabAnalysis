{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is just a notebook to visualise 1kHz filtered raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ephyviewer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mephyviewer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mkQApp, MainViewer, TraceViewer, TimeFreqViewer, InMemoryAnalogSignalSource, EventList\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mephyviewer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnalogSignalSourceWithScatter, SpikeInterfaceRecordingSource, InMemoryEventSource\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# add the Contrib dir that contains all tools developped by MB : mbTools.py\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#sys.path.append(os.path.join(os.path.dirname(sys.path[0]),'python'))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print(os.path.join(os.path.dirname(sys.path[0]),'python'))\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ephyviewer'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, TimeFreqViewer, InMemoryAnalogSignalSource, EventList\n",
    "from ephyviewer import AnalogSignalSourceWithScatter, SpikeInterfaceRecordingSource, InMemoryEventSource\n",
    "\n",
    "# add the Contrib dir that contains all tools developped by MB : mbTools.py\n",
    "#sys.path.append(os.path.join(os.path.dirname(sys.path[0]),'python'))\n",
    "#print(os.path.join(os.path.dirname(sys.path[0]),'python'))\n",
    "from mbTools import mbTools\n",
    "\n",
    "import configparser\n",
    "import json\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import local config, create it if inexistant\n",
    "All user-specific configuration (projects, defautl path to files...) are stored in a file named localConfig.ini in the python subfolder of AudreyHayLab repo. It is ignored by git so that it remains truely local. If the file does not exist at beginning, it is created with default values that can be modified at whishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = mbTools.localConf()\n",
    "rawDataPath = config['DATA']['path']\n",
    "print(f'All raw data are expected to be found in the folder: {rawDataPath}')\n",
    "analysisPath = config['ANALYSIS']['path']\n",
    "print(f'All analysis will be saved in the folder: {analysisPath}')\n",
    "config.printAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose experiment\n",
    "Select the experiment to display. If the experiment was already analyzed, a saved_dictionary.pkl was created and contains all necessary variables. Select this file. Otherwise select the raw data recording file.\n",
    ">**If you have a file with channel mapping somewhere**, we should make sure it is properly translated into a dict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFile = None\n",
    "%store -r currentFile\n",
    "print(currentFile)\n",
    "try:\n",
    "    theExpe = mbTools.expeConfigDict(currentFile)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "    theExpe = mbTools.expeConfigDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possibility to change raw data path \n",
    "if for some reason the path to the raw data is wrong, you can update it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theExpe.rawDataSelector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the whole data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    dpath = None #  '//10.69.168.1/crnldata/waking/audrey_hay/NPX/NPX4_claustrum/Expe_2024-07-18_12-00-43/'\n",
    "    # %store dpath\n",
    "    %store -r dpath\n",
    "    print(dpath)\n",
    "    theExpe.rawDataPath = dpath\n",
    "print(theExpe.rawDataPath)\n",
    "thedata = mbTools.experiment(theExpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "thedata.analyseExpe_findData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract submatrix of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate combined and channelLabels\n",
    "combined =  {}\n",
    "channelLabels = {}\n",
    "sample_rates = {}\n",
    "t_start = {}\n",
    "#t_end = 300 #seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expeConfigFN=os.path.sep.join([theExpe.rawDataPath,'expeConfig.ini'])\n",
    "parser = configparser.ConfigParser()\n",
    "parser.read(expeConfigFN)\n",
    "\n",
    "if os.path.isfile(expeConfigFN):\n",
    "    print('mapping exists so loading it')\n",
    "    thedata.data['OE_LFP'].channelsMap = ast.literal_eval(parser['OE_LFP']['channelsMap'])\n",
    "    thedata.data['OE_LFP'].start=ast.literal_eval(parser['OE_LFP']['start'])\n",
    "    thedata.data['OE_LFP'].sampling_rate=ast.literal_eval(parser['OE_LFP']['freq'])\n",
    "else:\n",
    "    print(\"mapping doesn't exist so generating it\")\n",
    "    thedata.data['OE_LFP'].channelsMap = dict( \\\n",
    "            M1 = [dict(canal = 17, status=1),\n",
    "                dict(canal = 16, status=2)],\n",
    "        )\n",
    "\n",
    "    parser['OE_LFP'] = {'channelsMap': thedata.data['OE_LFP'].channelsMap}\n",
    "\n",
    "\n",
    "    artefacts=[55.2, 88.74, 90.6, 121.18, 123, 188, 268, 2065, 3036, 3754, 3590]\n",
    "    parser['OE_LFP']['artefacts']=str(artefacts)\n",
    "\n",
    "\n",
    "    parser['OE_LFP']['start']=str(52.7137)\n",
    "\n",
    "    with open(expeConfigFN, 'w') as configfile:\n",
    "        parser.write(configfile)\n",
    "\n",
    "print(\"the mapping:\", thedata.data['OE_LFP'].channelsMap)\n",
    "print(\"the offset: \", thedata.data['OE_LFP'].start)\n",
    "print(\"the sampling rate: \", thedata.data['OE_LFP'].sampling_rate)\n",
    "\n",
    "thedata.data['OE_LFP'].reAlignTimes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract submatrix of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LFP\n",
    "if 'OE_LFP' in thedata.data:\n",
    "    sample_rates['LFP'] = thedata.data['OE_LFP'].sampling_rate #20000\n",
    "    t_start['LFP'] = thedata.data['OE_LFP'].start\n",
    "    combined['LFP'] = thedata.data['OE_LFP'].combineStructures(['M1'])\n",
    "    channelLabels['LFP'] = thedata.data['OE_LFP'].channelLabels[:]\n",
    "    print(\"LFP data combined\")\n",
    "else:\n",
    "    print(\"no LFP data to combine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NPX\n",
    "if 'NPX' in thedata.data:\n",
    "    sample_rates['NPX'] = thedata.data['NPX'].sampling_rate #30000\n",
    "    t_start['NPX'] = thedata.data['NPX'].start\n",
    "    combined['NPX'] = thedata.data['NPX'].signal['spike']\n",
    "    channelLabels['NPX'] = thedata.data['NPX'].channelLabels\n",
    "    print(\"NPX data combined\")\n",
    "else:\n",
    "    print(\"no NPX data to combine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load extra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbTools import mbTools\n",
    "try:\n",
    "    All_Spindle, M1 = thedata.data['OE_LFP'].loadSpindles(relativePath='../LFP', structure = \"M1\")\n",
    "    combined['LFP_DS']=M1[:,np.newaxis]\n",
    "    channelLabels['LFP_DS'] = ['M1_DS']\n",
    "    freqInitTheoric=20000\n",
    "    freqDS=1000\n",
    "    realignFactor=freqInitTheoric/sample_rates['LFP']\n",
    "    sample_rates['LFP_DS']=freqDS*realignFactor\n",
    "    t_start['LFP_DS']=t_start['LFP']\n",
    "    print(realignFactor)\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M1_i=thedata.data['OE_LFP'].combineStructures(['M1'])[:,0]\n",
    "M1_1=thedata.data['OE_LFP'].signal[:,16]\n",
    "M1_2=thedata.data['OE_LFP'].signal[:,17]\n",
    "M1_iL=thedata.data['OE_LFP'].channelLabels[:]\n",
    "print(M1_1.shape)\n",
    "print(M1_2.shape)\n",
    "print(M1_i.shape)\n",
    "combined['LFP'] = np.stack([M1_i,M1_1, M1_2], axis = 1) #cortex, filt_cortex, proj_cortexC, proj_cortex\n",
    "print(combined['LFP'].shape)\n",
    "channelLabels['LFP'] = ['M1_iL','ch16','ch17']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell can be used to plot very precisely time of interest. Beware that it conflicts with ephyviewer however. It might be possible to have 2 notebooks open simultanéeously...\n",
    "if False:\n",
    "    %matplotlib widget\n",
    "    mbTools.superCleanPlot(thedata.data['OE_LFP'], thedata.data['NPX'], time=1327)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "app = mkQApp()\n",
    "\n",
    "\n",
    "try:\n",
    "    TTL = Timestamps\n",
    "\n",
    "    #create 2 familly scatters from theses 2 indexes\n",
    "    scatter_indexes = {0: TTL, 1: TTL}\n",
    "    #and asign them to some channels each\n",
    "    scatter_channels = {0: [0, 12], 1: [0, 1]}\n",
    "    #source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True)\n",
    "\n",
    "if 'LFP' in combined:\n",
    "    source = InMemoryAnalogSignalSource(combined['LFP'], np.round(sample_rates['LFP']), t_start['LFP'], channel_names=channelLabels['LFP'])\n",
    "    view1 = TraceViewer(source=source, name = 'LFP')\n",
    "\n",
    "    #Parameters can be set in script\n",
    "    view1.params['display_labels'] = True\n",
    "    view1.params['scale_mode'] = 'same_for_all'\n",
    "    view1.auto_scale()\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"hsv\"]#Wistia\"]\n",
    "    nCh = len(view1.by_channel_params.children())\n",
    "    for ch in range(nCh):\n",
    "        #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.00002\n",
    "        #view1.by_channel_params[f'ch{ch}', 'offset'] = 0.1\n",
    "        view1.by_channel_params[f'ch{ch}', 'color'] = matplotlib.colors.to_hex(cmap(ch/nCh), keep_alpha=False)\n",
    "        pass\n",
    "\n",
    "    #create a time freq viewer conencted to the same source\n",
    "    view2 = TimeFreqViewer(source=source, name='tfr')\n",
    "    view2.params['show_axis'] = False\n",
    "    view2.params['timefreq', 'deltafreq'] = 1\n",
    "    #view2.by_channel_params['ch3', 'visible'] = False\n",
    "    view2.auto_scale()\n",
    "\n",
    "    win.add_view(view1)\n",
    "    #win.add_view(view2)\n",
    "\n",
    "if False:#'LFP_DS' in combined:\n",
    "\n",
    "    if All_Spindle is not None:\n",
    "        #Create one data source with 3 event channel\n",
    "        all_events = []\n",
    "        conditions = ['All','Good','Bad']\n",
    "        for c,cond in enumerate(conditions):\n",
    "            match cond:\n",
    "                case 'All':\n",
    "                    selection = \"All_Spindle['toKeep'] | ~All_Spindle['toKeep']\"\n",
    "                case 'Good':\n",
    "                    selection = \"All_Spindle['toKeep']\"\n",
    "                case 'Bad':\n",
    "                    selection = \"~All_Spindle['toKeep']\"\n",
    "            ev_times = mbTools.convertTheoricIndex2realTime(All_Spindle.loc[pd.eval(selection),'peak time'].values, realFreq=sample_rates['LFP_DS'], offset=t_start['LFP_DS'])\n",
    "            ev_labels = [f'spindle {i}'for i in All_Spindle[pd.eval(selection)].index]\n",
    "            all_events.append({ 'time':ev_times, 'label':ev_labels, 'name': conditions[c] })\n",
    "        source_ev = InMemoryEventSource(all_events=all_events)\n",
    "\n",
    "        Spindle_peak = All_Spindle['peak time'].astype(int)\n",
    "        Spindle_start = All_Spindle['start time'].astype(int)\n",
    "        Spindle_end = All_Spindle['end time'].astype(int)\n",
    "\n",
    "        #create 2 familly scatters from theses 2 indexes\n",
    "        scatter_indexes = {0: Spindle_peak, 1: Spindle_start, 2: Spindle_end}\n",
    "        #and asign them to some channels each\n",
    "        scatter_channels = {0: [0], 1: [0], 2: [0]}\n",
    "        source = AnalogSignalSourceWithScatter(combined['LFP_DS'], sample_rates['LFP_DS'], t_start['LFP_DS'], scatter_indexes, scatter_channels)#, channel_names=channelLabels['LFP_DS']\n",
    "        view_Events = EventList(source=source_ev, name='event')\n",
    "        \n",
    "    else:\n",
    "        source = InMemoryAnalogSignalSource(combined['LFP_DS'], sample_rates['LFP_DS'], t_start['LFP_DS'], channel_names=channelLabels['LFP_DS'])\n",
    "        view_Events = None\n",
    "    view_DS = TraceViewer(source=source, name = 'LFP_DS')\n",
    "\n",
    "    #Parameters can be set in script\n",
    "    view_DS.params['display_labels'] = True\n",
    "    view_DS.params['scale_mode'] = 'same_for_all'\n",
    "    view_DS.auto_scale()\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"hsv\"]#Wistia\"]\n",
    "    nCh = len(view_DS.by_channel_params.children())\n",
    "    for ch in range(nCh):\n",
    "        #view_DS.by_channel_params[f'ch{ch}', 'gain'] = 0.00002\n",
    "        #view_DS.by_channel_params[f'ch{ch}', 'offset'] = 0.1\n",
    "        view_DS.by_channel_params[f'ch{ch}', 'color'] = matplotlib.colors.to_hex(cmap(ch/nCh), keep_alpha=False)\n",
    "        pass\n",
    "\n",
    "    win.add_view(view_DS)\n",
    "else:\n",
    "    view_Events=None\n",
    "\n",
    "\n",
    "if 'NPX' in combined:\n",
    "    sig_source = SpikeInterfaceRecordingSource(recording=combined['NPX'])\n",
    "    #view3 = TraceViewer.from_numpy(combined['NPX'], sample_rates['NPX'], t_start['NPX'], 'NPX', channel_names=channelLabels['NPX'])\n",
    "    view3 = TraceViewer(source=sig_source, name='NPX')\n",
    "    win.add_view(view3)\n",
    "\n",
    "    #Parameters can be set in script\n",
    "    view3.params['display_labels'] = True\n",
    "    view3.params['scale_mode'] = 'same_for_all'\n",
    "    view3.auto_scale()\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"hsv\"]#Wistia\"]\n",
    "    nCh = len(view3.by_channel_params.children())\n",
    "    for ch in range(nCh):\n",
    "        #view3.by_channel_params[f'ch{ch}', 'gain'] = 0.00002\n",
    "        #view3.by_channel_params[f'ch{ch}', 'offset'] = 0.1\n",
    "        view3.by_channel_params[f'ch{ch}', 'color'] = matplotlib.colors.to_hex(cmap(ch/nCh), keep_alpha=False)\n",
    "        pass\n",
    "\n",
    "if view_Events is not None:\n",
    "    win.add_view(view_Events)\n",
    "\n",
    "\n",
    "#Run\n",
    "win.show()\n",
    "#app.exec()  #if commented, the app is shown and fonctionnal. Maybe detecting buttons. the Python icon doesn't close any better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
