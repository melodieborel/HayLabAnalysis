{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7dda0d",
   "metadata": {},
   "source": [
    "# Spike sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4cdd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reAnalyse = True\n",
    "engine = \"dask\"\n",
    "GPU_available = True\n",
    "sorterFolder='kilosort4_output'\n",
    "training_folder = 'sorting_analyzer_training'\n",
    "fullAnalyzer_folder = 'sorting_analyzer_full'\n",
    "whitenFirst = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd66156",
   "metadata": {},
   "source": [
    "## Set up everything\n",
    "You shouldn't have to change anything from here so you can keep that part folded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b006d50",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c2661-565d-4949-aa45-d44200c20f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import submitit\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import asyncio\n",
    "import gc\n",
    "\n",
    "#import HayLabAnalysis as hla\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython import get_ipython\n",
    "import IPython\n",
    "from IPython.display import Javascript\n",
    "import pickleshare\n",
    "\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e190a",
   "metadata": {},
   "source": [
    "### Define a few variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cf29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_extract = 2 #min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac2f4e",
   "metadata": {},
   "source": [
    "#### Structural (important for the process but no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e310982",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_job=None\n",
    "sorter='kilosort4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ed711",
   "metadata": {},
   "source": [
    "### Define a few functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4a6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magicretrieve(stored_var):\n",
    "   # myvar will contain the variable previously stored with \"%store test\"\n",
    "   myvar_filename = get_ipython().ipython_dir + '/profile_default/db/autorestore/' + stored_var\n",
    "   with open(myvar_filename, 'rb') as f:\n",
    "      return pickle.load(f)\n",
    "\n",
    "def magicstore(stored_var, value):\n",
    "   # myvar will contain the variable previously stored with \"%store test\"\n",
    "   myvar_filename = get_ipython().ipython_dir + '/profile_default/db/autorestore/' + stored_var\n",
    "   with open(myvar_filename, 'wb') as f:\n",
    "      pickle.dump(value,f)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbf1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_my_expe_choice(chooser):\n",
    "    currentFile_data = str(chooser.selected)\n",
    "    currentFile_mnt = os.path.join('/mnt/data/ahay',os.path.split(currentFile_data)[1])\n",
    "    if not currentFile_data.startswith('/crnldata/'):\n",
    "        print('please make sure to select the file on crnldata')\n",
    "        return\n",
    "    # check if the file already exists on /mnt/\n",
    "    if os.path.isfile(currentFile_mnt):\n",
    "        print(f\"{currentFile_mnt} already exists\")\n",
    "    else:\n",
    "        print(f\"there is no version of {currentFile_data} on /mnt/\")\n",
    "        shouldCopy = False # it took a while (20 min for a file of about 150Gb)\n",
    "        if shouldCopy:\n",
    "            print(f'it will be copied to {currentFile_mnt}')\n",
    "            startTime = time.time()\n",
    "            shutil.copyfile(currentFile_data, currentFile_mnt)\n",
    "            print(f'the transfer is complete, it took {time.time()-startTime} seconds')\n",
    "        else:\n",
    "            print('it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources')\n",
    "\n",
    "    magicstore('currentFile_data', currentFile_data)\n",
    "    magicstore('currentFile_mnt', currentFile_mnt)\n",
    "\n",
    "\n",
    "def selectData(currentFile):\n",
    "    print(currentFile)\n",
    "    if currentFile is not None:\n",
    "        pathName, fileName = os.path.split(currentFile)\n",
    "    else:\n",
    "        pathName = '/crnldata/waking/audrey_hay/'\n",
    "        fileName = ''\n",
    "    fc = FileChooser(path=pathName, filename=fileName, filter_pattern='NP_spikes_*.raw', select_default=True, show_only_dirs = False, title = \"<b>Select file on crnldata</b>\")\n",
    "    display(fc)\n",
    "\n",
    "    # Register callback function\n",
    "    fc.register_callback(update_my_expe_choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a4a6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def runFunction(engine,funcName,*params,**engineParams):\n",
    "    start_time = time.time()\n",
    "    match engine:\n",
    "        case \"dask\":\n",
    "            print(\"dask\")\n",
    "            cluster = SLURMCluster(\n",
    "                                **engineParams,\n",
    "                                log_directory=\"si_dask_logs\",\n",
    "                                scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                                )\n",
    "            cluster.scale(1)\n",
    "            client = Client(cluster)\n",
    "\n",
    "            print(client.get_versions(check=True))\n",
    "    \n",
    "            \"\"\"\n",
    "            from dask.distributed import PipInstall\n",
    "            plugin = PipInstall(packages=[\"git+https://github.com/SpikeInterface/spikeinterface.git\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            plugin = PipInstall(packages=[\"git+https://github.com/SpikeInterface/probeinterface.git\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            plugin = PipInstall(packages=[\"git+https://github.com/SpikeInterface/spikeinterface-gui.git\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            plugin = PipInstall(packages=[\"kilosort\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "\n",
    "            plugin = PipInstall(packages=[\"numpy\"], pip_options=[\"--upgrade\"])\n",
    "            client.register_plugin(plugin)\n",
    "            \"\"\"\n",
    "\n",
    "            \n",
    "            print(cluster.job_script()) \n",
    "\n",
    "            future = client.submit(funcName, *params)\n",
    "            res = future.result()\n",
    "            \n",
    "            #recording_layers = preprocess_traces(raw_rec)\n",
    "            print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "            # Close cluster\n",
    "            client.close()\n",
    "            cluster.close()\n",
    "\n",
    "            return res\n",
    "        \n",
    "        case \"submitit\":\n",
    "            print(\"submitit\")\n",
    "\n",
    "            executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "            executor.update_parameters(**engineParams)\n",
    "\n",
    "            job = executor.submit(funcName, *params)\n",
    "\n",
    "            # print the ID of your job\n",
    "            print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "            # await a single result\n",
    "            await job.awaitable().results()\n",
    "            print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")\n",
    "\n",
    "            return job.result()\n",
    "\n",
    "        case _:\n",
    "            print(\"no engine\")\n",
    "\n",
    "            return funcName(*params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b539b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateDict(rec, probe, folder, **sorter_params):\n",
    "    rec = rec.set_probe(probe)\n",
    "    si.set_global_job_kwargs(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    sorting = si.run_sorter(sorter, rec, verbose=True, folder=folder, remove_existing_folder=True, **sorter_params)\n",
    "    return sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484a0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_analyzer(sorting,rec,probe,folder,append=False):\n",
    "\n",
    "    rec = rec.set_probe(probe)\n",
    "    si.set_global_job_kwargs(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    \n",
    "    if append:\n",
    "        sorting_analyzer = si.load_sorting_analyzer(folder)\n",
    "    else:\n",
    "        sorting_analyzer = si.create_sorting_analyzer(sorting, rec, sparse=True, folder=folder,overwrite=True)\n",
    "\n",
    "    sorting_analyzer.compute(\"random_spikes\", method=\"uniform\", max_spikes_per_unit=500)\n",
    "    sorting_analyzer.compute(\"waveforms\")\n",
    "    sorting_analyzer.compute(\"templates\")\n",
    "    sorting_analyzer.compute(\"noise_levels\")\n",
    "    sorting_analyzer.compute(\"unit_locations\", method=\"monopolar_triangulation\")\n",
    "    sorting_analyzer.compute(\"isi_histograms\")\n",
    "    sorting_analyzer.compute(\"correlograms\") #, window_ms=100, bin_ms=5.\n",
    "    sorting_analyzer.compute(\"principal_components\", n_components=3, mode='by_channel_global', whiten=True)\n",
    "    sorting_analyzer.compute(\"quality_metrics\", metric_names=[\"snr\", \"firing_rate\"])\n",
    "    sorting_analyzer.compute(\"template_similarity\")\n",
    "    sorting_analyzer.compute(\"spike_amplitudes\")\n",
    "\n",
    "\n",
    "    #sorting_analyzer.save_as(folder=folder, format='binary_folder')\n",
    "\n",
    "    #return sorting_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "017793bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_traces(rec):\n",
    "    # filter traces\n",
    "    rec = rec.astype('float32')\n",
    "    rec_filt = si.bandpass_filter(rec)\n",
    "    display(rec_filt)\n",
    "\n",
    "    # Remove bad channels\n",
    "    try:\n",
    "        bad_channel_ids, channel_labels = si.detect_bad_channels(rec_filt)\n",
    "        print('bad_channel_ids', bad_channel_ids)\n",
    "        rec_filt = rec_filt.remove_channels(bad_channel_ids)\n",
    "    except Exception as error:\n",
    "        print(\"could not remove bad channels because there was an error:\")\n",
    "        print(error)\n",
    "\n",
    "    # Account for the slight delays in recordings due to the fact the 384 channels are only digitilized with 32 ADCs\n",
    "\n",
    "    inter_sample_shift=[0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                           0., 0., 0.07692308, 0.07692308, 0.15384615, 0.15384615, 0.23076923, 0.23076923, 0.30769231, 0.30769231,\n",
    "                         0.38461538, 0.38461538, 0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462, 0.69230769,\n",
    "                           0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
    "                               ]\n",
    "    rec_filt_shifted = si.phase_shift(rec_filt, inter_sample_shift=inter_sample_shift)\n",
    "\n",
    "    # Remove the common noisy events (artefacts)\n",
    "    rec_filt_ref = si.common_reference(rec_filt_shifted)\n",
    "    display(rec_filt_ref)\n",
    "\n",
    "    recording_layers = dict(\n",
    "        raw = rec,\n",
    "        filter = rec_filt,\n",
    "        realigned = rec_filt_shifted,\n",
    "        cmr = rec_filt_ref,\n",
    "    )\n",
    "    #si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'\n",
    "\n",
    "    return recording_layers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_drift(rec, probe):      \n",
    "    rec = rec.set_probe(probe)\n",
    "\n",
    "    job_kwargs_global = dict(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    si.set_global_job_kwargs(**job_kwargs_global)\n",
    "    \n",
    "    recording_corrected, motion, motion_info = si.correct_motion(\n",
    "            rec, preset=\"dredge_fast\", folder=None, output_motion=True, output_motion_info=True, estimate_motion_kwargs=dict(rigid=True)#,\n",
    "        )\n",
    "    return recording_corrected, motion, motion_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d616f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiten(rec,recording_layers,layerName):\n",
    "\n",
    "    rec_whitened = si.WhitenRecording(rec)\n",
    "\n",
    "    recording_layers[layerName] = rec_whitened\n",
    "\n",
    "    return recording_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339081a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRessources():\n",
    "    # check node and CPU information\n",
    "    print(\"### Node counts: \\nA: currently in use \\B available\")\n",
    "    !sinfo -o%A\n",
    "    print(\"### CPU counts: \\nA: core currently in use \\nI: available \\nO: unavailable (maintenance, down, etc) \\nT: total\")\n",
    "    !sinfo -o%C\n",
    "    !sinfo\n",
    "\n",
    "    # check some stats of our last job\n",
    "    if last_job is not None:\n",
    "        print('### CPU time and MaxRSS of our last job (about 1000Mb should be added to your MaxRSS (Mb) in order to cover safely the memory needs of the python runtime)###')\n",
    "        os.system(f'sacct -j {last_job.job_id} --format=\"CPUTime,MaxRSS\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a24596",
   "metadata": {},
   "source": [
    "## Choose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dc444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16/NP_spikes_2024-07-22T17_55_16.raw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522b10cd0a4e4f0fb3d80dd06fe61134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16', filename='NP_spikes_2024-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#currentFile_data = '/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16/NP_spikes_2024-07-22T17_55_16.raw'\n",
    "#hla.tools.magicstore('currentFile_data', currentFile_data)\n",
    "currentFile_data = magicretrieve('currentFile_data')\n",
    "selectData(currentFile_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8669ae",
   "metadata": {},
   "source": [
    "### Move data to /mnt/ if appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbf2a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shouldCopy = False # it took a while (20 min for a file of about 150Gb)\n",
    "if shouldCopy:\n",
    "    currentFile_data = magicretrieve('currentFile_data')\n",
    "    currentFile_mnt = magicretrieve('currentFile_mnt')\n",
    "    print(f'The file {currentFile_data} will be copied to {currentFile_mnt}')\n",
    "    startTime = time.time()\n",
    "    shutil.copyfile(currentFile_data, currentFile_mnt)\n",
    "    print(f'the transfer is complete, it took {time.time()-startTime} seconds')\n",
    "else:\n",
    "    print('it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532274e",
   "metadata": {},
   "source": [
    "### Lazy load data and probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8606c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFile_data = magicretrieve('currentFile_data')\n",
    "currentFile_mnt = magicretrieve('currentFile_mnt')\n",
    "\n",
    "raw_rec = si.read_binary(currentFile_mnt, dtype='uint16', num_channels=384, sampling_frequency=30_000.,gain_to_uV=-1)\n",
    "raw_rec.annotate(raw_path = currentFile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3d0a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spikeinterface.widgets.probe_map.ProbeMapWidget at 0x7f17b3aaae50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a546db70c54f6a83ff4737869a2c49",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('/crnldata/waking/audrey_hay/NPX/NPXprobe.pkl', 'rb') as outp: \n",
    "    probe = pickle.load(outp)\n",
    "probe.set_device_channel_indices(np.arange(384))\n",
    "\n",
    "raw_rec = raw_rec.set_probe(probe)\n",
    "display(si.plot_probe_map(raw_rec, with_channel_ids=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a43680",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c250e0",
   "metadata": {},
   "source": [
    "### Filter and apply common ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f39f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e si_dask_logs/dask-worker-%J.err\n",
      "#SBATCH -o si_dask_logs/dask-worker-%J.out\n",
      "#SBATCH -p CPU\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=1\n",
      "#SBATCH --mem=3G\n",
      "#SBATCH -t 00:02:00\n",
      "\n",
      "/home/audrey.hay/HayLabAnalysis/.si-env/bin/python -m distributed.cli.dask_worker tcp://10.69.168.93:37637 --name dummy-name --nthreads 1 --memory-limit 2.79GiB --nanny --death-timeout 60\n",
      "\n",
      "job done in 18.179140329360962 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76d4cb6a13d447ea0660dd4f68833d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(TimeSlider(children=(Dropdown(description='segment', options=(0,), value=0), Button(icon='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if engine==\"dask\":\n",
    "    # takes about 15s\n",
    "    cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"3GB\",\n",
    "                        walltime=\"00:02:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(preprocess_traces, raw_rec)\n",
    "    recording_layers = future.result() \n",
    "\n",
    "\n",
    "    #recording_layers = preprocess_traces(raw_rec)\n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b49c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if engine==\"submitit\":\n",
    "    # takes less than 10s\n",
    "    start_time = time.time()\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    executor.update_parameters(mem_gb=3, timeout_min=2, slurm_partition=\"CPU\", cpus_per_task=4)\n",
    "    job = executor.submit(preprocess_traces, raw_rec)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")\n",
    "\n",
    "    last_job = job\n",
    "    recording_layers = job.result()\n",
    "\n",
    "    si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637e35e",
   "metadata": {},
   "source": [
    "### Correct for motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8efb7e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>WhitenRecording: 384 channels - 30.0kHz - 1 segments - 189,418,428 samples - 6,313.95s (1.75 hours) - float32 dtype - 270.97 GiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
       "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
       "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
       "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
       "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
       "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
       " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
       " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
       " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
       " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
       " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
       " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
       " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
       " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
       " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
       " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
       " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
       " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
       " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
       " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
       " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
       " 378 379 380 381 382 383] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: True</li><li> <strong> name </strong>: None</li></ul> </details><details style='margin-left: 10px;'><summary><strong>Channel Properties</strong></summary><ul><details><summary> <strong> gain_to_uV </strong> </summary>[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
       " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]</details><details><summary> <strong> group </strong> </summary>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]</details><details><summary> <strong> location </strong> </summary>[[  16.    0.]\n",
       " [  48.    0.]\n",
       " [   0.   20.]\n",
       " [  32.   20.]\n",
       " [  16.   40.]\n",
       " [  48.   40.]\n",
       " [   0.   60.]\n",
       " [  32.   60.]\n",
       " [  16.   80.]\n",
       " [  48.   80.]\n",
       " [   0.  100.]\n",
       " [  32.  100.]\n",
       " [  16.  120.]\n",
       " [  48.  120.]\n",
       " [   0.  140.]\n",
       " [  32.  140.]\n",
       " [  16.  160.]\n",
       " [  48.  160.]\n",
       " [   0.  180.]\n",
       " [  32.  180.]\n",
       " [  16.  200.]\n",
       " [  48.  200.]\n",
       " [   0.  220.]\n",
       " [  32.  220.]\n",
       " [  16.  240.]\n",
       " [  48.  240.]\n",
       " [   0.  260.]\n",
       " [  32.  260.]\n",
       " [  16.  280.]\n",
       " [  48.  280.]\n",
       " [   0.  300.]\n",
       " [  32.  300.]\n",
       " [  16.  320.]\n",
       " [  48.  320.]\n",
       " [   0.  340.]\n",
       " [  32.  340.]\n",
       " [  16.  360.]\n",
       " [  48.  360.]\n",
       " [   0.  380.]\n",
       " [  32.  380.]\n",
       " [  16.  400.]\n",
       " [  48.  400.]\n",
       " [   0.  420.]\n",
       " [  32.  420.]\n",
       " [  16.  440.]\n",
       " [  48.  440.]\n",
       " [   0.  460.]\n",
       " [  32.  460.]\n",
       " [  16.  480.]\n",
       " [  48.  480.]\n",
       " [   0.  500.]\n",
       " [  32.  500.]\n",
       " [  16.  520.]\n",
       " [  48.  520.]\n",
       " [   0.  540.]\n",
       " [  32.  540.]\n",
       " [  16.  560.]\n",
       " [  48.  560.]\n",
       " [   0.  580.]\n",
       " [  32.  580.]\n",
       " [  16.  600.]\n",
       " [  48.  600.]\n",
       " [   0.  620.]\n",
       " [  32.  620.]\n",
       " [  16.  640.]\n",
       " [  48.  640.]\n",
       " [   0.  660.]\n",
       " [  32.  660.]\n",
       " [  16.  680.]\n",
       " [  48.  680.]\n",
       " [   0.  700.]\n",
       " [  32.  700.]\n",
       " [  16.  720.]\n",
       " [  48.  720.]\n",
       " [   0.  740.]\n",
       " [  32.  740.]\n",
       " [  16.  760.]\n",
       " [  48.  760.]\n",
       " [   0.  780.]\n",
       " [  32.  780.]\n",
       " [  16.  800.]\n",
       " [  48.  800.]\n",
       " [   0.  820.]\n",
       " [  32.  820.]\n",
       " [  16.  840.]\n",
       " [  48.  840.]\n",
       " [   0.  860.]\n",
       " [  32.  860.]\n",
       " [  16.  880.]\n",
       " [  48.  880.]\n",
       " [   0.  900.]\n",
       " [  32.  900.]\n",
       " [  16.  920.]\n",
       " [  48.  920.]\n",
       " [   0.  940.]\n",
       " [  32.  940.]\n",
       " [  16.  960.]\n",
       " [  48.  960.]\n",
       " [   0.  980.]\n",
       " [  32.  980.]\n",
       " [  16. 1000.]\n",
       " [  48. 1000.]\n",
       " [   0. 1020.]\n",
       " [  32. 1020.]\n",
       " [  16. 1040.]\n",
       " [  48. 1040.]\n",
       " [   0. 1060.]\n",
       " [  32. 1060.]\n",
       " [  16. 1080.]\n",
       " [  48. 1080.]\n",
       " [   0. 1100.]\n",
       " [  32. 1100.]\n",
       " [  16. 1120.]\n",
       " [  48. 1120.]\n",
       " [   0. 1140.]\n",
       " [  32. 1140.]\n",
       " [  16. 1160.]\n",
       " [  48. 1160.]\n",
       " [   0. 1180.]\n",
       " [  32. 1180.]\n",
       " [  16. 1200.]\n",
       " [  48. 1200.]\n",
       " [   0. 1220.]\n",
       " [  32. 1220.]\n",
       " [  16. 1240.]\n",
       " [  48. 1240.]\n",
       " [   0. 1260.]\n",
       " [  32. 1260.]\n",
       " [  16. 1280.]\n",
       " [  48. 1280.]\n",
       " [   0. 1300.]\n",
       " [  32. 1300.]\n",
       " [  16. 1320.]\n",
       " [  48. 1320.]\n",
       " [   0. 1340.]\n",
       " [  32. 1340.]\n",
       " [  16. 1360.]\n",
       " [  48. 1360.]\n",
       " [   0. 1380.]\n",
       " [  32. 1380.]\n",
       " [  16. 1400.]\n",
       " [  48. 1400.]\n",
       " [   0. 1420.]\n",
       " [  32. 1420.]\n",
       " [  16. 1440.]\n",
       " [  48. 1440.]\n",
       " [   0. 1460.]\n",
       " [  32. 1460.]\n",
       " [  16. 1480.]\n",
       " [  48. 1480.]\n",
       " [   0. 1500.]\n",
       " [  32. 1500.]\n",
       " [  16. 1520.]\n",
       " [  48. 1520.]\n",
       " [   0. 1540.]\n",
       " [  32. 1540.]\n",
       " [  16. 1560.]\n",
       " [  48. 1560.]\n",
       " [   0. 1580.]\n",
       " [  32. 1580.]\n",
       " [  16. 1600.]\n",
       " [  48. 1600.]\n",
       " [   0. 1620.]\n",
       " [  32. 1620.]\n",
       " [  16. 1640.]\n",
       " [  48. 1640.]\n",
       " [   0. 1660.]\n",
       " [  32. 1660.]\n",
       " [  16. 1680.]\n",
       " [  48. 1680.]\n",
       " [   0. 1700.]\n",
       " [  32. 1700.]\n",
       " [  16. 1720.]\n",
       " [  48. 1720.]\n",
       " [   0. 1740.]\n",
       " [  32. 1740.]\n",
       " [  16. 1760.]\n",
       " [  48. 1760.]\n",
       " [   0. 1780.]\n",
       " [  32. 1780.]\n",
       " [  16. 1800.]\n",
       " [  48. 1800.]\n",
       " [   0. 1820.]\n",
       " [  32. 1820.]\n",
       " [  16. 1840.]\n",
       " [  48. 1840.]\n",
       " [   0. 1860.]\n",
       " [  32. 1860.]\n",
       " [  16. 1880.]\n",
       " [  48. 1880.]\n",
       " [   0. 1900.]\n",
       " [  32. 1900.]\n",
       " [  16. 1920.]\n",
       " [  48. 1920.]\n",
       " [   0. 1940.]\n",
       " [  32. 1940.]\n",
       " [  16. 1960.]\n",
       " [  48. 1960.]\n",
       " [   0. 1980.]\n",
       " [  32. 1980.]\n",
       " [  16. 2000.]\n",
       " [  48. 2000.]\n",
       " [   0. 2020.]\n",
       " [  32. 2020.]\n",
       " [  16. 2040.]\n",
       " [  48. 2040.]\n",
       " [   0. 2060.]\n",
       " [  32. 2060.]\n",
       " [  16. 2080.]\n",
       " [  48. 2080.]\n",
       " [   0. 2100.]\n",
       " [  32. 2100.]\n",
       " [  16. 2120.]\n",
       " [  48. 2120.]\n",
       " [   0. 2140.]\n",
       " [  32. 2140.]\n",
       " [  16. 2160.]\n",
       " [  48. 2160.]\n",
       " [   0. 2180.]\n",
       " [  32. 2180.]\n",
       " [  16. 2200.]\n",
       " [  48. 2200.]\n",
       " [   0. 2220.]\n",
       " [  32. 2220.]\n",
       " [  16. 2240.]\n",
       " [  48. 2240.]\n",
       " [   0. 2260.]\n",
       " [  32. 2260.]\n",
       " [  16. 2280.]\n",
       " [  48. 2280.]\n",
       " [   0. 2300.]\n",
       " [  32. 2300.]\n",
       " [  16. 2320.]\n",
       " [  48. 2320.]\n",
       " [   0. 2340.]\n",
       " [  32. 2340.]\n",
       " [  16. 2360.]\n",
       " [  48. 2360.]\n",
       " [   0. 2380.]\n",
       " [  32. 2380.]\n",
       " [  16. 2400.]\n",
       " [  48. 2400.]\n",
       " [   0. 2420.]\n",
       " [  32. 2420.]\n",
       " [  16. 2440.]\n",
       " [  48. 2440.]\n",
       " [   0. 2460.]\n",
       " [  32. 2460.]\n",
       " [  16. 2480.]\n",
       " [  48. 2480.]\n",
       " [   0. 2500.]\n",
       " [  32. 2500.]\n",
       " [  16. 2520.]\n",
       " [  48. 2520.]\n",
       " [   0. 2540.]\n",
       " [  32. 2540.]\n",
       " [  16. 2560.]\n",
       " [  48. 2560.]\n",
       " [   0. 2580.]\n",
       " [  32. 2580.]\n",
       " [  16. 2600.]\n",
       " [  48. 2600.]\n",
       " [   0. 2620.]\n",
       " [  32. 2620.]\n",
       " [  16. 2640.]\n",
       " [  48. 2640.]\n",
       " [   0. 2660.]\n",
       " [  32. 2660.]\n",
       " [  16. 2680.]\n",
       " [  48. 2680.]\n",
       " [   0. 2700.]\n",
       " [  32. 2700.]\n",
       " [  16. 2720.]\n",
       " [  48. 2720.]\n",
       " [   0. 2740.]\n",
       " [  32. 2740.]\n",
       " [  16. 2760.]\n",
       " [  48. 2760.]\n",
       " [   0. 2780.]\n",
       " [  32. 2780.]\n",
       " [  16. 2800.]\n",
       " [  48. 2800.]\n",
       " [   0. 2820.]\n",
       " [  32. 2820.]\n",
       " [  16. 2840.]\n",
       " [  48. 2840.]\n",
       " [   0. 2860.]\n",
       " [  32. 2860.]\n",
       " [  16. 2880.]\n",
       " [  48. 2880.]\n",
       " [   0. 2900.]\n",
       " [  32. 2900.]\n",
       " [  16. 2920.]\n",
       " [  48. 2920.]\n",
       " [   0. 2940.]\n",
       " [  32. 2940.]\n",
       " [  16. 2960.]\n",
       " [  48. 2960.]\n",
       " [   0. 2980.]\n",
       " [  32. 2980.]\n",
       " [  16. 3000.]\n",
       " [  48. 3000.]\n",
       " [   0. 3020.]\n",
       " [  32. 3020.]\n",
       " [  16. 3040.]\n",
       " [  48. 3040.]\n",
       " [   0. 3060.]\n",
       " [  32. 3060.]\n",
       " [  16. 3080.]\n",
       " [  48. 3080.]\n",
       " [   0. 3100.]\n",
       " [  32. 3100.]\n",
       " [  16. 3120.]\n",
       " [  48. 3120.]\n",
       " [   0. 3140.]\n",
       " [  32. 3140.]\n",
       " [  16. 3160.]\n",
       " [  48. 3160.]\n",
       " [   0. 3180.]\n",
       " [  32. 3180.]\n",
       " [  16. 3200.]\n",
       " [  48. 3200.]\n",
       " [   0. 3220.]\n",
       " [  32. 3220.]\n",
       " [  16. 3240.]\n",
       " [  48. 3240.]\n",
       " [   0. 3260.]\n",
       " [  32. 3260.]\n",
       " [  16. 3280.]\n",
       " [  48. 3280.]\n",
       " [   0. 3300.]\n",
       " [  32. 3300.]\n",
       " [  16. 3320.]\n",
       " [  48. 3320.]\n",
       " [   0. 3340.]\n",
       " [  32. 3340.]\n",
       " [  16. 3360.]\n",
       " [  48. 3360.]\n",
       " [   0. 3380.]\n",
       " [  32. 3380.]\n",
       " [  16. 3400.]\n",
       " [  48. 3400.]\n",
       " [   0. 3420.]\n",
       " [  32. 3420.]\n",
       " [  16. 3440.]\n",
       " [  48. 3440.]\n",
       " [   0. 3460.]\n",
       " [  32. 3460.]\n",
       " [  16. 3480.]\n",
       " [  48. 3480.]\n",
       " [   0. 3500.]\n",
       " [  32. 3500.]\n",
       " [  16. 3520.]\n",
       " [  48. 3520.]\n",
       " [   0. 3540.]\n",
       " [  32. 3540.]\n",
       " [  16. 3560.]\n",
       " [  48. 3560.]\n",
       " [   0. 3580.]\n",
       " [  32. 3580.]\n",
       " [  16. 3600.]\n",
       " [  48. 3600.]\n",
       " [   0. 3620.]\n",
       " [  32. 3620.]\n",
       " [  16. 3640.]\n",
       " [  48. 3640.]\n",
       " [   0. 3660.]\n",
       " [  32. 3660.]\n",
       " [  16. 3680.]\n",
       " [  48. 3680.]\n",
       " [   0. 3700.]\n",
       " [  32. 3700.]\n",
       " [  16. 3720.]\n",
       " [  48. 3720.]\n",
       " [   0. 3740.]\n",
       " [  32. 3740.]\n",
       " [  16. 3760.]\n",
       " [  48. 3760.]\n",
       " [   0. 3780.]\n",
       " [  32. 3780.]\n",
       " [  16. 3800.]\n",
       " [  48. 3800.]\n",
       " [   0. 3820.]\n",
       " [  32. 3820.]]</details></ul></details>"
      ],
      "text/plain": [
       "WhitenRecording: 384 channels - 30.0kHz - 1 segments - 189,418,428 samples \n",
       "                 6,313.95s (1.75 hours) - float32 dtype - 270.97 GiB"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "canal_lim=383 #limitation of canals to keep for drift correction\n",
    "probe_2_correct = probe.get_slice(np.arange(canal_lim))\n",
    "#TODO : investigate the rigid correction\n",
    "\n",
    "if whitenFirst:\n",
    "    recording_layers = whiten(recording_layers[\"cmr\"],recording_layers,\"whitenFirst\")\n",
    "    rec_2_correct = recording_layers[\"whitenFirst\"]\n",
    "else:\n",
    "    rec_2_correct = recording_layers[\"cmr\"]\n",
    "\n",
    "rec_2_correct_short = rec_2_correct.channel_slice(np.arange(0,canal_lim))\n",
    "display(rec_2_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ef37904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask\n",
      "{'scheduler': {'host': {'python': '3.11.2.final.0', 'python-bits': 64, 'OS': 'Linux', 'OS-release': '6.1.0-22-amd64', 'machine': 'x86_64', 'processor': '', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'fr_FR.UTF-8'}, 'packages': {'python': '3.11.2.final.0', 'dask': '2024.11.2', 'distributed': '2024.11.2', 'msgpack': '1.1.0', 'cloudpickle': '3.0.0', 'tornado': '6.4.1', 'toolz': '0.12.1', 'numpy': '1.26.3', 'pandas': '2.2.2', 'lz4': None}}, 'workers': {}, 'client': {'host': {'python': '3.11.2.final.0', 'python-bits': 64, 'OS': 'Linux', 'OS-release': '6.1.0-22-amd64', 'machine': 'x86_64', 'processor': '', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'fr_FR.UTF-8'}, 'packages': {'python': '3.11.2.final.0', 'dask': '2024.11.2', 'distributed': '2024.11.2', 'msgpack': '1.1.0', 'cloudpickle': '3.0.0', 'tornado': '6.4.1', 'toolz': '0.12.1', 'numpy': '1.26.3', 'pandas': '2.2.2', 'lz4': None}}}\n",
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e si_dask_logs/dask-worker-%J.err\n",
      "#SBATCH -o si_dask_logs/dask-worker-%J.out\n",
      "#SBATCH -p CPU\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=55\n",
      "#SBATCH --mem=47G\n",
      "#SBATCH -t 01:00:00\n",
      "\n",
      "/home/audrey.hay/HayLabAnalysis/.si-env/bin/python -m distributed.cli.dask_worker tcp://10.69.168.93:38207 --name dummy-name --nthreads 1 --memory-limit 46.57GiB --no-nanny --death-timeout 60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/audrey.hay/HayLabAnalysis/.si-env/lib/python3.11/site-packages/distributed/node.py:187: UserWarning: Port 8780 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37603 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "estimate_motion() got multiple values for argument 'recording'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m         engineParam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m---> 34\u001b[0m recording_corrected_short, motion, motion_info  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m runFunction(engine,check_drift,rec_2_correct_short, probe_2_correct, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengineParam)\n\u001b[1;32m     36\u001b[0m recording_layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrected\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m recording_corrected\n\u001b[1;32m     37\u001b[0m display(motion)\n",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m, in \u001b[0;36mrunFunction\u001b[0;34m(engine, funcName, *params, **engineParams)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(cluster\u001b[38;5;241m.\u001b[39mjob_script()) \n\u001b[1;32m     34\u001b[0m future \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39msubmit(funcName, \u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 35\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#recording_layers = preprocess_traces(raw_rec)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob done in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/HayLabAnalysis/.si-env/lib/python3.11/site-packages/distributed/client.py:402\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_initialized()\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 7\u001b[0m, in \u001b[0;36mcheck_drift\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m job_kwargs_global \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, chunk_duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m si\u001b[38;5;241m.\u001b[39mset_global_job_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjob_kwargs_global)\n\u001b[0;32m----> 7\u001b[0m recording_corrected, motion, motion_info \u001b[38;5;241m=\u001b[39m si\u001b[38;5;241m.\u001b[39mcorrect_motion(\n\u001b[1;32m      8\u001b[0m         rec, preset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdredge_fast\u001b[39m\u001b[38;5;124m\"\u001b[39m, folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_motion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, output_motion_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, estimate_motion_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(recording\u001b[38;5;241m=\u001b[39mrec,rigid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;66;03m#,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recording_corrected, motion, motion_info\n",
      "File \u001b[0;32m~/HayLabAnalysis/.si-env/lib/python3.11/site-packages/spikeinterface/preprocessing/motion.py:436\u001b[0m, in \u001b[0;36mcorrect_motion\u001b[0;34m()\u001b[0m\n\u001b[1;32m    429\u001b[0m     run_times \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    430\u001b[0m         detect_peaks\u001b[38;5;241m=\u001b[39mt1 \u001b[38;5;241m-\u001b[39m t0,\n\u001b[1;32m    431\u001b[0m         select_peaks\u001b[38;5;241m=\u001b[39mt2 \u001b[38;5;241m-\u001b[39m t1,\n\u001b[1;32m    432\u001b[0m         localize_peaks\u001b[38;5;241m=\u001b[39mt3 \u001b[38;5;241m-\u001b[39m t2,\n\u001b[1;32m    433\u001b[0m     )\n\u001b[1;32m    435\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 436\u001b[0m motion \u001b[38;5;241m=\u001b[39m estimate_motion(recording, peaks, peak_locations, progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mestimate_motion_kwargs)\n\u001b[1;32m    437\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    438\u001b[0m run_times[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimate_motion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m t1 \u001b[38;5;241m-\u001b[39m t0\n",
      "\u001b[0;31mTypeError\u001b[0m: estimate_motion() got multiple values for argument 'recording'"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    engine=\"dask\"\n",
    "    GPU_available=False\n",
    "    if reAnalyse:\n",
    "        match engine,GPU_available:\n",
    "            case \"dask\", True | False:\n",
    "                engineParam=dict(\n",
    "                                    queue='CPU',\n",
    "                                    cores=1,\n",
    "                                    memory=\"50GB\",\n",
    "                                    job_cpu=55,\n",
    "                                    nanny=False,\n",
    "                                    walltime=\"01:00:00\",\n",
    "                )\n",
    "            case \"submitit\", True:\n",
    "                engineParam=dict(\n",
    "                                    slurm_array_parallelism=40,\n",
    "                                    mem_gb=16,\n",
    "                                    timeout_min=20,\n",
    "                                    slurm_partition=\"GPU\",\n",
    "                                    cpus_per_task=2\n",
    "                )\n",
    "            case \"submitit\", False:\n",
    "                engineParam=dict(\n",
    "                                    slurm_array_parallelism=4,\n",
    "                                    mem_gb=60,\n",
    "                                    timeout_min=20,\n",
    "                                    slurm_partition=\"CPU\",\n",
    "                                    cpus_per_task=40\n",
    "                )\n",
    "            case _:\n",
    "                engineParam = dict()\n",
    "\n",
    "        recording_corrected_short, motion, motion_info  = await runFunction(engine,check_drift,rec_2_correct_short, probe_2_correct, **engineParam)\n",
    "\n",
    "        recording_layers[\"corrected\"] = recording_corrected_short\n",
    "        display(motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (72) 16 min (slurm_array_parallelism=4, mem_gb=60, timeout_min=20, slurm_partition=\"CPU\", cpus_per_task=40)\n",
    "print(\"\"\"rq: you should avoid submitting multiple small tasks with submitit, which would create many independent jobs\n",
    "      and possibly overload the cluster, while you can do it without any problem through dask.distributed.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7225843",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_motion_info(motion_info, recording_corrected,\n",
    "                   color_amplitude=True,\n",
    "        amplitude_cmap=\"inferno\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not whitenFirst:\n",
    "    recording_layers = whiten(recording_corrected,recording_layers,\"whitenLast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28144436",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if whitenFirst:\n",
    "    #rec = recording_layers[\"whitenFirst\"] #if whitened and not corrected\n",
    "    rec = recording_layers[\"corrected\"] #if whitened then corrected\n",
    "else:\n",
    "    rec = recording_layers[\"whitenLast\"] #if corrected the whiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9470dc2",
   "metadata": {},
   "source": [
    "## Identify spike clusters for the first few minutes of recording"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df08855",
   "metadata": {},
   "source": [
    "It is good practice to have a look at available ressources and current use of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkRessources()\n",
    "\n",
    "#!sinfo --nodes=node15 -o \"%50N  %10c  %20m  %30G \"\n",
    "!squeue --partition=\"GPU\"\n",
    "\n",
    "#torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 712.00 MiB. GPU 0 has a total capacity of 79.26 GiB of which 187.19 MiB is free. Process 1619368 has 77.78 GiB memory in use. Including non-PyTorch memory, this process has 1.28 GiB memory in use. Of the allocated memory 529.55 MiB is allocated by PyTorch, and 276.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for information, display a list of all parameters that can be modified for the sorter\n",
    "params = si.get_default_sorter_params(sorter_name_or_class=sorter)\n",
    "print(f\"For information, parameters that are available for the sorter {sorter} are:\\n\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine is None:\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "    rec_training = recording_corrected.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "    sorter_params=dict(\n",
    "        do_correction = False,\n",
    "        skip_kilosort_preprocessing = True # we already did it\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    sorting = GenerateDict(rec_training, probe, sorterFolder, **sorter_params)\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine = \"dask\"\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "    rec_training = recording_corrected.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "    sorter_params=dict(\n",
    "        do_correction = False,\n",
    "        skip_kilosort_preprocessing = True # we already did it\n",
    "    )\n",
    "\n",
    "    \n",
    "    if GPU_available: # takes about 10 minutes with dask #longer?\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"4GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:10:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gpus=2'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 40 minutes\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"6GB\",\n",
    "                        job_cpu=55,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "    print(client.get_versions(check=True))\n",
    "    \n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(GenerateDict, rec_training, probe, sorterFolder, **sorter_params)\n",
    "    sorting = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine==\"submitit\":\n",
    "    #it takes about 90s with GPU (if available) ; 40 min otherwise\n",
    "    gc.collect()\n",
    "\n",
    "    GPU_available = True\n",
    "\n",
    "    start_time = time.time()\n",
    "    rec_training = recording_corrected.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    if GPU_available:\n",
    "        executor.update_parameters(mem_gb=5, timeout_min=10, slurm_partition=\"GPU\", cpus_per_task=2)\n",
    "        #executor.update_parameters(mem_gb=5, timeout_min=5, slurm_partition=\"GPU\", slurm_gres='gpu:1')\n",
    "    else:\n",
    "        executor.update_parameters(mem_gb=5, timeout_min=120, slurm_partition=\"CPU\", cpus_per_task=60)\n",
    "\n",
    "\n",
    "    # actually submit the job\n",
    "    job = executor.submit(GenerateDict, rec_training, probe)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")\n",
    "\n",
    "    last_job = job\n",
    "    sorting = job.result()\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277d8c6-e2e1-46e1-8dee-4424d98675d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kilosort4 run time 2212.34s for 8Gb 10cpus num1 (15.74, 15.42, 1.49, 2.11)\n",
    "#100%|██████████| 60/60 [39:44<00:00, 39.74s/it] 8/10 python\n",
    "\n",
    "#32%|███▏      | 19/60 [09:26<19:40, 28.78s/it] 8/30 submitit\n",
    "#32%|███▏      | 19/60 [09:13<19:55, 29.16s/it] 16/30 submitit\n",
    "#60%|██████    | 36/60 [12:10<07:36, 19.02s/it] 5/30 submitit\n",
    "#23%|██▎       | 14/60 [10:14<32:55, 42.95s/it] 5/10 submitit\n",
    "#42%|████▏     | 25/60 [06:35<07:23, 12.66s/it] 5/50 submitit\n",
    "#33%|███▎      | 20/60 [05:32<10:29, 15.75s/it] 5/50 submitit data in mnt\n",
    "\n",
    "\n",
    "#GPU\n",
    "#job completed: 33972 returned in 110.73936009407043 seconds 5/50\n",
    "#job completed: 33973 returned in 94.93399000167847 seconds 5/10\n",
    "#job completed: 33975 returned in 93.79518842697144 seconds 5/2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee34b754",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "file_path=\"kilosort4_output/spikeinterface_recording.pickle\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    d = pickle.load(f)\n",
    "\n",
    "for key in d[\"kwargs\"]:\n",
    "#for key in d:\n",
    "    print(key)\n",
    "\n",
    "print(d[\"kwargs\"][\"parent_recording\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf455d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not reAnalyse:\n",
    "    if os.path.isdir(sorterFolder):\n",
    "        # directory exists\n",
    "        print(f\"the previous folder {sorterFolder} was found, importing the data\")\n",
    "        sorting = si.read_sorter_folder(sorterFolder)\n",
    "        display(sorting)\n",
    "    else:\n",
    "        print(f\"the folder {sorterFolder} does not exist ; make sure of the path or reAnalyse the data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ff5c7",
   "metadata": {},
   "source": [
    "## Cure the clusters\n",
    "Here you should ensure that you are happy with the clusters that were found. For that, you should first compute analysis for the training clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037ccfe",
   "metadata": {},
   "source": [
    "### Fast initial curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cebbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sorting)\n",
    "sorting = si.remove_duplicated_spikes(sorting=sorting)\n",
    "sorting = si.remove_excess_spikes(sorting=sorting, recording=recording_corrected)\n",
    "#Est-ce qu'on veut aussi remove_redundant_units?\n",
    "display(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfff988",
   "metadata": {},
   "source": [
    "### Construct analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f54b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine is None:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compute_analyzer(sorting, rec_training, probe, training_folder) #, append=True) # uncomment to redo only a few analysis\n",
    "\n",
    "    #display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reAnalyse=True\n",
    "GPU_available=False\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    gc.collect()\n",
    "    \n",
    "    if GPU_available: # takes about 1.5 minutes with dask\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"70GB\",\n",
    "                        job_cpu=70,\n",
    "                        walltime=\"01:20:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gpus=2'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 1.5 min\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"60GB\",\n",
    "                        job_cpu=40,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(compute_analyzer, sorting, rec_training, probe, training_folder) #, append=True) # uncomment to redo only a few analysis\n",
    "    future.result()\n",
    "    #sorting_analyzer_training = future.results() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    #display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4112693",
   "metadata": {},
   "source": [
    "Now, you have 2 options:\n",
    "- Either go back to local computer for full benefice of spikeinterface_gui\n",
    "1. First, copy the sorting_analyzer_training folder to crnldata ([see next cell](#download))\n",
    "1. Then, go on a local (not over ssh) script at [the most interactive viewing part](#local) at the end of this notebook, reload the sorting_analyzer older, and visualize everything on a gui.\n",
    "1. Finally, when you are happy with the spike clusters, you can upload it back to the crnl cluster to proceed with [full sorting](#sort-full-recording)\n",
    "- Or use [the following embedded plotting widgets](#widgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efe0c4",
   "metadata": {},
   "source": [
    "### Option1: go back to local PC\n",
    "<a id='download'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec648099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy initial sorting to crnldata for viewing\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    src=training_folder\n",
    "    currentFile_data = magicretrieve('currentFile_data')\n",
    "    dst=os.path.join(os.path.split(currentFile_data)[0],src)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a0cdd",
   "metadata": {},
   "source": [
    "**Here is when you should work locally**\n",
    "and do the last part\n",
    "\n",
    "... and then come back on ssh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ce41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import back sorting_analyzer\n",
    "# reAnalyse = True\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    dst=training_folder\n",
    "    currentFile_data = magicretrieve('currentFile_data')\n",
    "    src=os.path.join(os.path.split(currentFile_data)[0],dst)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2477c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae12783",
   "metadata": {},
   "source": [
    "### Option2: inline visualisation\n",
    "<a id='widgets'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3241794",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_analyzer_training = si.load_sorting_analyzer(\"sorting_analyzer_training\")\n",
    "display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few ids (unités)\n",
    "#unit_ids=[1, 2, 5]\n",
    "unit_ids=sorting_analyzer_training.unit_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_unit_templates(sorting_analyzer_training, unit_ids=unit_ids, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97227a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few ids\n",
    "unit_ids=[1, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14860987",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_rasters(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    si.plot_isi_distribution(sorting_analyzer_training,unit_ids=unit_ids)\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_autocorrelograms(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389668da",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_crosscorrelograms(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c822e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_unit_presence(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ca0a6",
   "metadata": {},
   "source": [
    "## Sort full recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine==\"dask\":\n",
    "    gc.collect()\n",
    "    \n",
    "    if GPU_available: # takes about 10 minutes with dask\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"70GB\",\n",
    "                        job_cpu=70,\n",
    "                        walltime=\"00:20:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gpus=2'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 10 minutes\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"6GB\",\n",
    "                        job_cpu=55,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(compute_analyzer, sorting, recording_corrected, probe, fullAnalyzer_folder)\n",
    "    future.result()\n",
    "    #sorting_analyzer_training = future.results() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    #display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adef6f8-a103-40aa-a640-8ad538b056ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine=='submitit':\n",
    "    start_time = time.time()\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    #executor.update_parameters(slurm_array_parallelism=2, mem_gb=30, timeout_min=10, slurm_partition=\"CPU\", cpus_per_task=50)\n",
    "    executor.update_parameters(mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70) #cpus_per_task\n",
    "\n",
    "    # actually submit the job\n",
    "    job = executor.submit(compute_analyzer, sorting, recording_corrected, probe, fullAnalyzer_folder)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a42b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#job 34074 completed in 408.1813361644745 second (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34078 completed in 437.409494638443 seconds (slurm_array_parallelism=3, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34081 completed in 423.37460565567017 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", slurm_gres=\"gpu:2\", cpus_per_task=50)\n",
    "#job 34085 completed in 367.0000305175781 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "#job 34089 completed in 370.1982145309448 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=80)\n",
    "#job 34093 completed in 355.1876621246338 seconds (mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "\n",
    "last_job = job\n",
    "checkRessources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not reAnalyse:\n",
    "    print(\"not running analysis but loading previous one\")\n",
    "    sorting_analyzer = si.load_sorting_analyzer(fullAnalyzer_folder)\n",
    "    display(sorting_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.export_report(sorting_analyzer=sorting_analyzer,output_folder='report')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2da484",
   "metadata": {},
   "source": [
    "# Most interactive viewing on local\n",
    "<a id='local'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes 13s\n",
    "#from IPython.display import Javascript\n",
    "#Javascript(\"Jupyter.notebook.execute_cell_range(0,15)\")\n",
    "#TODO: here should find a way to execute previous cell, or have the function in a loadable module.\n",
    "currentFile_data = magicretrieve('currentFile_data')\n",
    "print(currentFile_data)\n",
    "sorting_analyzer_training = si.load_sorting_analyzer(os.path.join('//10.69.168.1',os.path.split(currentFile_data)[0],training_folder))\n",
    "display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061be488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "si.plot_sorting_summary(sorting_analyzer_training, backend=\"spikeinterface_gui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d554903",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFile_data = magicretrieve('currentFile_data', storePath='')\n",
    "print(currentFile_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".si-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
