{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of LFP & Calcium traces if no subsessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LFP and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "from scipy import fftpack\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "from ephyviewer import AnalogSignalSourceWithScatter\n",
    "import ephyviewer\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "from itertools import groupby\n",
    "import sys \n",
    "import pickle\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/minian\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    open_minian_mf,\n",
    "    save_minian,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose recording session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dpath either from a previous run or from a previous notebook\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "    dpath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording\"\n",
    "\n",
    "# Set up Initial Basic Parameters#\n",
    "minian_path = \".\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Select session folder</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_base = Path(os.path.join(dpath, \"OpenEphys\"))\n",
    "\n",
    "filename2 = folder_base / f'RawDataChannelExtractedDS.npy'\n",
    "All = np.load(filename2, mmap_mode= 'r')\n",
    "\n",
    "ScoringFile = folder_base / f'ScoredSleep_AB.npy'\n",
    "SleepScoredTS=np.load(ScoringFile)\n",
    "\n",
    "mfile = open(Path(dpath).parent / f'mappingsAB_ALL.pkl', 'rb')\n",
    "mapping = pickle.load(mfile)\n",
    "B = mapping['session']    \n",
    "\n",
    "Channels = '//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/LFPChannels_perMice.xlsx' \n",
    "allchannels = pd.read_excel(Channels)\n",
    "\n",
    "StampsFile = folder_base.parent / f'SynchroFile.xlsx'\n",
    "Stamps= pd.read_excel(StampsFile)\n",
    "StartTime = list(Stamps[0])[0]\n",
    "minian_freq=list(Stamps[0])[2]   \n",
    "\n",
    "try:\n",
    "    minian_ds =  open_minian(folder_base.parent /f'V4_Miniscope'/ f'minian')\n",
    "    subsession=0\n",
    "except: \n",
    "    minian_ds = open_minian_mf(folder_base.parent, [\"session\"], pattern=\"minian\")\n",
    "    subsession=1\n",
    "    \n",
    "Calcium = minian_ds['C'] # calcium traces \n",
    "Spike = minian_ds['S'] # estimated spikes\n",
    "\n",
    "coord = Calcium.coords['session'].values\n",
    "loop=coord if subsession else [coord]\n",
    "freqLFP=1000\n",
    "\n",
    "AllCalcium=pd.DataFrame()\n",
    "AllSpike=pd.DataFrame()\n",
    "for s,subsessionName in enumerate(loop): #number of subsession\n",
    "    indexMappList=B[subsessionName] if subsession else B[folder_base.parts[-2]]\n",
    "    folder_mini=folder_base.parent/ f'V4_Miniscope'/subsessionName if subsession else folder_base.parent/ f'V4_Miniscope'\n",
    "    try:\n",
    "        TodropFile = folder_mini / f'minian/TodropFileAB.json'\n",
    "        with open(TodropFile, 'r') as f:\n",
    "            unit_to_drop = json.load(f)\n",
    "    except:\n",
    "        TodropFile = folder_mini / f'minian/TodropFile.json'\n",
    "        with open(TodropFile, 'r') as f:\n",
    "            unit_to_drop = json.load(f)\n",
    "    CalciumSub1 = Calcium[s] if subsession else Calcium\n",
    "    SpikeSub1 = Spike[s] if subsession else Spike\n",
    "\n",
    "    AA = CalciumSub1['unit_id']\n",
    "    copyAA = list(AA.copy())\n",
    "    for u in unit_to_drop: # ugly way to do it, need to be improved to only use unit_to_drop\n",
    "        copyAA.remove(u)\n",
    "    unit_to_keep = copyAA\n",
    "    Cupd = CalciumSub1.loc[unit_to_keep,:]\n",
    "    \n",
    "    nb_unit = Cupd.shape[0]\n",
    "    units = range(nb_unit)                    \n",
    "    C_upd_unit_id = Cupd['unit_id'].values\n",
    "    kept_uniq_unit_List=[]\n",
    "    for unit in units:\n",
    "        indexMapp = np.where(indexMappList == C_upd_unit_id[unit])[0]\n",
    "        kept_uniq_unit_List.append(str(indexMapp))\n",
    "\n",
    "\n",
    "    CalciumSub = pd.DataFrame(CalciumSub1.loc[unit_to_keep,:], index=[f\"{mice}{str(i).replace('[','').replace(']','')}\" for i in kept_uniq_unit_List])\n",
    "    CalciumSub = CalciumSub.dropna(axis=0, how='all') #cause Nans were added to match the different number of units detected per subsessions \n",
    "    CalciumSub = CalciumSub.dropna(axis=1, how='all') #cause Nans were added to match the different subsessions video sizes\n",
    "    SpikeSub = pd.DataFrame(SpikeSub1.loc[unit_to_keep,:], index=[f\"{mice}{str(i).replace('[','').replace(']','')}\" for i in kept_uniq_unit_List])\n",
    "    SpikeSub = SpikeSub.dropna(axis=0, how='all') #cause Nans were added to match the different number of units detected per subsessions \n",
    "    SpikeSub = SpikeSub.dropna(axis=1, how='all') #cause Nans were added to match the different subsessions video sizes\n",
    "\n",
    "    print(np.shape(CalciumSub))\n",
    "    AllCalcium=pd.concat([AllCalcium, CalciumSub.T], axis=0, ignore_index=True) #if CalciumSub.shape[0] else pd.concat([AllCalcium, pd.DataFrame(np.full((1, CalciumSub1.shape[1]), np.nan))], ignore_index=True)\n",
    "    AllSpike=pd.concat([AllSpike, SpikeSub.T], axis=0, ignore_index=True)# if CalciumSub.shape[0] else pd.concat([AllSpike, pd.DataFrame(np.full((1, CalciumSub1.shape[1]), np.nan))], ignore_index=True)\n",
    "\n",
    "Calcium=AllCalcium.T\n",
    "Spike=AllSpike.T\n",
    "\n",
    "# Delay and Upscale CalciumTraces\n",
    "nan_matrix=np.full((len(Calcium), int(StartTime*minian_freq)), np.nan) # ISSUES if subsessions\n",
    "Calcium_aligned=np.concatenate((nan_matrix.T, Calcium.T), axis=0) # ISSUES if subsessions\n",
    "nan_matrix=np.full((len(Spike), int(StartTime*minian_freq)), np.nan) # ISSUES if subsessions\n",
    "Spike_aligned=np.concatenate((nan_matrix.T, Spike.T), axis=0) # ISSUES if subsessions\n",
    "\n",
    "scalefactor=freqLFP/minian_freq\n",
    "upscaled_Calcium = np.repeat(Calcium_aligned, scalefactor, axis=0) # ISSUES if subsessions\n",
    "upscaled_Spike = np.repeat(Spike_aligned, scalefactor, axis=0) # ISSUES if subsessions\n",
    "\n",
    "path_obj=Path(os.path.join(folder_mini, \"minian\"))\n",
    "if len(path_obj.parts)==12: # Not a DrugExperiment with Subsessions       \n",
    "    mice= path_obj.parents[3].name\n",
    "elif len(path_obj.parts)==11: # Not a DrugExperiment with No Subsessions\n",
    "    mice= path_obj.parents[2].name\n",
    "elif len(path_obj.parts)==13: # DrugExperiment with Subsessions\n",
    "    mice = path_obj.parents[4].name\n",
    "\n",
    "PFCch1=int(allchannels[mice][0].split(',')[0])\n",
    "PFCch2=int(allchannels[mice][0].split(',')[1])\n",
    "CA1ch1=int(allchannels[mice][2].split(',')[0])\n",
    "CA1ch2=int(allchannels[mice][2].split(',')[1])\n",
    "S1ch1=int(allchannels[mice][1].split(',')[0])\n",
    "S1ch2=int(allchannels[mice][1].split(',')[1])\n",
    "EMGch1=int(allchannels[mice][3])\n",
    "\n",
    "PFC  =  All[:, PFCch1]-All[:, PFCch2] \n",
    "CA1  =  All[:, CA1ch1]-All[:, CA1ch2] \n",
    "S1  =  All[:, S1ch1]-All[:, S1ch2] \n",
    "EMG  =  All[:, EMGch1]\n",
    "\n",
    "# Upscale Scoring\n",
    "indices = np.linspace(0, len(SleepScoredTS) - 1, len(SleepScoredTS))\n",
    "new_indices = np.linspace(0, len(SleepScoredTS) - 1, len(EMG))\n",
    "interpolated_func = interp1d(indices, SleepScoredTS, kind='zero')\n",
    "SleepScoredTS_upscaled = interpolated_func(new_indices)\n",
    "SleepScoredTS_upscaled = np.round(SleepScoredTS_upscaled * 2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load detected oscillations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OldSWSdetection=folder_base / f'SWRproperties_8sd_AB.xlsx'\n",
    "SWR_prop = pd.read_excel(OldSWSdetection, index_col=0)            \n",
    "OldSWSdetection=folder_base / f'SWRproperties.csv'\n",
    "SWR_prop = pd.read_csv(OldSWSdetection, index_col=0)         \n",
    "try: \n",
    "    SWR_prop['toKeep'] = SWR_prop['toKeep'].astype(str)\n",
    "    SWR_prop  = SWR_prop[SWR_prop['toKeep'].isin(['VRAI', 'True'])]        \n",
    "except: None\n",
    "SWR_peak = np.transpose(SWR_prop['peak time'].astype(int))\n",
    "SWR_start = np.transpose(SWR_prop['start time'].astype(int))\n",
    "SWR_end = np.transpose(SWR_prop['end time'].astype(int))\n",
    "\n",
    "OldS1spdldetection=folder_base / f'Spindlesproperties_S1_7sd_AB.xlsx'\n",
    "S1spdl_prop = pd.read_excel(OldS1spdldetection, index_col=0)            \n",
    "OldS1spdldetection=folder_base / f'Spindleproperties_S1&PFC.csv'\n",
    "S1spdl_prop = pd.read_csv(OldS1spdldetection, index_col=0)  \n",
    "S1spdl_prop['toKeep'] = S1spdl_prop['toKeep'].astype(str)\n",
    "S1spdl_prop  = S1spdl_prop[S1spdl_prop['toKeep'].isin(['VRAI', 'True'])]\n",
    "S1spdl_peak = np.transpose(S1spdl_prop['peak time'].astype(int))\n",
    "S1spdl_start = np.transpose(S1spdl_prop['start time'].astype(int))\n",
    "S1spdl_end = np.transpose(S1spdl_prop['end time'].astype(int))\n",
    "\n",
    "OldPFCspdldetection=folder_base / f'Spindlesproperties_PFC_7sd_AB.xlsx'\n",
    "PFCspdl_prop = pd.read_excel(OldPFCspdldetection, index_col=0)            \n",
    "OldPFCspdldetection=folder_base / f'Spindleproperties_S1&PFC.csv'\n",
    "PFCspdl_prop = pd.read_csv(OldPFCspdldetection, index_col=0)  \n",
    "PFCspdl_prop['toKeep'] = PFCspdl_prop['toKeep'].astype(str)\n",
    "PFCspdl_prop  = PFCspdl_prop[PFCspdl_prop['toKeep'].isin(['VRAI', 'True'])]       \n",
    "PFCspdl_peak = np.transpose(PFCspdl_prop['peak time'].astype(int))\n",
    "PFCspdl_start = np.transpose(PFCspdl_prop['start time'].astype(int))\n",
    "PFCspdl_end = np.transpose(PFCspdl_prop['end time'].astype(int))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EphyViewer = LFPs, Calcium traces, Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, TimeFreqViewer, CsvEpochSource, EpochEncoder,EpochViewer\n",
    "from ephyviewer import InMemoryAnalogSignalSource\n",
    "from ephyviewer import InMemorySpikeSource\n",
    "\n",
    "\n",
    "app = mkQApp()\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# LFPs\n",
    "\n",
    "sample_rate = freqLFP\n",
    "t_start = 0.\n",
    "scatter_indexes = {0: PFCspdl_start, 1: PFCspdl_end, 2: S1spdl_start, 3: S1spdl_end, 4: SWR_start, 5: SWR_end}\n",
    "scatter_channels = {0: [1], 1: [1], 2: [0], 3: [0], 4: [2], 5: [2]}\n",
    "combined = np.stack([(S1)/2, (PFC)*3, (CA1)/5, (EMG)/2], axis = 1)\n",
    "#source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels, scatter_colors= {0: '#FFFFFF', 1: '#222222', 2: '#FFFFFF', 3: '#222222', 4: '#FFFFFF', 5: '#222222'}, channel_names=['S1','PFC', 'CA1', 'EMG', 'Scoring'])\n",
    "source =InMemoryAnalogSignalSource(combined, sample_rate, t_start, channel_names=['S1','PFC', 'CA1', 'EMG', 'Scoring'])\n",
    "view1 = TraceViewer(source=source)\n",
    "\n",
    "view1.params['display_labels'] = True\n",
    "view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.auto_scale()\n",
    "view1.by_channel_params['ch0', 'color'] = '#88FF88' #FF0000 red, #00FF00 green, and #0000FF blue\n",
    "view1.by_channel_params['ch1', 'color'] = '#8888FF'\n",
    "view1.by_channel_params['ch2', 'color'] = '#FF8888'\n",
    "view1.by_channel_params['ch3', 'color'] = '#FFFFFF'\n",
    "\n",
    "# Calcium traces \n",
    "view2 = TraceViewer.from_numpy(zscore(np.array(Calcium.T), nan_policy='omit'), float(minian_freq), round(StartTime,2), 'Calcium Traces',channel_names=Calcium.index)\n",
    "view2.params['scale_mode'] = 'same_for_all'\n",
    "view2.auto_scale()\n",
    "view2.params['display_labels'] = True\n",
    "\n",
    "\n",
    "# Spike traces \n",
    "\n",
    "all_spikes = []\n",
    "for c,row in enumerate(upscaled_Spike.T):\n",
    "    peaks, _ = find_peaks(row)#, height=np.nanstd(row)/5)\n",
    "    all_spikes.append({ 'time':peaks/freqLFP, 'name':Calcium.index[c] })\n",
    "source = InMemorySpikeSource(all_spikes=all_spikes)\n",
    "view3 = ephyviewer.SpikeTrainViewer(source=source, name='spikes')\n",
    "\n",
    "\n",
    "# Sleep Scoring\n",
    "\n",
    "array=SleepScoredTS_upscaled\n",
    "SleepScoredTS_upscaled[SleepScoredTS_upscaled == 0.5] = 0\n",
    "substates_duration = [len(list(group)) for key, group in groupby(array)]\n",
    "substates_duration =np.array(substates_duration)/freqLFP\n",
    "substates_identity = [key for key, _ in groupby(array)]\n",
    "substates_end = np.array(substates_duration).cumsum()\n",
    "substates_start =np.append([0],substates_end[:-1])\n",
    "mapp = {0: 'NREM', 0.5: 'NREM', 1: 'REM', 1.5: 'Wake'}\n",
    "substates_identity = [mapp[num] for num in substates_identity]\n",
    "substates_identity = np.array(substates_identity)\n",
    "\n",
    "all_epochs = []\n",
    "ep_times=[]\n",
    "ep_durations=[]\n",
    "ep_labels=[]\n",
    "\n",
    "states=['NREM', 'REM', 'Wake']\n",
    "for c,st in enumerate(states):\n",
    "    ep_times=[]\n",
    "    ep_durations=[]\n",
    "    ep_labels=[]\n",
    "    for subs in range(len(substates_duration)):\n",
    "        if substates_identity[subs] == st:\n",
    "            ep_times.append(substates_start[subs])\n",
    "            ep_durations.append(substates_duration[subs])\n",
    "            ep_labels.append(subs)\n",
    "    all_epochs.append({ 'time':np.array(ep_times), 'duration':np.array(ep_durations), 'label':np.array(ep_labels), 'name':st })\n",
    "\n",
    "source_ep = ephyviewer.InMemoryEpochSource(all_epochs=all_epochs)\n",
    "view4= EpochViewer(source=source_ep, name='Scoring')\n",
    "\n",
    "view4.by_channel_params['ch0', 'color'] = '#5555FF'\n",
    "view4.by_channel_params['ch1', 'color'] = '#00AA00'\n",
    "view4.by_channel_params['ch2', 'color'] = '#FFFFFF'\n",
    "#add them to mainwindow\n",
    "\n",
    "win.add_view(view1)\n",
    "win.add_view(view4)\n",
    "win.add_view(view2)\n",
    "win.add_view(view3)\n",
    "\n",
    "#Run\n",
    "\n",
    "win.show()\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EphyViewer =  LFPs, Spikes, FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, TimeFreqViewer, CsvEpochSource, EpochEncoder,EpochViewer\n",
    "from ephyviewer import InMemoryAnalogSignalSource\n",
    "from ephyviewer import InMemorySpikeSource\n",
    "\n",
    "app = mkQApp()\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# LFPs\n",
    "\n",
    "sample_rate = freqLFP\n",
    "t_start = 0.\n",
    "scatter_indexes = {0: PFCspdl_start, 1: PFCspdl_end, 2: S1spdl_start, 3: S1spdl_end, 4: SWR_start, 5: SWR_end}\n",
    "scatter_channels = {0: [1], 1: [1], 2: [0], 3: [0], 4: [2], 5: [2]}\n",
    "combined = np.stack([(S1), (PFC), (CA1)/5, (EMG)/5], axis = 1)\n",
    "source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels, scatter_colors= {0: '#FFFFFF', 1: '#222222', 2: '#FFFFFF', 3: '#222222', 4: '#FFFFFF', 5: '#222222'}, channel_names=['S1','PFC', 'CA1', 'EMG', 'Scoring'])\n",
    "\n",
    "view1 = TraceViewer(source=source)\n",
    "\n",
    "view1.params['display_labels'] = True\n",
    "view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.auto_scale()\n",
    "view1.by_channel_params['ch0', 'color'] = '#88FF88' #FF0000 red, #00FF00 green, and #0000FF blue\n",
    "view1.by_channel_params['ch1', 'color'] = '#8888FF'\n",
    "view1.by_channel_params['ch2', 'color'] = '#FF8888'\n",
    "view1.by_channel_params['ch3', 'color'] = '#FFFFFF'\n",
    "\n",
    "# FFT\n",
    "view3 = TimeFreqViewer(source=source, name='FFT')\n",
    "\n",
    "view3.params['show_axis'] = True\n",
    "view3.params['timefreq', 'f_start'] = 1\n",
    "view3.params['timefreq', 'f_stop'] = 60\n",
    "view3.params['timefreq', 'deltafreq'] = 1 #interval in Hz\n",
    "\n",
    "view3.by_channel_params['ch0', 'clim'] = 300\n",
    "view3.by_channel_params['ch1', 'clim'] = 300\n",
    "view3.by_channel_params['ch2', 'clim'] = 300\n",
    "view3.by_channel_params['ch0', 'visible'] = True\n",
    "view3.by_channel_params['ch1', 'visible'] = False\n",
    "view3.by_channel_params['ch2', 'visible'] = False\n",
    "view3.by_channel_params['ch3', 'visible'] = False\n",
    "\n",
    "\n",
    "# Spike traces \n",
    "\n",
    "all_spikes = []\n",
    "for c,row in enumerate(upscaled_Spike.T):\n",
    "    peaks, _ = find_peaks(row)#, height=np.nanstd(row))\n",
    "    all_spikes.append({ 'time':peaks/freqLFP, 'name':'Unit#{}'.format(c) })\n",
    "source = InMemorySpikeSource(all_spikes=all_spikes)\n",
    "view2 = ephyviewer.SpikeTrainViewer(source=source, name='spikes')\n",
    "\n",
    "\n",
    "# Add them to mainwindow\n",
    "\n",
    "win.add_view(view1)\n",
    "win.add_view(view2)\n",
    "win.add_view(view3)\n",
    "\n",
    "#Run\n",
    "\n",
    "win.show()\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Extract of Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "beg=20\n",
    "end=1780\n",
    "\n",
    "# Filtre parameter:\n",
    "f_lowcut = 5.\n",
    "f_hicut = 9.\n",
    "fs = 1000\n",
    "nyq = 0.5 * fs\n",
    "N = 4                 # Filtre order\n",
    "Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "b, a = signal.butter(N, Wn, 'band')\n",
    "filt_Theta = signal.filtfilt(b, a, CA1)\n",
    "# Parameter and computation of CWT\n",
    "w = 100. #window size\n",
    "freq = np.linspace(5, 9, 8)\n",
    "widths = w*fs / (2*freq*np.pi)\n",
    "ThetaCWT = signal.cwt(filt_Theta, signal.morlet2, widths, w=w)\n",
    "# Projection calculation\n",
    "absThetaCWT = np.absolute(ThetaCWT)\n",
    "from scipy import stats\n",
    "zabsThetaCWT = stats.zscore(absThetaCWT, axis=None)\n",
    "proj_ThetaCWT = np.max(zabsThetaCWT, axis = 0)/8\n",
    "\n",
    "# Filtre parameter:\n",
    "f_lowcut = 10.\n",
    "f_hicut = 18.\n",
    "fs = 1000\n",
    "nyq = 0.5 * fs\n",
    "N = 4                 # Filtre order\n",
    "Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "b, a = signal.butter(N, Wn, 'band')\n",
    "filt_Beta1 = signal.filtfilt(b, a, PFC)\n",
    "filt_Beta2 = signal.filtfilt(b, a, S1)\n",
    "# Parameter and computation of CWT\n",
    "w = 100.  #window size \n",
    "freq = np.linspace(10, 18, 16)\n",
    "widths = w*fs / (2*freq*np.pi)\n",
    "Beta1CWT = signal.cwt(filt_Beta1, signal.morlet2, widths, w=w)\n",
    "Beta2CWT = signal.cwt(filt_Beta2, signal.morlet2, widths, w=w)\n",
    "# Projection calculation\n",
    "absBeta1CWT = np.absolute(Beta1CWT)\n",
    "absBeta2CWT = np.absolute(Beta2CWT)\n",
    "zabsBeta1CWT = stats.zscore(absBeta1CWT, axis=None)\n",
    "zabsBeta2CWT = stats.zscore(absBeta2CWT, axis=None)\n",
    "proj_Beta1CWT = np.max(zabsBeta1CWT, axis = 0)/16\n",
    "proj_Beta2CWT = np.max(zabsBeta2CWT, axis = 0)/16\n",
    "\n",
    "# Filtre parameter:\n",
    "f_lowcut = 1.\n",
    "f_hicut = 4.\n",
    "fs = 1000\n",
    "nyq = 0.5 * fs\n",
    "N = 3                 # Filtre order\n",
    "Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "b, a = signal.butter(N, Wn, 'band')\n",
    "filt_Delta = signal.filtfilt(b, a, S1)\n",
    "# Parameter and computation of CWT\n",
    "w = 100.  #window size \n",
    "freq = np.linspace(1, 4, 3)\n",
    "widths = w*fs / (2*freq*np.pi)\n",
    "DeltaCWT = signal.cwt(filt_Delta, signal.morlet2, widths, w=w)\n",
    "# Projection calculation\n",
    "absDeltaCWT = np.absolute(DeltaCWT)\n",
    "zabsDeltaCWT = stats.zscore(absDeltaCWT, axis=None)\n",
    "proj_DeltaCWT = np.max(zabsDeltaCWT, axis = 0)/3\n",
    "\n",
    "\n",
    "S1extract=(S1[beg*sample_rate:end*sample_rate])\n",
    "BetaS1extract=(proj_Beta2CWT[beg*sample_rate:end*sample_rate])\n",
    "DeltaCWTextract=(proj_DeltaCWT[beg*sample_rate:end*sample_rate])\n",
    "PFCextract=(PFC[beg*sample_rate:end*sample_rate])\n",
    "BetaPFCextract=(proj_Beta1CWT[beg*sample_rate:end*sample_rate])\n",
    "CA1extract=(CA1[beg*sample_rate:end*sample_rate])\n",
    "Thetaextract=(proj_ThetaCWT[beg*sample_rate:end*sample_rate])\n",
    "EMGextract=(EMG[beg*sample_rate:end*sample_rate])\n",
    "HypnoExtract=SleepScoredTS_upscaled[beg*sample_rate:end*sample_rate]\n",
    "\n",
    "S1extractDS=S1extract[::100]\n",
    "BetaS1extractDS=BetaS1extract[::100]\n",
    "DeltaCWTextractDS=DeltaCWTextract[::100]\n",
    "PFCextractDS=PFCextract[::100]\n",
    "BetaPFCextractDS=BetaPFCextract[::100]\n",
    "CA1extractDS=CA1extract[::100]\n",
    "ThetaextractDS=Thetaextract[::100]\n",
    "EMGextractDS=EMGextract[::100]\n",
    "HypnoExtractDS=HypnoExtract[::100]\n",
    "\n",
    "Extract=pd.DataFrame({'S1': S1extract,'filtS1': BetaS1extract,  'PFC': PFCextract, 'filtPFC': BetaPFCextract, 'CA1':CA1extract,'filtCA1': Thetaextract,  'EMG':EMGextract, 'Hypno': HypnoExtract})\n",
    "ExtractDS=pd.DataFrame({'S1': S1extractDS, 'filtS1': BetaS1extractDS, 'filtDelta': DeltaCWTextractDS, 'PFC': PFCextractDS, 'filtPFC': BetaPFCextractDS, 'CA1':CA1extractDS,'filtCA1': ThetaextractDS,  'EMG':EMGextractDS, 'Hypno': HypnoExtractDS})\n",
    "\n",
    "CaExtract=zscore(upscaled_Calcium[beg*sample_rate:end*sample_rate])\n",
    "CaExtractDS=CaExtract[::100]\n",
    "\n",
    "UnitName=[f'Unit #{i}' for i in range(len(Calcium))]\n",
    "Ca=pd.DataFrame(CaExtract, columns=UnitName)\n",
    "CaDSo=pd.DataFrame(CaExtractDS, columns=UnitName)\n",
    "CaDS = CaDSo*2 + [10 * i for i in range(1, len(CaDSo.columns) + 1)]\n",
    "\n",
    "Sum=pd.concat([Extract,Ca], axis=1)\n",
    "SumDS=pd.concat([ExtractDS,CaDS], axis=1)\n",
    "\n",
    "filenameOut=f'C:/Users/Manip2/Documents/ElifePaper/Rawdata/Extract{mice}_{folder_base.parts[-2]}_{beg}to{end}s.xlsx'\n",
    "writer=pd.ExcelWriter(filenameOut)\n",
    "SumDS.to_excel(writer, sheet_name='All')\n",
    "HypnoExtractDS=pd.DataFrame(HypnoExtractDS[::10])\n",
    "HypnoExtractDS.to_excel(writer, sheet_name='DownSample10times')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "plt.close()\n",
    "plt.plot(c)\n",
    "plt.plot(BetaS1extractDS*100)\n",
    "print('r=', round(np.corrcoef(c,BetaPFCextractDS )[0,1], 2))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure as a .png file\n",
    "filenameOut=f'C:/Users/Manip2/Documents/ElifePaper/Rawdata/Extract{mice}_{folder_base.parts[-2]}_{beg}to{end}s.png'\n",
    "plt.savefig(filenameOut, format='png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "984d3fbee8ffa490637705ae3d7233e001ab0304f3daaca07b5aa8569b88ca53"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('formation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
