{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451c17b4",
   "metadata": {},
   "source": [
    "# üìò Analyse des connexions optog√©n√©tiques via LFP (version am√©lior√©e)\n",
    "Ce notebook est une version enrichie du pipeline initial. Il permet :\n",
    "- d'extraire automatiquement les param√®tres des r√©ponses √©voqu√©es (amplitude, latence, aire),\n",
    "- de visualiser les √©volutions par r√©gion et par √¢ge,\n",
    "- de g√©n√©rer des tableaux de r√©sultats pr√™ts √† √™tre utilis√©s pour l‚Äôanalyse statistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33146329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from scipy.stats import zscore\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "import IPython\n",
    "import ast\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82994dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load LFP coordinates \n",
    "notebook_path = Path(\"/\".join(IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[-5:]))\n",
    "Channels = f'{notebook_path.parent}/_LFP_coordinates_of_all_mice.csv'\n",
    "all_LFPcoordinates = pd.read_csv(Channels, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dpath either from a previous run or from a previous notebook\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    dpath = \"//10.69.168.1/crnldata/forgetting/\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Go inside the folder containing the LFP raw file</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf96268",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_base = Path(dpath) \n",
    "miceIDflipped=[]\n",
    "\n",
    "if Path(f'{folder_base}\\DataFrame_rawdataDS.pkl').exists(): # prefer loading downsample file over original file\n",
    "    print('DataFrame_rawdataDS.pkl file')\n",
    "    LFPfile = Path(f'{folder_base}\\DataFrame_rawdataDS.pkl')\n",
    "    LFPs_df = pd.read_pickle(LFPfile)\n",
    "    samplerate = 1000 \n",
    "    numchannel = LFPs_df.shape[1]\n",
    "    rec_ch_list = LFPs_df.columns.values\n",
    "    # Load LFPs timestamps \n",
    "    for file_pathTS in folder_base.parent.parent.glob('**/continuous/*/timeStampsDS.npy'):\n",
    "        print('LFPs timestamps file found')\n",
    "        LFPtimestamps = np.load(file_pathTS)  \n",
    "elif Path(f'{folder_base}\\continuous.dat').exists():\n",
    "    print('continuous.dat file')\n",
    "    LFPfile = Path(f'{folder_base}\\continuous.dat')\n",
    "    DataRec = np.fromfile(LFPfile, dtype=\"int16\")\n",
    "    filepath = Path(os.path.join(folder_base.parent.parent, f'structure.oebin'))\n",
    "    with open(filepath) as f:\n",
    "        metadata = json.load(f)\n",
    "    samplerate = metadata['continuous'][0]['sample_rate']  \n",
    "    numchannel = metadata['continuous'][0]['num_channels'] \n",
    "    rec_ch_list = np.array([int(''.join(c for c in metadata['continuous'][0]['channels'][x]['channel_name'] if c.isdigit()))-1 for x in range(0, len(metadata['continuous'][0]['channels']))])\n",
    "    DataRec = DataRec.reshape(-1,numchannel)\n",
    "    print('Metadata found')\n",
    "    # Load LFPs timestamps \n",
    "    for file_pathTS in folder_base.parent.parent.glob('**/continuous/*/timeStamps.npy'):\n",
    "        print('LFPs timestamps file found')\n",
    "        LFPtimestamps = np.load(file_pathTS) \n",
    "    LFPs_df=pd.DataFrame(DataRec, columns=rec_ch_list) \n",
    "else: \n",
    "    print('no LFPs file found')\n",
    "\n",
    "print('sample rate =', samplerate, 'Hz')\n",
    "print(numchannel, 'channels recorded')\n",
    "print(round(LFPs_df.shape[0]/samplerate/60), 'min of recording')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_decimal=4 # 4 = 0.1ms precision / 3 = 1ms precision\n",
    "\n",
    "# Load TTLs\n",
    "TTL_Opto_duration=[]\n",
    "for file_pathTTL in folder_base.parent.parent.glob('**/TTL/timeStamps.npy'):\n",
    "    print('TTL opto file = ', file_pathTTL)\n",
    "    TTL_Opto_o = np.load(file_pathTTL)\n",
    "    TTL_Opto_duration =[round(TTL_Opto_o[i+1] - TTL_Opto_o[i],nb_decimal) for i in range(len(TTL_Opto_o) - 1)[::2]]\n",
    "    TTL_Opto= TTL_Opto_o[::2] # remove the TTL for laser OFF, only keep TTL for laser ON. CAUTION /!/ works only if it started with a TTL for laser ON\n",
    "    print(TTL_Opto.shape[0], 'opto stimulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774274ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if samplerate > 1000:\n",
    "    new_sampling_rate = 1000 # Hz\n",
    "    Nmber_points = int(np.shape(LFPs_df)[0] * new_sampling_rate / samplerate)\n",
    "    LFPs_df_DS = pd.DataFrame(signal.resample(LFPs_df, Nmber_points, axis = 0), columns=LFPs_df.columns.values)\n",
    "    LFPtimestampsDS = LFPtimestamps[::int(samplerate/new_sampling_rate)][:-1]\n",
    "    samplerate = new_sampling_rate\n",
    "    LFPs_df_DS.to_pickle(f'{LFPfile.parent}/DataFrame_rawdataDS.pkl')\n",
    "    np.save(f'{file_pathTS.parent}/timeStampsDS.npy', LFPtimestampsDS)\n",
    "    LFPs_df = LFPs_df_DS\n",
    "    LFPtimestamps = LFPtimestampsDS\n",
    "# eventually delete original files to gain space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = []\n",
    "pos_mice = []\n",
    "for mouse_name in all_LFPcoordinates.index:\n",
    "    if mouse_name in LFPfile.__str__():\n",
    "        mouse.append(mouse_name)\n",
    "        pos_mice.append(LFPfile.__str__().find(mouse_name)) \n",
    "mouse = [x for _, x in sorted(zip(pos_mice, mouse))] # sort mouse in the same order as they appear in the path\n",
    "\n",
    "if len(mouse) > 1: # found multiple mouse name in the path\n",
    "    if max(rec_ch_list) <= 31: # no channels superior to 32, so only one mouse recorded\n",
    "        id = 0 # change to 0 to see the first mouse name found, 1 the second, etc\n",
    "        ID = 0\n",
    "        print(f\"/!\\ Mutliple mice name found in the path but only mouse recorded = {mouse}. The n¬∞{id+1} was choosen automatically = {mouse[id]}.\")\n",
    "        mouse = mouse[id]\n",
    "    else:\n",
    "        ###################################################################################################################################\n",
    "        ID = 2 # choose 0 to see the first mouse recorded, 1 the second, 2 the third, 3 the fourth (only 4 mice can be recorded at the same time)\n",
    "        ###################################################################################################################################\n",
    "        print(f\"/!\\ Mutliple mice recorded at the same time = {mouse}. The n¬∞{ID+1} was choosen automatically = {mouse[ID]}.\")\n",
    "        mouse = mouse[ID] \n",
    "elif len(mouse) == 1: # found only one mouse name in the path\n",
    "    ID = 0\n",
    "    mouse = mouse[ID]\n",
    "    \n",
    "all_LFPcoordinates= all_LFPcoordinates.astype(str)\n",
    "for region in all_LFPcoordinates.loc[mouse].index:\n",
    "    locals()[f'{region}_0']=[]\n",
    "    locals()[f'{region}_1']=[]\n",
    "    locals()[f'{region}_0ch']=[]\n",
    "    locals()[f'{region}_1ch']=[]\n",
    "\n",
    "RecordedArea = []\n",
    "ChoosenChannels = []\n",
    "combined = []\n",
    "if mouse:\n",
    "    rec_ch_list_mouse = [value for value in rec_ch_list if 0+(ID*32) <= value <= 31+(ID*32)]\n",
    "    for rec_ch in rec_ch_list_mouse:\n",
    "        for idx, LFPcoord_str in enumerate(all_LFPcoordinates.loc[mouse]):\n",
    "            region = all_LFPcoordinates.loc[mouse].index[idx]\n",
    "            if LFPcoord_str != 'nan' and region != 'EMG':\n",
    "                LFPcoord = LFPcoord_str.split('_')[:2] # only take into account the 2 first of electrode of that region \n",
    "                num_ch = np.where(str(rec_ch-(ID*32)) == np.array(LFPcoord))[0]\n",
    "                if len(num_ch)>0:\n",
    "                    region=all_LFPcoordinates.loc[mouse].index[idx]\n",
    "                    LFP=locals()[f'{region}_0']\n",
    "                    if len(LFP)>0:\n",
    "                        LFP= np.array(LFPs_df[(rec_ch)])\n",
    "                        locals()[f'{region}_1']=LFP\n",
    "                        locals()[f'{region}_1ch']=rec_ch\n",
    "                    else:\n",
    "                        LFP= np.array(LFPs_df[(rec_ch)])\n",
    "                        locals()[f'{region}_0']=LFP\n",
    "                        locals()[f'{region}_0ch']=rec_ch\n",
    "                    break\n",
    "                continue\n",
    "    \n",
    "    for region in all_LFPcoordinates.loc[mouse].index:\n",
    "        for n in range(0,2,1):\n",
    "            LFP=locals()[f'{region}_{n}']\n",
    "            LFP_ch=locals()[f'{region}_{n}ch']\n",
    "            if len(LFP)>0:\n",
    "                combined=zscore(LFP[:,np.newaxis]) if len(combined)==0 else np.append(combined, zscore(LFP[:,np.newaxis]), axis=1)\n",
    "                RecordedArea.append(f'{region}_{n}') \n",
    "                ChoosenChannels.append(LFP_ch) \n",
    "else:\n",
    "    print(\"/!\\ No mouse name found in the path OR in the csv file '_LFP_coordinates_of_all_mice.csv'\")\n",
    "    mouse = '' # fill mouse name\n",
    "    RecordedArea = ['PFC','S1'] \n",
    "    PFC_0 = LFPs_df[0]\n",
    "    S1_1 = LFPs_df[1]\n",
    "    combined = np.stack([zscore(PFC_0), zscore(S1_1)], axis=1)\n",
    "\n",
    "print(mouse)\n",
    "print(RecordedArea)\n",
    "print(ChoosenChannels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_region='PFC_1' # to change\n",
    "SelectedLFP=locals()[Selected_region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9eb722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìê Extraction automatique des param√®tres des r√©ponses √©voqu√©es\n",
    "from scipy.integrate import simps\n",
    "\n",
    "results = []\n",
    "window = (0, 50)  # en ms pour fen√™tre de mesure post-TTL\n",
    "\n",
    "for i, ttl in enumerate(TTL_Opto):\n",
    "    epoch = AllEPSPs[i]  # (time x region)\n",
    "    for region_idx, region_name in enumerate(RecordedArea):\n",
    "        trace = epoch[:, region_idx]\n",
    "        time_axis = np.linspace(-500, 500, len(trace))  # en ms\n",
    "\n",
    "        # Zoom sur fen√™tre d'int√©r√™t (0‚Äì50 ms apr√®s stimulation)\n",
    "        mask = (time_axis >= window[0]) & (time_axis <= window[1])\n",
    "        trace_window = trace[mask]\n",
    "        time_window = time_axis[mask]\n",
    "\n",
    "        # Param√®tres\n",
    "        min_amp = np.min(trace_window)\n",
    "        min_lat = time_window[np.argmin(trace_window)]\n",
    "        area = simps(trace_window, time_window)  # aire sous la courbe\n",
    "\n",
    "        results.append({\n",
    "            'TTL_index': i,\n",
    "            'Region': region_name,\n",
    "            'Amplitude': min_amp,\n",
    "            'Latence_ms': min_lat,\n",
    "            'Aire': area,\n",
    "            'Mouse': mouse,\n",
    "            'Filename': folder_base.parts[-6],\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ccc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üìä Visualisation des param√®tres extraits\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(data=df_results, x=\"Region\", y=\"Amplitude\")\n",
    "plt.title(\"Amplitude des r√©ponses √©voqu√©es par r√©gion\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(data=df_results, x=\"Region\", y=\"Latence_ms\")\n",
    "plt.title(\"Latence des r√©ponses √©voqu√©es par r√©gion\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(data=df_results, x=\"Region\", y=\"Aire\")\n",
    "plt.title(\"Aire sous la courbe des r√©ponses √©voqu√©es\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
