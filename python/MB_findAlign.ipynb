{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is just a notebook to visualise 1kHz filtered raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, TimeFreqViewer, InMemoryAnalogSignalSource, EventList\n",
    "from ephyviewer import AnalogSignalSourceWithScatter, SpikeInterfaceRecordingSource, InMemoryEventSource\n",
    "\n",
    "# add the Contrib dir that contains all tools developped by MB : mbTools.py\n",
    "#sys.path.append(os.path.join(os.path.dirname(sys.path[0]),'python'))\n",
    "#print(os.path.join(os.path.dirname(sys.path[0]),'python'))\n",
    "from mbTools import mbTools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import local config, create it if inexistant\n",
    "All user-specific configuration (projects, defautl path to files...) are stored in a file named localConfig.ini in the python subfolder of AudreyHayLab repo. It is ignored by git so that it remains truely local. If the file does not exist at beginning, it is created with default values that can be modified at whishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = mbTools.localConf()\n",
    "rawDataPath = config['DATA']['path']\n",
    "print(f'All raw data are expected to be found in the folder: {rawDataPath}')\n",
    "analysisPath = config['ANALYSIS']['path']\n",
    "print(f'All analysis will be saved in the folder: {analysisPath}')\n",
    "config.printAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose experiment\n",
    "Select the experiment to display. If the experiment was already analyzed, a saved_dictionary.pkl was created and contains all necessary variables. Select this file. Otherwise select the raw data recording file.\n",
    ">**If you have a file with channel mapping somewhere**, we should make sure it is properly translated into a dict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFile = None\n",
    "%store -r currentFile\n",
    "print(currentFile)\n",
    "try:\n",
    "    theExpe = mbTools.expeConfigDict(currentFile)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "    theExpe = mbTools.expeConfigDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possibility to change raw data path \n",
    "if for some reason the path to the raw data is wrong, you can update it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theExpe.rawDataSelector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the whole data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    dpath = None #  '//10.69.168.1/crnldata/waking/audrey_hay/NPX/NPX4_claustrum/Expe_2024-07-18_12-00-43/'\n",
    "    # %store dpath\n",
    "    %store -r dpath\n",
    "    print(dpath)\n",
    "    theExpe.rawDataPath = dpath\n",
    "print(theExpe.rawDataPath)\n",
    "thedata = mbTools.experiment(theExpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "thedata.analyseExpe_findData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract submatrix of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate combined and channelLabels\n",
    "combined =  {}\n",
    "channelLabels = {}\n",
    "sample_rates = {}\n",
    "t_start = {}\n",
    "#t_end = 300 #seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract submatrix of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbTools import mbTools\n",
    "#LFP\n",
    "if 'OE_LFP' in thedata.data:\n",
    "    sample_rates['LFP'] = thedata.data['OE_LFP'].sampling_rate #20000\n",
    "    t_start['LFP'] = thedata.data['OE_LFP'].start\n",
    "    combined['LFP'] = thedata.data['OE_LFP'].combineStructures()#['M1'])\n",
    "    channelLabels['LFP'] = thedata.data['OE_LFP'].channelLabels[:]\n",
    "    print(\"LFP data combined\")\n",
    "else:\n",
    "    print(\"no LFP data to combine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NPX\n",
    "if 'NPX' in thedata.data:\n",
    "    sample_rates['NPX'] = thedata.data['NPX'].sampling_rate #30000\n",
    "    t_start['NPX'] = thedata.data['NPX'].start\n",
    "    combined['NPX'] = thedata.data['NPX'].signal['spike'].select_channels([0,1])\n",
    "    channelLabels['NPX'] = thedata.data['NPX'].channelLabels\n",
    "    print(\"NPX data combined\")\n",
    "else:\n",
    "    print(\"no NPX data to combine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for artefacts\n",
    "here you should start aphyviewer and scroll for artefacts. Try to get ate least 3 distributed along recording and write their rough time in the cell above ephyviewer's cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"artifact are around: {artefacts} s\")\n",
    "except Exception:\n",
    "    print('make sure you have manually defined artifacts times at the end of notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6174\n",
    "from mbTools import mbTools\n",
    "thedata.data['OE_LFP'].resetAlign()\n",
    "start=42#-100\n",
    "#thedata.data['OE_LFP'].start=52\n",
    "#thedata.data['OE_LFP'].sampling_rate=20046\n",
    "thedata.data['OE_LFP'].reAlignTimes()\n",
    "start=0\n",
    "print(thedata.data['NPX'])\n",
    "%matplotlib widget\n",
    "mbTools.superCleanPlot(thedata.data['OE_LFP'], thedata.data['NPX'], canauxLFP=np.arange(0,3), canauxNPX=[0], scaleNPX=10, time=567-start) #structureLFP=['M1'], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NPX=[3374.402017885, 4894.289311424] #\n",
    "timesreset=[3329.5068804, 4852.947944337] #\n",
    "thedata.data['OE_LFP'].resetAlign()\n",
    "LFPpoint=[]\n",
    "for t in timesreset:\n",
    "    if t is not np.nan:\n",
    "        p=mbTools.find_nearest(thedata.data['OE_LFP'].times,t)\n",
    "    else:\n",
    "        p=np.nan\n",
    "    print(p)\n",
    "    LFPpoint.append(p)\n",
    "print(LFPpoint)\n",
    "LFPpoint=np.array(LFPpoint).reshape(-1, 1)\n",
    "NPX2=np.array(NPX).reshape(-1, 1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,root_mean_squared_error \n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(LFPpoint,NPX2)\n",
    "freq = 1/reg.coef_[0][0]\n",
    "start = reg.intercept_[0]#+thedata.data['NPX'].times[0]\n",
    "print(freq, start)\n",
    "thedata.data['OE_LFP'].sampling_rate=freq\n",
    "thedata.data['OE_LFP'].start=start\n",
    "\n",
    "print(reg.score(LFPpoint, NPX2)) \n",
    "\n",
    "y_pred = reg.predict(LFPpoint) \n",
    "mae = mean_absolute_error(y_true=NPX2,y_pred=y_pred) \n",
    "#squared True returns MSE value, False returns RMSE value. \n",
    "mse = root_mean_squared_error(y_true=NPX2,y_pred=y_pred) #default=True \n",
    "\n",
    "print(\"MAE:\",mae) \n",
    "print(\"MSE:\",mse) \n",
    "\n",
    "thedata.data['OE_LFP'].updateParser('start',start)\n",
    "thedata.data['OE_LFP'].updateParser('freq',freq)\n",
    "thedata.data['OE_LFP'].updateParser('NPX',NPX)\n",
    "thedata.data['OE_LFP'].updateParser('timesreset',timesreset)\n",
    "\n",
    "plt.close()\n",
    "plt.plot(LFPpoint,y_pred,color='r')\n",
    "plt.scatter(LFPpoint,NPX)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, fitting is good with plenty of artefacts to realign, now let's try to find a function that depends on timestamps, number of points theoric frequencies...\n",
    "first; let's try to see how many samples are recorded by npx at the end of recording compared to LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeLFP=thedata.data['OE_LFP'].signal.shape[0]\n",
    "print(sizeLFP)\n",
    "\n",
    "sizeNPX=thedata.data['NPX'].signal['spike'].get_num_frames()\n",
    "print(sizeNPX)\n",
    "print(thedata.data['NPX'].times.shape)\n",
    "\n",
    "print(thedata.data['NPX'].times)\n",
    "print(thedata.data['OE_LFP'].times)\n",
    "\n",
    "thedata.data['OE_LFP'].reAlignTimes()\n",
    "\n",
    "lastT=thedata.data['NPX'].times[-1]\n",
    "idx=mbTools.find_nearest(thedata.data['OE_LFP'].times,lastT)\n",
    "print(idx)\n",
    "print(thedata.data['OE_LFP'].times[idx])\n",
    "print(sizeLFP-idx)\n",
    "print(idx%1024)\n",
    "\n",
    "\n",
    "lastT=thedata.data['OE_LFP'].times[-1]\n",
    "idx=mbTools.find_nearest(thedata.data['NPX'].times,lastT)\n",
    "print(idx)\n",
    "print(thedata.data['NPX'].times[idx])\n",
    "print(sizeNPX-idx)\n",
    "#there are 693 npx samples recorded after stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the recordings seem to end together, it might be a coincidence that recording stops so near a multiple of 1024 => should make sure on another experiment.\n",
    "Now, let's see if we can use the end of recordin and a single artefact to realign everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thedata.data['OE_LFP'].resetAlign() #so that lfpT is correct\n",
    "\n",
    "#let's try with first artefact as pt 1\n",
    "npxT1= NPX[0] #57.079179468   #213.831317136 #214.083826084  #459096    \n",
    "lfpT1= timesreset[0] #5.64385005  #162.7626014 #163.0008 #6385152\n",
    "idx1=mbTools.find_nearest(thedata.data['OE_LFP'].times,lfpT1)\n",
    "print(idx1)\n",
    "print(thedata.data['OE_LFP'].times[idx1])\n",
    "\n",
    "if False:\n",
    "    #let's try with last artefact as pt 2\n",
    "    npxT2= NPX[-1] #57.079179468   #213.831317136 #214.083826084  #459096    \n",
    "    lfpT2= timesreset[-1] #5.64385005  #162.7626014 #163.0008 #6385152\n",
    "    idx2=mbTools.find_nearest(thedata.data['OE_LFP'].times,lfpT2)\n",
    "    print(idx2)\n",
    "    print(thedata.data['OE_LFP'].times[idx2])\n",
    "else:\n",
    "    #let's try with end of file\n",
    "    endoffset=-243\n",
    "    print(thedata.data['OE_LFP'].signal.shape[0])\n",
    "    npxT2=thedata.data['NPX'].times[thedata.data['NPX'].signal['spike'].get_num_frames()-endoffset]\n",
    "    print(npxT2)\n",
    "    #lfpT2= thedata.data['NPX'].times[-endoffset]\n",
    "    idx2=thedata.data['OE_LFP'].signal.shape[0]\n",
    "    print(idx2)\n",
    "    print(thedata.data['OE_LFP'].signal.shape[0]-endoffset)\n",
    "    \n",
    "\n",
    "\n",
    "dn=idx2-idx1\n",
    "print(f\"dn measured with lfp : {dn}\")\n",
    "\n",
    "\n",
    "\n",
    "#iNPX=mbTools.find_nearest(thedata.data['NPX'].times,npxT1)\n",
    "#print(iNPX)\n",
    "\n",
    "#print(f\"dt measured with npx : {thedata.data['NPX'].times[-1]-npxT}\")\n",
    "#npxdt=thedata.data['NPX'].times[-1]-npxT\n",
    "\n",
    "\n",
    "#print(npxT-lfpT)\n",
    "\n",
    "\n",
    "\n",
    "#print(thedata.data['NPX'].times)\n",
    "#print(thedata.data['OE_LFP'].times)\n",
    "#thedata.data['OE_LFP'].times+=(thedata.data['NPX'].times[-1]-thedata.data['OE_LFP'].times[-1])\n",
    "#print(thedata.data['OE_LFP'].times)\n",
    "\n",
    "#dt=thedata.data['OE_LFP'].times[-1]-npxT1\n",
    "\n",
    "dt=npxT2-npxT1\n",
    "print(f\"dt measured with lfp : {dt}\")\n",
    "\n",
    "\n",
    "\n",
    "freqC=dn/dt\n",
    "print(\"the calculated freq is :\", freqC)\n",
    "print(\"while it previously was: \", thedata.data['OE_LFP'].sampling_rate)\n",
    "print(\"diff is: \", thedata.data['OE_LFP'].sampling_rate-freqC)\n",
    "\n",
    "\n",
    "#thedata.data['OE_LFP']\n",
    "#realign(offset=0, freq=freqC)\n",
    "#print(\"times npx\", thedata.data['NPX'].times)\n",
    "#print(\"times lfp\", thedata.data['OE_LFP'].times)\n",
    "#offsetC=-(thedata.data['OE_LFP'].times[-1]-thedata.data['NPX'].times[-1])\n",
    "#print(\"calculated offset\", offsetC)\n",
    "\n",
    "#realign(offset=offsetC, freq=freqC)\n",
    "\n",
    "#superCleanPlot(55)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load extra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbTools import mbTools\n",
    "All_Spindle, M1 = thedata.data['OE_LFP'].loadSpindles(relativePath='../LFP', structure = \"M1\")\n",
    "combined['LFP_DS']=M1[:,np.newaxis]\n",
    "channelLabels['LFP_DS'] = ['M1_DS']\n",
    "freqInitTheoric=20000\n",
    "freqDS=1000\n",
    "realignFactor=freqInitTheoric/sample_rates['LFP']\n",
    "sample_rates['LFP_DS']=freqDS*realignFactor\n",
    "t_start['LFP_DS']=t_start['LFP']\n",
    "print(realignFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M1_i=thedata.data['OE_LFP'].combineStructures(['M1'])[:,0]\n",
    "M1_1=thedata.data['OE_LFP'].signal[:,16]\n",
    "M1_2=thedata.data['OE_LFP'].signal[:,17]\n",
    "M1_iL=thedata.data['OE_LFP'].channelLabels[:]\n",
    "print(M1_1.shape)\n",
    "print(M1_2.shape)\n",
    "print(M1_i.shape)\n",
    "combined['LFP'] = np.stack([M1_i,M1_1, M1_2], axis = 1) #cortex, filt_cortex, proj_cortexC, proj_cortex\n",
    "print(combined['LFP'].shape)\n",
    "channelLabels['LFP'] = ['M1_iL','ch16','ch17']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell can be used to plot very precisely time of interest. Beware that it conflicts with ephyviewer however. It might be possible to have 2 notebooks open simultanéeously...\n",
    "thedata.data['OE_LFP'].reAlignTimes()\n",
    "if True:\n",
    "    %matplotlib widget\n",
    "    #you can confiure a y-offset and some scaling, have a look at the help of superCleanPlot\n",
    "    #artefacts=[55, 2649, 2709, 5362]\n",
    "    mbTools.superCleanPlot(thedata.data['OE_LFP'], thedata.data['NPX'], canauxLFP=np.arange(0,32), canauxNPX=[0], scaleNPX=10, time=5362) #structureLFP=['M1'], \n",
    "    #picFN = os.path.sep.join([theExpe.rawDataPath,'A1-8978.svg'])\n",
    "    #plt.savefig(picFN, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write here the rough times of artifacts on NPX and run the cell so that the list is accessible above\n",
    "artefacts=[3374, 4894]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "app = mkQApp()\n",
    "\n",
    "\n",
    "try:\n",
    "    TTL = Timestamps\n",
    "\n",
    "    #create 2 familly scatters from theses 2 indexes\n",
    "    scatter_indexes = {0: TTL, 1: TTL}\n",
    "    #and asign them to some channels each\n",
    "    scatter_channels = {0: [0, 12], 1: [0, 1]}\n",
    "    #source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True)\n",
    "\n",
    "if 'LFP' in combined:\n",
    "    print(sample_rates['LFP'], t_start['LFP'])\n",
    "    source = InMemoryAnalogSignalSource(combined['LFP'], sample_rates['LFP'], t_start['LFP'], channel_names=channelLabels['LFP'])\n",
    "    view1 = TraceViewer(source=source, name = 'LFP')\n",
    "\n",
    "    #Parameters can be set in script\n",
    "    view1.params['display_labels'] = True\n",
    "    view1.params['scale_mode'] = 'same_for_all'\n",
    "    view1.auto_scale()\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"hsv\"]#Wistia\"]\n",
    "    nCh = len(view1.by_channel_params.children())\n",
    "    for ch in range(nCh):\n",
    "        #view1.by_channel_params[f'ch{ch}', 'gain'] = 0.00002\n",
    "        #view1.by_channel_params[f'ch{ch}', 'offset'] = 0.1\n",
    "        view1.by_channel_params[f'ch{ch}', 'color'] = matplotlib.colors.to_hex(cmap(ch/nCh), keep_alpha=False)\n",
    "        pass\n",
    "\n",
    "    #create a time freq viewer conencted to the same source\n",
    "    view2 = TimeFreqViewer(source=source, name='tfr')\n",
    "    view2.params['show_axis'] = False\n",
    "    view2.params['timefreq', 'deltafreq'] = 1\n",
    "    #view2.by_channel_params['ch3', 'visible'] = False\n",
    "    view2.auto_scale()\n",
    "\n",
    "    win.add_view(view1)\n",
    "    #win.add_view(view2)\n",
    "\n",
    "if False:#'LFP_DS' in combined:\n",
    "\n",
    "    if All_Spindle is not None:\n",
    "        #Create one data source with 3 event channel\n",
    "        all_events = []\n",
    "        conditions = ['All','Good','Bad']\n",
    "        for c,cond in enumerate(conditions):\n",
    "            match cond:\n",
    "                case 'All':\n",
    "                    selection = \"All_Spindle['toKeep'] | ~All_Spindle['toKeep']\"\n",
    "                case 'Good':\n",
    "                    selection = \"All_Spindle['toKeep']\"\n",
    "                case 'Bad':\n",
    "                    selection = \"~All_Spindle['toKeep']\"\n",
    "            ev_times = mbTools.convertTheoricIndex2realTime(All_Spindle.loc[pd.eval(selection),'peak time'].values, realFreq=sample_rates['LFP_DS'], offset=t_start['LFP_DS'])\n",
    "            ev_labels = [f'spindle {i}'for i in All_Spindle[pd.eval(selection)].index]\n",
    "            all_events.append({ 'time':ev_times, 'label':ev_labels, 'name': conditions[c] })\n",
    "        source_ev = InMemoryEventSource(all_events=all_events)\n",
    "\n",
    "        Spindle_peak = All_Spindle['peak time'].astype(int)\n",
    "        Spindle_start = All_Spindle['start time'].astype(int)\n",
    "        Spindle_end = All_Spindle['end time'].astype(int)\n",
    "\n",
    "        #create 2 familly scatters from theses 2 indexes\n",
    "        scatter_indexes = {0: Spindle_peak, 1: Spindle_start, 2: Spindle_end}\n",
    "        #and asign them to some channels each\n",
    "        scatter_channels = {0: [0], 1: [0], 2: [0]}\n",
    "        source = AnalogSignalSourceWithScatter(combined['LFP_DS'], sample_rates['LFP_DS'], t_start['LFP_DS'], scatter_indexes, scatter_channels)#, channel_names=channelLabels['LFP_DS']\n",
    "        view_Events = EventList(source=source_ev, name='event')\n",
    "        \n",
    "    else:\n",
    "        source = InMemoryAnalogSignalSource(combined['LFP_DS'], sample_rates['LFP_DS'], t_start['LFP_DS'], channel_names=channelLabels['LFP_DS'])\n",
    "        view_Events = None\n",
    "    view_DS = TraceViewer(source=source, name = 'LFP_DS')\n",
    "\n",
    "    #Parameters can be set in script\n",
    "    view_DS.params['display_labels'] = True\n",
    "    view_DS.params['scale_mode'] = 'same_for_all'\n",
    "    view_DS.auto_scale()\n",
    "\n",
    "    cmap = matplotlib.colormaps[\"hsv\"]#Wistia\"]\n",
    "    nCh = len(view_DS.by_channel_params.children())\n",
    "    for ch in range(nCh):\n",
    "        #view_DS.by_channel_params[f'ch{ch}', 'gain'] = 0.00002\n",
    "        #view_DS.by_channel_params[f'ch{ch}', 'offset'] = 0.1\n",
    "        view_DS.by_channel_params[f'ch{ch}', 'color'] = matplotlib.colors.to_hex(cmap(ch/nCh), keep_alpha=False)\n",
    "        pass\n",
    "\n",
    "    win.add_view(view_DS)\n",
    "else:\n",
    "    view_Events=None\n",
    "\n",
    "\n",
    "if 'NPX' in combined:\n",
    "    sig_source = SpikeInterfaceRecordingSource(recording=combined['NPX'])\n",
    "    #view3 = TraceViewer.from_numpy(combined['NPX'], sample_rates['NPX'], t_start['NPX'], 'NPX', channel_names=channelLabels['NPX'])\n",
    "    view3 = TraceViewer(source=sig_source, name='NPX')\n",
    "    win.add_view(view3)\n",
    "\n",
    "    #Parameters can be set in script\n",
    "    view3.params['display_labels'] = True\n",
    "    view3.params['scale_mode'] = 'same_for_all'\n",
    "    view3.auto_scale()\n",
    "    \n",
    "    cmap = matplotlib.colormaps[\"hsv\"]#Wistia\"]\n",
    "    nCh = len(view3.by_channel_params.children())\n",
    "    for ch in range(nCh):\n",
    "        #view3.by_channel_params[f'ch{ch}', 'gain'] = 0.00002\n",
    "        #view3.by_channel_params[f'ch{ch}', 'offset'] = 0.1\n",
    "        view3.by_channel_params[f'ch{ch}', 'color'] = matplotlib.colors.to_hex(cmap(ch/nCh), keep_alpha=False)\n",
    "        pass\n",
    "\n",
    "\n",
    "if view_Events is not None:\n",
    "    win.add_view(view_Events)\n",
    "\n",
    "\n",
    "#Run\n",
    "win.show()\n",
    "#app.exec()  #if commented, the app is shown and fonctionnal. Maybe detecting buttons. the Python icon doesn't close any better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract submatrix of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
