{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Minian outputs\n",
    "\n",
    "- Load\n",
    "    - spatial map (A) -> maybe to associate with a projection of neuron fluorescence\n",
    "    - temporal activity of detected neurons\n",
    "\n",
    "- Validate units\n",
    "- Extract and save relevant data for each selected unit\n",
    "    - spatial location (x, y); no need for shape\n",
    "    - Ca2+ trace\n",
    "    - Ca2+ peak time and amplitude\n",
    "    - Deconvolved spikes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required packages (and many more that are not useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as itt\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "\n",
    "import holoviews as hv\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from holoviews.operation.datashader import datashade, regrid\n",
    "from holoviews.util import Dynamic\n",
    "from holoviews import opts\n",
    "from holoviews.operation.datashader import shade\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "from IPython.core.display import display\n",
    "\n",
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")\n",
    "\n",
    "\n",
    "#%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the minian files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderGen = Path('.').absolute()\n",
    "recording = 'Baseline_recording'\n",
    "experimenter = 'Gaelle'\n",
    "mouse_name = 'BlueLines'\n",
    "date = '2022_08_06_13_46_59'\n",
    "device = 'V4_Miniscope'\n",
    "#time = '10_01_23'\n",
    "minianversion = 'minian'\n",
    "\n",
    "folderMouse = Path(f'{folderGen}/{experimenter}/{recording}/{mouse_name}/{date}/{device}/{minianversion}/')\n",
    "\n",
    "minian_ds = open_minian(folderMouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import spatial map, Ca2+ traces, deconvolved spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = minian_ds['A']\n",
    "C = minian_ds['C']\n",
    "S = minian_ds['S']\n",
    "\n",
    "B = A['unit_id']\n",
    "series = B.to_series()\n",
    "D = series.count()\n",
    "\n",
    "idloc = A.idxmax(\"unit_id\")\n",
    "Hmax = A.idxmax(\"height\")\n",
    "Hmax2 = Hmax.max(\"width\")\n",
    "\n",
    "Wmax = A.idxmax(\"width\")\n",
    "Wmax2 = Wmax.max(\"height\")\n",
    "coord1 = Wmax2.to_series()\n",
    "coord2 = Hmax2.to_series()\n",
    "\n",
    "a = pd.concat([coord1,coord2], axis=1)\n",
    "unit = len(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot either all cells or just the one of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the spatial map for all cells + interactive Ca2+ trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_size = 150\n",
    "hv.output(size=int(output_size))\n",
    "opts = dict(\n",
    "    plot=dict(colorbar=True, invert_yaxis=True),\n",
    "    style=dict(cmap=\"Viridis\"),\n",
    ")\n",
    "image = hv.Image(\n",
    "    A.max(\"unit_id\").compute().astype(np.float32).rename(\"A\"),\n",
    "    kdims=[\"width\", \"height\"],\n",
    ").opts(**opts)\n",
    "labels = hv.Labels([(a.iloc[i,0], a.iloc[i,1], a.index[i]) for i in range(unit)])\n",
    "plot_unit = hv.HoloMap({i: hv.Curve(((C[i,:])), group='Group', label=f'{a.index[i]}') for i in range(unit)}, 'Value').opts(ylim=(-0.5, 20))\n",
    "labels2 = hv.Labels((150, 150, a.index[1]))\n",
    "layout = image * labels + plot_unit * labels2\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove dropped units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in unit_to_drop with cell_id of cells to drop\n",
    "unit_to_drop = [197]\n",
    "copyB = list(B.copy())\n",
    "for i in range(len(unit_to_drop)):\n",
    "    elem = unit_to_drop[i]\n",
    "    copyB.remove(elem)\n",
    "unit_to_keep = copyB\n",
    "\n",
    "A_upd = A.loc[unit_to_keep,:,:]\n",
    "C_upd = C.loc[unit_to_keep,:]\n",
    "S_upd = S.loc[unit_to_keep,:]\n",
    "\n",
    "TodropFile = folderMouse / f'TodropFile.json'\n",
    "\n",
    "with open(TodropFile, 'w') as f:\n",
    "    json.dump(unit_to_drop, f, indent=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Ca2+ peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For one neuron, need to be implemented for the whole set and concatenate the np into one xarray with \n",
    "\n",
    "Indiv_trace = C_upd[2,:].to_series()\n",
    "peaks, properties = find_peaks(Indiv_trace)\n",
    "# peak boundaries taken at 70% from peak of intensity. This means that the peaks with small amplitude will be longer than the big ones.\n",
    "results_width = peak_widths(Indiv_trace, peaks, rel_height=0.7)\n",
    "# Organise results in numpy array\n",
    "peaks2 = peaks.reshape(len(peaks),1)\n",
    "npresults_width = np.array(results_width).reshape(4,-1)\n",
    "peak_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(unit_to_keep)):\n",
    "    Indiv_trace = C_upd[i,:].to_series()\n",
    "    peaks, properties = find_peaks(Indiv_trace)\n",
    "# peak boundaries taken at 70% from peak of intensity. This means that the peaks with small amplitude will be longer than the big ones.\n",
    "    results_width = peak_widths(Indiv_trace, peaks, rel_height=0.7)\n",
    "# Organise results in numpy array\n",
    "    peaks2 = peaks.reshape(len(peaks),1)\n",
    "    npresults_width = np.array(results_width).reshape(4,-1)\n",
    "    peak_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(unit)):\n",
    "    print(i)\n",
    "    subfolder = file_path.parents[1].stem\n",
    "    if subfolder == 'continuous':\n",
    "        recording = file_path.parents[2].stem.replace('recording','')\n",
    "        print(recording)\n",
    "        file = file_path.stem\n",
    "        print(recording, file)\n",
    "        np_arr = np.load(file_path)\n",
    "        datalen = len(np_arr)\n",
    "        print(file, datalen)\n",
    "        if recording == 1: #not in TTL_stamp2:\n",
    "            TTL_stamp2.append(recording)\n",
    "            coords = {\n",
    "                'channels' : np.array(['synchronized_timestamps', 'timestamps']),\n",
    "                'duration_rec' : np.arange(datalen)\n",
    "            }\n",
    "            globals()[f\"StampsCont_{recording}\"] = xr.DataArray(coords=coords, dims=['channels', 'duration_rec'])\n",
    "        globals()[f\"StampsCont_{recording}\"].loc[file,:] = np_arr   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[1,2,3,4,5]\n",
    "TodropFile = folderMouse / f'TodropFile.json'\n",
    "\n",
    "with open(TodropFile, 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable \n",
    "    # if the data is nested\n",
    "    json.dump(score, f, indent=2) \n",
    "\n",
    "with open(TodropFile, 'r') as f:\n",
    "    score = json.load(f)\n",
    "\n",
    "print(score)\n",
    "\n",
    "\n",
    "# fill in unit_to_drop with cell_id of cells to drop\n",
    "# RedLines Rec1 unit_to_drop = [0, 1, 6, 15, 18, 20, 21, 24, 26, 27, 28]\n",
    "# RedLines Rec3 unit_to_drop = [10, 12, 13, 17]\n",
    "# RedLines Rec2 unit_to_drop = [13, 14, 15]\n",
    "# GreenDots Rec2 unit_to_drop = [0, 2, 16, 30, 56] # 30 is an unit but the second part of the record (from 25000 there must have been movent and few \"cells\" show similar signal)\n",
    "# GreenLines Rec2 unit_to_drop = [2]\n",
    "# ThreeBlueCross Rec1 unit_to_drop = [30]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('minian')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d28f0aa69d972f186b6eef62f149b885b857325c1e4e259a67006c9c0c737cc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
